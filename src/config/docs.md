# RisingWave System Configurations

This page is automatically generated by `./risedev generate-example-config`

## batch

| Config | Description | Default |
|--------|-------------|---------|
| distributed_query_limit | This is the max number of queries per sql session. |  |
| enable_barrier_read |  | false |
| enable_spill | Enable the spill out to disk feature for batch queries. | true |
| frontend_compute_runtime_worker_threads | frontend compute runtime worker threads | 4 |
| mask_worker_temporary_secs | This is the secs used to mask a worker unavailable temporarily. | 30 |
| max_batch_queries_per_frontend_node | This is the max number of batch queries per frontend node. |  |
| redact_sql_option_keywords | Keywords on which SQL option redaction is based in the query log. A SQL option with a name containing any of these keywords will be redacted. | ["credential", "key", "password", "private", "secret", "token"] |
| statement_timeout_in_sec | Timeout for a batch query in seconds. | 3600 |
| worker_threads_num | The thread number of the batch task runtime in the compute node. The default value is decided by `tokio`. |  |

## meta

| Config | Description | Default |
|--------|-------------|---------|
| backend |  | "Mem" |
| compact_task_table_size_partition_threshold_high | The threshold of table size in one compact task to decide whether to partition one table into `partition_vnode_count` parts, which belongs to default group and materialized view group. Set it max value of 64-bit number to disable this feature. | 536870912 |
| compact_task_table_size_partition_threshold_low | The threshold of table size in one compact task to decide whether to partition one table into `hybrid_partition_vnode_count` parts, which belongs to default group and materialized view group. Set it max value of 64-bit number to disable this feature. | 134217728 |
| compaction_group_merge_dimension_threshold | The threshold of each dimension of the compaction group after merging. When the dimension * `compaction_group_merge_dimension_threshold` >= limit, the merging job will be rejected. | 1.2 |
| compaction_task_max_heartbeat_interval_secs |  | 30 |
| compaction_task_max_progress_interval_secs |  | 600 |
| cut_table_size_limit |  | 1073741824 |
| dangerous_max_idle_secs | After specified seconds of idle (no mview or flush), the process will be exited. It is mainly useful for playgrounds. |  |
| default_parallelism | The default global parallelism for all streaming jobs, if user doesn't specify the parallelism, this value will be used. `FULL` means use all available parallelism units, otherwise it's a number. | "Full" |
| disable_automatic_parallelism_control | Whether to disable adaptive-scaling feature. | false |
| disable_recovery | Whether to enable fail-on-recovery. Should only be used in e2e tests. | false |
| do_not_config_object_storage_lifecycle | Whether config object storage bucket lifecycle to purge stale data. | false |
| enable_committed_sst_sanity_check | Enable sanity check when SSTs are committed. | false |
| enable_compaction_deterministic | Whether to enable deterministic compaction scheduling, which will disable all auto scheduling of compaction tasks. Should only be used in e2e tests. | false |
| enable_dropped_column_reclaim | Whether compactor should rewrite row to remove dropped column. | false |
| enable_hummock_data_archive | If enabled, `SSTable` object file and version delta will be retained. `SSTable` object file need to be deleted via full GC. version delta need to be manually deleted. | false |
| event_log_channel_max_size | Keeps the latest N events per channel. | 10 |
| event_log_enabled |  | true |
| full_gc_interval_sec | Interval of automatic hummock full GC. | 3600 |
| full_gc_object_limit | Max number of object per full GC job can fetch. | 100000 |
| gc_history_retention_time_sec | Duration in seconds to retain garbage collection history data. | 21600 |
| hummock_time_travel_snapshot_interval | The interval at which a Hummock version snapshot is taken for time travel. Larger value indicates less storage overhead but worse query performance. | 100 |
| hummock_version_checkpoint_interval_sec | Interval of hummock version checkpoint. | 30 |
| hybrid_partition_vnode_count | Count of partitions of tables in default group and materialized view group. The meta node will decide according to some strategy whether to cut the boundaries of the file according to the vnode alignment. Each partition contains aligned data of `vnode_count / hybrid_partition_vnode_count` consecutive virtual-nodes of one state table. Set it zero to disable this feature. | 4 |
| max_heartbeat_interval_secs | Maximum allowed heartbeat interval in seconds. | 60 |
| max_inflight_time_travel_query | Max number of inflight time travel query. | 1000 |
| meta_leader_lease_secs |  | 30 |
| min_delta_log_num_for_hummock_version_checkpoint | The minimum delta log number a new checkpoint should compact, otherwise the checkpoint attempt is rejected. | 10 |
| min_sst_retention_time_sec | Objects within `min_sst_retention_time_sec` won't be deleted by hummock full GC, even they are dangling. | 21600 |
| move_table_size_limit |  | 10737418240 |
| node_num_monitor_interval_sec |  | 10 |
| parallelism_control_batch_size | The number of streaming jobs per scaling operation. | 10 |
| parallelism_control_trigger_first_delay_sec | The first delay of parallelism control. | 30 |
| parallelism_control_trigger_period_sec | The period of parallelism control trigger. | 10 |
| partition_vnode_count | Count of partition in split group. Meta will assign this value to every new group when it splits from default-group by automatically. Each partition contains aligned data of `vnode_count / partition_vnode_count` consecutive virtual-nodes of one state table. | 16 |
| periodic_compaction_interval_sec | Schedule compaction for all compaction groups with this interval. | 60 |
| periodic_scheduling_compaction_group_merge_interval_sec | The interval of the periodic scheduling compaction group merge job. | 600 |
| periodic_scheduling_compaction_group_split_interval_sec | The interval of the periodic scheduling compaction group split job. | 10 |
| periodic_space_reclaim_compaction_interval_sec | Schedule `space_reclaim` compaction for all compaction groups with this interval. | 3600 |
| periodic_tombstone_reclaim_compaction_interval_sec |  | 600 |
| periodic_ttl_reclaim_compaction_interval_sec | Schedule `ttl_reclaim` compaction for all compaction groups with this interval. | 1800 |
| split_group_size_limit |  | 68719476736 |
| split_group_size_ratio | Whether to split the compaction group when the size of the group exceeds the `compaction_group_config.max_estimated_group_size() * split_group_size_ratio`. | 0.9 |
| table_high_write_throughput_threshold | The threshold of write throughput to trigger a group split. | 16777216 |
| table_low_write_throughput_threshold | The threshold of write throughput to trigger a group merge. | 4194304 |
| table_stat_high_write_throughput_ratio_for_split | To split the compaction group when the high throughput statistics of the group exceeds the threshold. | 0.5 |
| table_stat_low_write_throughput_ratio_for_merge | To merge the compaction group when the low throughput statistics of the group exceeds the threshold. | 0.7 |
| table_stat_throuput_window_seconds_for_merge | The window seconds of table throughput statistic history for merge compaction group. | 240 |
| table_stat_throuput_window_seconds_for_split | The window seconds of table throughput statistic history for split compaction group. | 60 |
| vacuum_interval_sec | Interval of invoking a vacuum job, to remove stale metadata from meta store and objects from object store. | 30 |
| vacuum_spin_interval_ms | The spin interval inside a vacuum job. It avoids the vacuum job monopolizing resources of meta node. | 100 |

## meta.compaction_config

| Config | Description | Default |
|--------|-------------|---------|
| compaction_filter_mask |  | 6 |
| disable_auto_group_scheduling |  | false |
| emergency_level0_sst_file_count |  | 2000 |
| emergency_level0_sub_level_partition |  | 256 |
| enable_emergency_picker |  | true |
| level0_max_compact_file_number |  | 100 |
| level0_overlapping_sub_level_compact_level_count |  | 12 |
| level0_stop_write_threshold_max_size |  | 322122547200 |
| level0_stop_write_threshold_max_sst_count |  | 10000 |
| level0_stop_write_threshold_sub_level_number |  | 300 |
| level0_sub_level_compact_level_count |  | 3 |
| level0_tier_compact_file_number |  | 12 |
| max_bytes_for_level_base |  | 536870912 |
| max_bytes_for_level_multiplier |  | 5 |
| max_compaction_bytes |  | 2147483648 |
| max_l0_compact_level_count |  | 42 |
| max_level |  | 6 |
| max_overlapping_level_size |  | 268435456 |
| max_space_reclaim_bytes |  | 536870912 |
| max_sub_compaction |  | 4 |
| sst_allowed_trivial_move_max_count |  | 64 |
| sst_allowed_trivial_move_min_size |  | 4194304 |
| sub_level_max_compaction_bytes |  | 134217728 |
| target_file_size_base |  | 33554432 |
| tombstone_reclaim_ratio |  | 40 |

## meta.meta_store_config

| Config | Description | Default |
|--------|-------------|---------|
| acquire_timeout_sec | Acquire timeout in seconds for a meta store connection. | 30 |
| connection_timeout_sec | Connection timeout in seconds for a meta store connection. | 10 |
| idle_timeout_sec | Idle timeout in seconds for a meta store connection. | 30 |
| max_connections | Maximum number of connections for the meta store connection pool. | 10 |
| min_connections | Minimum number of connections for the meta store connection pool. | 1 |

## server

| Config | Description | Default |
|--------|-------------|---------|
| connection_pool_size | The default number of the connections when connecting to a gRPC server. For the connections used in streaming or batch exchange, please refer to the entries in `[stream.developer]` and `[batch.developer]` sections. This value will be used if they are not specified. | 16 |
| grpc_max_reset_stream |  | 200 |
| heap_profiling | Enable heap profile dump when memory usage is high. |  |
| heartbeat_interval_ms | The interval for periodic heartbeat from worker to the meta service. | 1000 |
| metrics_level | Used for control the metrics level, similar to log level. | "Info" |
| telemetry_enabled |  | true |

## storage

| Config | Description | Default |
|--------|-------------|---------|
| block_cache_capacity_mb | DEPRECATED: This config will be deprecated in the future version, use `storage.cache.block_cache_capacity_mb` instead. |  |
| check_compaction_result |  | false |
| compact_iter_recreate_timeout_ms |  | 600000 |
| compactor_concurrent_uploading_sst_count | The concurrent uploading number of `SSTables` of builder |  |
| compactor_fast_max_compact_delete_ratio |  | 40 |
| compactor_fast_max_compact_task_size |  | 2147483648 |
| compactor_iter_max_io_retry_times |  | 8 |
| compactor_max_overlap_sst_count |  | 64 |
| compactor_max_preload_meta_file_count | The maximum number of meta files that can be preloaded. If the number of meta files exceeds this value, the compactor will try to compute parallelism only through `SstableInfo`, no longer preloading `SstableMeta`. This is to prevent the compactor from consuming too much memory, but it may cause the compactor to be less efficient. | 32 |
| compactor_max_sst_key_count |  | 2097152 |
| compactor_max_sst_size |  | 536870912 |
| compactor_max_task_multiplier | Compactor calculates the maximum number of tasks that can be executed on the node based on `worker_num` and `compactor_max_task_multiplier`. `max_pull_task_count` = `worker_num` * `compactor_max_task_multiplier` | 3.0 |
| compactor_memory_available_proportion | The percentage of memory available when compactor is deployed separately. `non_reserved_memory_bytes` = `system_memory_available_bytes` * `compactor_memory_available_proportion` | 0.8 |
| compactor_memory_limit_mb |  |  |
| disable_remote_compactor |  | false |
| enable_fast_compaction |  | true |
| high_priority_ratio_in_percent | DEPRECATED: This config will be deprecated in the future version, use `storage.cache.block_cache_eviction.high_priority_ratio_in_percent` with `storage.cache.block_cache_eviction.algorithm = "Lru"` instead. |  |
| imm_merge_threshold | The threshold for the number of immutable memtables to merge to a new imm. | 0 |
| max_cached_recent_versions_number |  | 60 |
| max_concurrent_compaction_task_number |  | 16 |
| max_prefetch_block_number | max prefetch block number | 16 |
| max_preload_io_retry_times |  | 3 |
| max_preload_wait_time_mill |  | 0 |
| max_version_pinning_duration_sec |  | 10800 |
| mem_table_spill_threshold | The spill threshold for mem table. | 4194304 |
| meta_cache_capacity_mb | DEPRECATED: This config will be deprecated in the future version, use `storage.cache.meta_cache_capacity_mb` instead. |  |
| min_sst_size_for_streaming_upload | Whether to enable streaming upload for sstable. | 33554432 |
| min_sstable_size_mb |  | 32 |
| object_store | Object storage configuration 1. General configuration 2. Some special configuration of Backend 3. Retry and timeout configuration |  |
| prefetch_buffer_capacity_mb | max memory usage for large query |  |
| share_buffer_compaction_worker_threads_number | Worker threads number of dedicated tokio runtime for share buffer compaction. 0 means use tokio's default value (number of CPU core). | 4 |
| share_buffer_upload_concurrency | Number of tasks shared buffer can upload in parallel. | 8 |
| share_buffers_sync_parallelism | parallelism while syncing share buffers into L0 SST. Should NOT be 0. | 1 |
| shared_buffer_capacity_mb | Configure the maximum shared buffer size in MB explicitly. Writes attempting to exceed the capacity will stall until there is enough space. The overridden value will only be effective if: 1. `block_cache_capacity_mb` and `meta_cache_capacity_mb` are also configured explicitly. 2. `block_cache_capacity_mb` + `meta_cache_capacity_mb` + `meta_cache_capacity_mb` doesn't exceed 0.3 * non-reserved memory. |  |
| shared_buffer_flush_ratio | The shared buffer will start flushing data to object when the ratio of memory usage to the shared buffer capacity exceed such ratio. | 0.800000011920929 |
| shared_buffer_min_batch_flush_size_mb | The minimum total flush size of shared buffer spill. When a shared buffer spilled is trigger, the total flush size across multiple epochs should be at least higher than this size. | 800 |
| sstable_id_remote_fetch_number | Number of SST ids fetched from meta per RPC | 10 |
| table_info_statistic_history_times | Deprecated: The window size of table info statistic history. | 240 |
| time_travel_version_cache_capacity |  | 10 |
| write_conflict_detection_enabled | Whether to enable write conflict detection | true |

## storage.cache

| Config | Description | Default |
|--------|-------------|---------|
| block_cache_capacity_mb | Configure the capacity of the block cache in MB explicitly. The overridden value will only be effective if: 1. `meta_cache_capacity_mb` and `shared_buffer_capacity_mb` are also configured explicitly. 2. `block_cache_capacity_mb` + `meta_cache_capacity_mb` + `meta_cache_capacity_mb` doesn't exceed 0.3 * non-reserved memory. |  |
| block_cache_shard_num | Configure the number of shards in the block cache explicitly. If not set, the shard number will be determined automatically based on cache capacity. |  |
| meta_cache_capacity_mb | Configure the capacity of the block cache in MB explicitly. The overridden value will only be effective if: 1. `block_cache_capacity_mb` and `shared_buffer_capacity_mb` are also configured explicitly. 2. `block_cache_capacity_mb` + `meta_cache_capacity_mb` + `meta_cache_capacity_mb` doesn't exceed 0.3 * non-reserved memory. |  |
| meta_cache_shard_num | Configure the number of shards in the meta cache explicitly. If not set, the shard number will be determined automatically based on cache capacity. |  |

## storage.cache_refill

| Config | Description | Default |
|--------|-------------|---------|
| concurrency | Inflight data cache refill tasks. | 10 |
| data_refill_levels | `SSTable` levels to refill. | [] |
| recent_filter_layers | Recent filter layer count. | 6 |
| recent_filter_rotate_interval_ms | Recent filter layer rotate interval. | 10000 |
| threshold | Data cache refill unit admission ratio. Only unit whose blocks are admitted above the ratio will be refilled. | 0.5 |
| timeout_ms | Cache refill maximum timeout to apply version delta. | 6000 |
| unit | Block count that a data cache refill request fetches. | 64 |

## storage.data_file_cache

| Config | Description | Default |
|--------|-------------|---------|
| capacity_mb |  | 1024 |
| compression |  | "None" |
| dir |  | "" |
| file_capacity_mb |  | 64 |
| flush_buffer_threshold_mb |  |  |
| flushers |  | 4 |
| indexer_shards |  | 64 |
| insert_rate_limit_mb | Deprecated soon. Please use `throttle` to do I/O throttling instead. | 0 |
| reclaimers |  | 4 |
| recover_concurrency |  | 8 |
| recover_mode | Recover mode. Options: - "None": Do not recover disk cache. - "Quiet": Recover disk cache and skip errors. - "Strict": Recover disk cache and panic on errors. More details, see [`RecoverMode::None`], [`RecoverMode::Quiet`] and [`RecoverMode::Strict`], | "None" |
| runtime_config |  |  |
| throttle |  |  |

## storage.meta_file_cache

| Config | Description | Default |
|--------|-------------|---------|
| capacity_mb |  | 1024 |
| compression |  | "None" |
| dir |  | "" |
| file_capacity_mb |  | 64 |
| flush_buffer_threshold_mb |  |  |
| flushers |  | 4 |
| indexer_shards |  | 64 |
| insert_rate_limit_mb | Deprecated soon. Please use `throttle` to do I/O throttling instead. | 0 |
| reclaimers |  | 4 |
| recover_concurrency |  | 8 |
| recover_mode | Recover mode. Options: - "None": Do not recover disk cache. - "Quiet": Recover disk cache and skip errors. - "Strict": Recover disk cache and panic on errors. More details, see [`RecoverMode::None`], [`RecoverMode::Quiet`] and [`RecoverMode::Strict`], | "None" |
| runtime_config |  |  |
| throttle |  |  |

## streaming

| Config | Description | Default |
|--------|-------------|---------|
| actor_runtime_worker_threads_num | The thread number of the streaming actor runtime in the compute node. The default value is decided by `tokio`. |  |
| async_stack_trace | Enable async stack tracing through `await-tree` for risectl. | "ReleaseVerbose" |
| in_flight_barrier_nums | The maximum number of barriers in-flight in the compute nodes. | 10000 |
| unique_user_stream_errors | Max unique user stream errors per actor | 10 |
| unsafe_enable_strict_consistency | Control the strictness of stream consistency. | true |

## system

| Config | Description | Default |
|--------|-------------|---------|
| adaptive_parallelism_strategy | The strategy for Adaptive Parallelism. | "Auto" |
| backup_storage_directory | Remote directory for storing snapshots. |  |
| backup_storage_url | Remote storage url for storing snapshots. |  |
| barrier_interval_ms | The interval of periodic barrier. | 1000 |
| block_size_kb | Size of each block in bytes in SST. | 64 |
| bloom_false_positive | False positive probability of bloom filter. | 0.001 |
| checkpoint_frequency | There will be a checkpoint for every n barriers. | 1 |
| data_directory | Remote directory for storing data and metadata objects. |  |
| enable_tracing | Whether to enable distributed tracing. | false |
| license_key | The license key to activate enterprise features. | "" |
| max_concurrent_creating_streaming_jobs | Max number of concurrent creating streaming jobs. | 1 |
| parallel_compact_size_mb | The size of parallel task for one compact/flush job. | 512 |
| pause_on_next_bootstrap | Whether to pause all data sources on next bootstrap. | false |
| per_database_isolation | Whether per database isolation is enabled | true |
| sstable_size_mb | Target size of the Sstable. | 256 |
| state_store | URL for the state store |  |
| time_travel_retention_ms | The data retention period for time travel. | 600000 |
| use_new_object_prefix_strategy | Whether to split object prefix. |  |

## udf

| Config | Description | Default |
|--------|-------------|---------|
| enable_embedded_javascript_udf | Allow embedded JS UDFs to be created. | true |
| enable_embedded_python_udf | Allow embedded Python UDFs to be created. | false |
| enable_embedded_wasm_udf | Allow embedded WASM UDFs to be created. | true |
