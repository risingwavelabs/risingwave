# This file is automatically generated. See `src/frontend/test_runner/README.md` for more information.
- sql: |
    /* desc */
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc;
  batch_plan: |
    BatchExchange { order: [t.v1 DESC], dist: Single }
      BatchSort { order: [t.v1 DESC] }
        BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], pk_columns: [t._row_id], order_descs: [v1, t._row_id] }
      StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    /* output names are not qualified after table names */
    create table t (v1 bigint, v2 double precision);
    select t.* from t order by v1;
  batch_plan: |
    BatchExchange { order: [t.v1 ASC], dist: Single }
      BatchSort { order: [t.v1 ASC] }
        BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select v1, v1+1 from t order by v1;
  batch_plan: |
    BatchExchange { order: [t.v1 ASC], dist: Single }
      BatchSort { order: [t.v1 ASC] }
        BatchProject { exprs: [t.v1, (t.v1 + 1:Int32)] }
          BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select t.v1 from t order by v1;
  batch_plan: |
    BatchExchange { order: [t.v1 ASC], dist: Single }
      BatchSort { order: [t.v1 ASC] }
        BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    /* order by output alias */
    create table t (v1 bigint, v2 double precision);
    select v1 as a1 from t order by a1;
  batch_plan: |
    BatchExchange { order: [t.v1 ASC], dist: Single }
      BatchSort { order: [t.v1 ASC] }
        BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    /* order by ambiguous */
    create table t (v1 bigint, v2 double precision);
    select v1 as a, v2 as a from t order by a;
  binder_error: 'Bind error: ORDER BY "a" is ambiguous'
- sql: |
    /* ambiguous output name is okay as long as not used in order by */
    create table t (v1 bigint, v2 double precision);
    select v1 as a, v2 as a from t order by 2;
  batch_plan: |
    BatchExchange { order: [t.v2 ASC], dist: Single }
      BatchSort { order: [t.v2 ASC] }
        BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by 1+1;
  batch_plan: |
    BatchProject { exprs: [t.v1, t.v2] }
      BatchExchange { order: [(1:Int32 + 1:Int32) ASC], dist: Single }
        BatchSort { order: [(1:Int32 + 1:Int32) ASC] }
          BatchProject { exprs: [t.v1, t.v2, (1:Int32 + 1:Int32)] }
            BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, v2, (1:Int32 + 1:Int32)(hidden), t._row_id(hidden)], pk_columns: [t._row_id], order_descs: [(1:Int32 + 1:Int32), t._row_id] }
      StreamProject { exprs: [t.v1, t.v2, (1:Int32 + 1:Int32), t._row_id] }
        StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v;
  binder_error: 'Item not found: Invalid column: v'
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc limit 5;
  batch_plan: |
    BatchTopN { order: "[t.v1 DESC]", limit: 5, offset: 0 }
      BatchExchange { order: [], dist: Single }
        BatchTopN { order: "[t.v1 DESC]", limit: 5, offset: 0 }
          BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], pk_columns: [t._row_id], order_descs: [v1, t._row_id] }
      StreamTopN { order: "[t.v1 DESC]", limit: 5, offset: 0 }
        StreamExchange { dist: Single }
          StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 3 offset 4;
  batch_plan: |
    BatchLimit { limit: 3, offset: 4 }
      BatchExchange { order: [], dist: Single }
        BatchLimit { limit: 7, offset: 0 }
          BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 5;
  batch_plan: |
    BatchLimit { limit: 5, offset: 0 }
      BatchExchange { order: [], dist: Single }
        BatchLimit { limit: 5, offset: 0 }
          BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc limit 5 offset 7;
  batch_plan: |
    BatchTopN { order: "[t.v1 DESC]", limit: 5, offset: 7 }
      BatchExchange { order: [], dist: Single }
        BatchTopN { order: "[t.v1 DESC]", limit: 12, offset: 0 }
          BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], pk_columns: [t._row_id], order_descs: [v1, t._row_id] }
      StreamTopN { order: "[t.v1 DESC]", limit: 5, offset: 7 }
        StreamExchange { dist: Single }
          StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    /* order by expression that would be valid in select list */
    create table t (x int, y int, z int);
    select x, y from t order by x + y, z;
  optimized_logical_plan: |
    LogicalProject { exprs: [t.x, t.y, (t.x + t.y), t.z] }
      LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |
    BatchProject { exprs: [t.x, t.y] }
      BatchExchange { order: [(t.x + t.y) ASC, t.z ASC], dist: Single }
        BatchSort { order: [(t.x + t.y) ASC, t.z ASC] }
          BatchProject { exprs: [t.x, t.y, (t.x + t.y), t.z] }
            BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [x, y, (t.x + t.y)(hidden), t.z(hidden), t._row_id(hidden)], pk_columns: [t._row_id], order_descs: [(t.x + t.y), t.z, t._row_id] }
      StreamProject { exprs: [t.x, t.y, (t.x + t.y), t.z, t._row_id] }
        StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], pk: [t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    /* order by the number of an output column */
    create table t (x int, y int);
    select x, y from t order by 2;
  optimized_logical_plan: |
    LogicalScan { table: t, columns: [t.x, t.y] }
  batch_plan: |
    BatchExchange { order: [t.y ASC], dist: Single }
      BatchSort { order: [t.y ASC] }
        BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
- sql: |
    /* index exceeds the number of select items */
    create table t (x int, y int);
    select x from t order by 2;
  binder_error: 'Invalid input syntax: Invalid value in ORDER BY: 2'
- sql: |
    /* an output column name cannot be used in an expression */
    create table t (x int, y int);
    select x + y as sum from t order by sum + 1;
  binder_error: 'Item not found: Invalid column: sum'
- sql: |
    /* select distinct with order by expressions not appear in select list */
    create table t (x int, y int);
    select distinct x from t order by y;
  planner_error: 'Invalid input syntax: for SELECT DISTINCT, ORDER BY expressions
    must appear in select list'
- sql: |
    /* No BatchSort needed, when input is already sorted */
    create table t(v int);
    create materialized view mv as select * from t order by v asc;
    select * from mv order by v asc;
  batch_plan: |
    BatchExchange { order: [mv.v ASC], dist: Single }
      BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- sql: |
    /* BatchSort needed, when input is sorted in wrong order */
    create table t(v int);
    create materialized view mv as select * from t order by v asc;
    select * from mv order by v desc;
  batch_plan: |
    BatchExchange { order: [mv.v DESC], dist: Single }
      BatchSort { order: [mv.v DESC] }
        BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- sql: |
    /* No BatchSort needed, when input is already sorted */
    create table t(v int);
    create materialized view mv as select * from t order by v desc;
    select * from mv order by v desc;
  batch_plan: |
    BatchExchange { order: [mv.v DESC], dist: Single }
      BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- sql: |
    /* BatchSort needed, when input is sorted in wrong order */
    create table t(v int);
    create materialized view mv as select * from t order by v desc;
    select * from mv order by v asc;
  batch_plan: |
    BatchExchange { order: [mv.v ASC], dist: Single }
      BatchSort { order: [mv.v ASC] }
        BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
