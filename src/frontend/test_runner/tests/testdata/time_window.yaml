- sql: |
    create table t1 (id int, created_at date);
    select * from tumble(t1, created_at, interval '3' day);
  logical_plan: |
    LogicalProject { exprs: [$1, $2, $3, $4], expr_alias: [id, created_at, window_start, window_end] }
      LogicalProject { exprs: [$0, $1, $2, TumbleStart($2, '3 days 00:00:00':Interval), (TumbleStart($2, '3 days 00:00:00':Interval) + '3 days 00:00:00':Interval)], expr_alias: [ ,  ,  , window_start, window_end] }
        LogicalScan { table: t1, columns: [_row_id#0, id, created_at] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
      BatchProject { exprs: [$0, $1, TumbleStart($1, '3 days 00:00:00':Interval), (TumbleStart($1, '3 days 00:00:00':Interval) + '3 days 00:00:00':Interval)], expr_alias: [id, created_at, window_start, window_end] }
        BatchScan { table: t1, columns: [id, created_at] }
- sql: |
    create materialized view t as select * from s;
    select * from tumble(t, (country).created_at, interval '3' day);
  binder_error: 'Bind error: the 2st arg of window table function should be time_col'
  create_source:
    row_format: protobuf
    name: s
    file: |
        syntax = "proto3";
        package test;
        message TestRecord {
          int32 id = 1;
          Country country = 3;
          int64 zipcode = 4;
          float rate = 5;
        }
        message Country {
          string address = 1;
          City city = 2;
          string zipcode = 3;
          string created_at = 4;
        }
        message City {
          string address = 1;
          string zipcode = 2;
        }
- sql: |
    create table t1 (id int, created_at date);
    select * from hop(t1, created_at, interval '1' day, interval '3' day);
  logical_plan: |
    LogicalProject { exprs: [$1, $2, $3, $4], expr_alias: [id, created_at, window_start, window_end] }
      LogicalHopWindow { time_col: $2 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
        LogicalScan { table: t1, columns: [_row_id#0, id, created_at] }
  stream_plan: |
    StreamMaterialize { columns: [id, created_at, _row_id#0(hidden), window_start, window_end], pk_columns: [_row_id#0, window_start] }
      StreamExchange { dist: HashShard([2, 3]) }
        StreamHopWindow { time_col: $1 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
          StreamTableScan { table: t1, columns: [id, created_at, _row_id#0], pk_indices: [2] }
- sql: |
    create table t1 (id int, created_at date);
    select id, created_at, window_start from hop(t1, created_at, interval '1' day, interval '3' day);
  logical_plan: |
    LogicalProject { exprs: [$1, $2, $3], expr_alias: [id, created_at, window_start] }
      LogicalHopWindow { time_col: $2 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
        LogicalScan { table: t1, columns: [_row_id#0, id, created_at] }
  stream_plan: |
    StreamMaterialize { columns: [id, created_at, window_start, _row_id#0(hidden)], pk_columns: [_row_id#0, window_start] }
      StreamExchange { dist: HashShard([3, 2]) }
        StreamProject { exprs: [$0, $1, $3, $2], expr_alias: [id, created_at, window_start,  ] }
          StreamHopWindow { time_col: $1 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
            StreamTableScan { table: t1, columns: [id, created_at, _row_id#0], pk_indices: [2] }
- sql: |
    create table t1 (id int, created_at date);
    select id, created_at, window_end from hop(t1, created_at, interval '1' day, interval '3' day);
  logical_plan: |
    LogicalProject { exprs: [$1, $2, $4], expr_alias: [id, created_at, window_end] }
      LogicalHopWindow { time_col: $2 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
        LogicalScan { table: t1, columns: [_row_id#0, id, created_at] }
  stream_plan: |
    StreamMaterialize { columns: [id, created_at, window_end, _row_id#0(hidden), window_start(hidden)], pk_columns: [_row_id#0, window_start] }
      StreamExchange { dist: HashShard([3, 4]) }
        StreamProject { exprs: [$0, $1, $4, $2, $3], expr_alias: [id, created_at, window_end,  ,  ] }
          StreamHopWindow { time_col: $1 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
            StreamTableScan { table: t1, columns: [id, created_at, _row_id#0], pk_indices: [2] }
- sql: |
    create table t1 (id int, created_at date);
    select id, created_at from hop(t1, created_at, interval '1' day, interval '3' day);
  logical_plan: |
    LogicalProject { exprs: [$1, $2], expr_alias: [id, created_at] }
      LogicalHopWindow { time_col: $2 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
        LogicalScan { table: t1, columns: [_row_id#0, id, created_at] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
      BatchProject { exprs: [$0, $1], expr_alias: [id, created_at] }
        BatchHopWindow { time_col: $1 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
          BatchScan { table: t1, columns: [id, created_at] }
  stream_plan: |
    StreamMaterialize { columns: [id, created_at, _row_id#0(hidden), window_start(hidden)], pk_columns: [_row_id#0, window_start] }
      StreamExchange { dist: HashShard([2, 3]) }
        StreamProject { exprs: [$0, $1, $2, $3], expr_alias: [id, created_at,  ,  ] }
          StreamHopWindow { time_col: $1 slide: 1 day 00:00:00 size: 3 days 00:00:00 }
            StreamTableScan { table: t1, columns: [id, created_at, _row_id#0], pk_indices: [2] }
