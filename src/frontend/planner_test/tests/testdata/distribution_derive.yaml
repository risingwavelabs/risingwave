# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: create_tables
  sql: |
    set rw_streaming_enable_delta_join = true;
    create table A      (k1 int, k2 int, k3 int, v int);
    create index Ak1   on A(k1) include(k1,k2,k3,v);
    create index Ak1k2 on A(k1,k2) include(k1,k2,k3,v);
    create table B      (k1 int, k2 int, k3 int, v int);
    create index Bk1   on B(k1) include(k1,k2,k3,v);
- id: A_join_B_onk1
  before:
  - create_tables
  sql: select A.v, B.v as Bv from A join B using(k1);
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: a.k1 = bk1.k1, output: [a.v, bk1.v] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(a.k1) }
        └─BatchScan { table: a, columns: [a.k1, a.v], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    └─StreamExchange { dist: HashShard(ak1.a._row_id, ak1.k1, bk1.b._row_id) }
      └─StreamDeltaJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v, ak1.a._row_id, ak1.k1, bk1.b._row_id] }
        ├─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
        └─StreamTableScan { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamExchange Hash([2, 3, 4]) from 1
    ├── Union
    │   ├── StreamExchange Hash([2, 4, 3]) from 4
    │   └── StreamExchange Hash([2, 4, 3]) from 5
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 3
    │   └── StreamExchange NoShuffle from 2
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 2
    │   └── StreamExchange NoShuffle from 3
    └── Table 4294967294
        ├── columns: [ v, bv, ak1.a._row_id, ak1.k1, bk1.b._row_id ]
        ├── primary key: [ $2 ASC, $4 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4 ]
        ├── distribution key: [ 2, 3, 4 ]
        └── read pk prefix len hint: 3
- id: Ak1_join_B_onk1
  before:
  - create_tables
  sql: select A.v, B.v as Bv from Ak1 as A join B using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(ak1.k1) }
        └─BatchScan { table: ak1, columns: [ak1.k1, ak1.v], distribution: UpstreamHashShard(ak1.k1) }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    └─StreamExchange { dist: HashShard(ak1.a._row_id, ak1.k1, bk1.b._row_id) }
      └─StreamDeltaJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v, ak1.a._row_id, ak1.k1, bk1.b._row_id] }
        ├─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
        └─StreamTableScan { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamExchange Hash([2, 3, 4]) from 1
    ├── Union
    │   ├── StreamExchange Hash([2, 4, 3]) from 4
    │   └── StreamExchange Hash([2, 4, 3]) from 5
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 3
    │   └── StreamExchange NoShuffle from 2
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 2
    │   └── StreamExchange NoShuffle from 3
    └── Table 4294967294
        ├── columns: [ v, bv, ak1.a._row_id, ak1.k1, bk1.b._row_id ]
        ├── primary key: [ $2 ASC, $4 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4 ]
        ├── distribution key: [ 2, 3, 4 ]
        └── read pk prefix len hint: 3
- id: A_join_Bk1_onk1
  before:
  - create_tables
  sql: select A.v, B.v as Bv from A join Bk1 as B using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: a.k1 = bk1.k1, output: [a.v, bk1.v] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(a.k1) }
        └─BatchScan { table: a, columns: [a.k1, a.v], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    └─StreamExchange { dist: HashShard(ak1.a._row_id, ak1.k1, bk1.b._row_id) }
      └─StreamDeltaJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v, ak1.a._row_id, ak1.k1, bk1.b._row_id] }
        ├─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
        └─StreamTableScan { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamExchange Hash([2, 3, 4]) from 1
    ├── Union
    │   ├── StreamExchange Hash([2, 4, 3]) from 4
    │   └── StreamExchange Hash([2, 4, 3]) from 5
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 3
    │   └── StreamExchange NoShuffle from 2
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 2
    │   └── StreamExchange NoShuffle from 3
    └── Table 4294967294
        ├── columns: [ v, bv, ak1.a._row_id, ak1.k1, bk1.b._row_id ]
        ├── primary key: [ $2 ASC, $4 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4 ]
        ├── distribution key: [ 2, 3, 4 ]
        └── read pk prefix len hint: 3
- id: Ak1_join_Bk1_onk1
  before:
  - create_tables
  sql: select A.v, B.v as Bv from Ak1 as A join Bk1 as B using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(ak1.k1) }
        └─BatchScan { table: ak1, columns: [ak1.k1, ak1.v], distribution: UpstreamHashShard(ak1.k1) }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    └─StreamExchange { dist: HashShard(ak1.a._row_id, ak1.k1, bk1.b._row_id) }
      └─StreamDeltaJoin { type: Inner, predicate: ak1.k1 = bk1.k1, output: [ak1.v, bk1.v, ak1.a._row_id, ak1.k1, bk1.b._row_id] }
        ├─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
        └─StreamTableScan { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), bk1.b._row_id(hidden)], pk_columns: [ak1.a._row_id, bk1.b._row_id, ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamExchange Hash([2, 3, 4]) from 1
    ├── Union
    │   ├── StreamExchange Hash([2, 4, 3]) from 4
    │   └── StreamExchange Hash([2, 4, 3]) from 5
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: bk1, columns: [bk1.k1, bk1.v, bk1.b._row_id], pk: [bk1.b._row_id], dist: UpstreamHashShard(bk1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 3
    │   └── StreamExchange NoShuffle from 2
    ├── Lookup
    │   ├── StreamExchange Hash([0]) from 2
    │   └── StreamExchange NoShuffle from 3
    └── Table 4294967294
        ├── columns: [ v, bv, ak1.a._row_id, ak1.k1, bk1.b._row_id ]
        ├── primary key: [ $2 ASC, $4 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4 ]
        ├── distribution key: [ 2, 3, 4 ]
        └── read pk prefix len hint: 3
- id: aggk1_from_A
  before:
  - create_tables
  sql: |
    select max(v) as max_v
    from A
    group by k1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(a.v)] }
      └─BatchHashAgg { group_key: [a.k1], aggs: [max(a.v)] }
        └─BatchExchange { order: [], dist: HashShard(a.k1) }
          └─BatchScan { table: a, columns: [a.k1, a.v], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_v, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(a.v), a.k1] }
      └─StreamHashAgg { group_key: [a.k1], aggs: [max(a.v), count] }
        └─StreamExchange { dist: HashShard(a.k1) }
          └─StreamTableScan { table: a, columns: [a.k1, a.v, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_v, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(a.v), a.k1] }
    │       └── StreamHashAgg { group_key: [a.k1], aggs: [max(a.v), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── StreamExchange Hash([0]) from 1
    ├── Chain { table: a, columns: [a.k1, a.v, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ a_k1, a_v, a__row_id ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k1, max(a_v), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ max_v, a.k1 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk1_from_Ak1
  before:
  - create_tables
  sql: |
    select max(v) as max_v
    from Ak1 as A
    group by k1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(ak1.v)] }
      └─BatchSortAgg { group_key: [ak1.k1], aggs: [max(ak1.v)] }
        └─BatchScan { table: ak1, columns: [ak1.k1, ak1.v], distribution: UpstreamHashShard(ak1.k1) }
  stream_plan: |
    StreamMaterialize { columns: [max_v, ak1.k1(hidden)], pk_columns: [ak1.k1], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(ak1.v), ak1.k1] }
      └─StreamHashAgg { group_key: [ak1.k1], aggs: [max(ak1.v), count] }
        └─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_v, ak1.k1(hidden)], pk_columns: [ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(ak1.v), ak1.k1] }
    │       └── StreamHashAgg { group_key: [ak1.k1], aggs: [max(ak1.v), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │               ├── Upstream
    │               └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1_k1, ak1_v, ak1_a__row_id ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ ak1_k1, max(ak1_v), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ max_v, ak1.k1 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk1_from_Ak1k2
  before:
  - create_tables
  sql: |
    select max(v) as max_v
    from Ak1k2 as A
    group by k1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(ak1k2.v)] }
      └─BatchSortAgg { group_key: [ak1k2.k1], aggs: [max(ak1k2.v)] }
        └─BatchExchange { order: [ak1k2.k1 ASC], dist: HashShard(ak1k2.k1) }
          └─BatchScan { table: ak1k2, columns: [ak1k2.k1, ak1k2.v], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_v, ak1k2.k1(hidden)], pk_columns: [ak1k2.k1], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(ak1k2.v), ak1k2.k1] }
      └─StreamHashAgg { group_key: [ak1k2.k1], aggs: [max(ak1k2.v), count] }
        └─StreamExchange { dist: HashShard(ak1k2.k1) }
          └─StreamTableScan { table: ak1k2, columns: [ak1k2.k1, ak1k2.v, ak1k2.k2, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_v, ak1k2.k1(hidden)], pk_columns: [ak1k2.k1], pk_conflict: "no check" } { materialized table: 4294967294 }
    │   └── StreamProject { exprs: [max(ak1k2.v), ak1k2.k1] }
    │       └── StreamHashAgg { group_key: [ak1k2.k1], aggs: [max(ak1k2.v), count] } { result table: 1, state tables: [ 0 ], distinct tables: [] }
    │           └── StreamExchange Hash([0]) from 1
    ├── Chain { table: ak1k2, columns: [ak1k2.k1, ak1k2.v, ak1k2.k2, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1k2_k1, ak1k2_v, ak1k2_a__row_id ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ ak1k2_k1, max(ak1k2_v), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ max_v, ak1k2.k1 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk2_from_Ak1k2
  before:
  - create_tables
  sql: |
    select max(v) as max_v
    from Ak1k2 as A
    group by k2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(ak1k2.v)] }
      └─BatchHashAgg { group_key: [ak1k2.k2], aggs: [max(ak1k2.v)] }
        └─BatchExchange { order: [], dist: HashShard(ak1k2.k2) }
          └─BatchScan { table: ak1k2, columns: [ak1k2.k2, ak1k2.v], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_v, ak1k2.k2(hidden)], pk_columns: [ak1k2.k2], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(ak1k2.v), ak1k2.k2] }
      └─StreamHashAgg { group_key: [ak1k2.k2], aggs: [max(ak1k2.v), count] }
        └─StreamExchange { dist: HashShard(ak1k2.k2) }
          └─StreamTableScan { table: ak1k2, columns: [ak1k2.k2, ak1k2.v, ak1k2.k1, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_v, ak1k2.k2(hidden)], pk_columns: [ak1k2.k2], pk_conflict: "no check" } { materialized table: 4294967294 }
    │   └── StreamProject { exprs: [max(ak1k2.v), ak1k2.k2] }
    │       └── StreamHashAgg { group_key: [ak1k2.k2], aggs: [max(ak1k2.v), count] } { result table: 1, state tables: [ 0 ], distinct tables: [] }
    │           └── StreamExchange Hash([0]) from 1
    ├── Chain { table: ak1k2, columns: [ak1k2.k2, ak1k2.v, ak1k2.k1, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1k2_k2, ak1k2_v, ak1k2_a__row_id ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ ak1k2_k2, max(ak1k2_v), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ max_v, ak1k2.k2 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk1k2_from_Ak1k2
  before:
  - create_tables
  sql: |
    select sum(v) as sum_v
    from Ak1k2 as A
    group by k1, k2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [sum(ak1k2.v)] }
      └─BatchSortAgg { group_key: [ak1k2.k1, ak1k2.k2], aggs: [sum(ak1k2.v)] }
        └─BatchScan { table: ak1k2, columns: [ak1k2.k1, ak1k2.k2, ak1k2.v], distribution: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
  stream_plan: |
    StreamMaterialize { columns: [sum_v, ak1k2.k1(hidden), ak1k2.k2(hidden)], pk_columns: [ak1k2.k1, ak1k2.k2], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(ak1k2.v), ak1k2.k1, ak1k2.k2] }
      └─StreamHashAgg { group_key: [ak1k2.k1, ak1k2.k2], aggs: [sum(ak1k2.v), count] }
        └─StreamTableScan { table: ak1k2, columns: [ak1k2.k1, ak1k2.k2, ak1k2.v, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [sum_v, ak1k2.k1(hidden), ak1k2.k2(hidden)], pk_columns: [ak1k2.k1, ak1k2.k2], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [sum(ak1k2.v), ak1k2.k1, ak1k2.k2] }
    │       └── StreamHashAgg { group_key: [ak1k2.k1, ak1k2.k2], aggs: [sum(ak1k2.v), count] } { result table: 0, state tables: [], distinct tables: [] }
    │           └── Chain { table: ak1k2, columns: [ak1k2.k1, ak1k2.k2, ak1k2.v, ak1k2.a._row_id], pk: [ak1k2.a._row_id], dist: UpstreamHashShard(ak1k2.k1, ak1k2.k2) }
    │               ├── Upstream
    │               └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1k2_k1, ak1k2_k2, sum(ak1k2_v), count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2, 3 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    └── Table 4294967294
        ├── columns: [ sum_v, ak1k2.k1, ak1k2.k2 ]
        ├── primary key: [ $1 ASC, $2 ASC ]
        ├── value indices: [ 0, 1, 2 ]
        ├── distribution key: [ 1, 2 ]
        └── read pk prefix len hint: 2
- id: aggk1k2_from_Ak1
  before:
  - create_tables
  sql: |
    select sum(v) as sum_v
    from Ak1 as A
    group by k1, k2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [sum(ak1.v)] }
      └─BatchHashAgg { group_key: [ak1.k1, ak1.k2], aggs: [sum(ak1.v)] }
        └─BatchScan { table: ak1, columns: [ak1.k1, ak1.k2, ak1.v], distribution: UpstreamHashShard(ak1.k1) }
  stream_plan: |
    StreamMaterialize { columns: [sum_v, ak1.k1(hidden), ak1.k2(hidden)], pk_columns: [ak1.k1, ak1.k2], pk_conflict: "no check" }
    └─StreamProject { exprs: [sum(ak1.v), ak1.k1, ak1.k2] }
      └─StreamHashAgg { group_key: [ak1.k1, ak1.k2], aggs: [sum(ak1.v), count] }
        └─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.k2, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [sum_v, ak1.k1(hidden), ak1.k2(hidden)], pk_columns: [ak1.k1, ak1.k2], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [sum(ak1.v), ak1.k1, ak1.k2] }
    │       └── StreamHashAgg { group_key: [ak1.k1, ak1.k2], aggs: [sum(ak1.v), count] }
    │           ├── result table: 0
    │           ├── state tables: []
    │           ├── distinct tables: []
    │           └── Chain { table: ak1, columns: [ak1.k1, ak1.k2, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │               ├── Upstream
    │               └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1_k1, ak1_k2, sum(ak1_v), count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2, 3 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 2
    └── Table 4294967294
        ├── columns: [ sum_v, ak1.k1, ak1.k2 ]
        ├── primary key: [ $1 ASC, $2 ASC ]
        ├── value indices: [ 0, 1, 2 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 2
- id: aggk1_from_aggk1
  before:
  - create_tables
  sql: |
    select
      max(num) as max_num
    from (
      select
        count(*) as num, k1
      from A
      group by k1
    )
    group by k1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(count)] }
      └─BatchHashAgg { group_key: [a.k1], aggs: [max(count)] }
        └─BatchHashAgg { group_key: [a.k1], aggs: [count] }
          └─BatchExchange { order: [], dist: HashShard(a.k1) }
            └─BatchScan { table: a, columns: [a.k1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_num, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(count), a.k1] }
      └─StreamHashAgg { group_key: [a.k1], aggs: [max(count), count] }
        └─StreamHashAgg { group_key: [a.k1], aggs: [count] }
          └─StreamExchange { dist: HashShard(a.k1) }
            └─StreamTableScan { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_num, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(count), a.k1] }
    │       └── StreamHashAgg { group_key: [a.k1], aggs: [max(count), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── StreamHashAgg { group_key: [a.k1], aggs: [count] }
    │               ├── result table: 2
    │               ├── state tables: []
    │               ├── distinct tables: []
    │               └── StreamExchange Hash([0]) from 1
    ├── Chain { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ a_k1, count ]
    │   ├── primary key: [ $0 ASC, $1 DESC ]
    │   ├── value indices: [ 0, 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k1, max(count), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2
    │   ├── columns: [ a_k1, count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ max_num, a.k1 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk1_from_aggk1k2
  before:
  - create_tables
  sql: |
    select
      max(num) as max_num
    from (
      select
        count(*) as num, k1
      from A
      group by k1, k2
    )
    group by k1;
  logical_plan: |
    LogicalProject { exprs: [max(count)] }
    └─LogicalAgg { group_key: [a.k1], aggs: [max(count)] }
      └─LogicalProject { exprs: [a.k1, count] }
        └─LogicalProject { exprs: [count, a.k1] }
          └─LogicalAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─LogicalProject { exprs: [a.k1, a.k2] }
              └─LogicalScan { table: a, columns: [a.k1, a.k2, a.k3, a.v, a._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [max(count)] }
    └─LogicalAgg { group_key: [a.k1], aggs: [max(count)] }
      └─LogicalAgg { group_key: [a.k1, a.k2], aggs: [count] }
        └─LogicalScan { table: a, columns: [a.k1, a.k2] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(count)] }
      └─BatchHashAgg { group_key: [a.k1], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(a.k1) }
          └─BatchHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(a.k1, a.k2) }
              └─BatchScan { table: a, columns: [a.k1, a.k2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_num, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(count), a.k1] }
      └─StreamHashAgg { group_key: [a.k1], aggs: [max(count), count] }
        └─StreamExchange { dist: HashShard(a.k1) }
          └─StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─StreamExchange { dist: HashShard(a.k1, a.k2) }
              └─StreamTableScan { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_num, a.k1(hidden)], pk_columns: [a.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(count), a.k1] }
    │       └── StreamHashAgg { group_key: [a.k1], aggs: [max(count), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── StreamExchange Hash([0]) from 1
    ├── StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
    │   ├── result table: 2
    │   ├── state tables: []
    │   ├── distinct tables: []
    │   └── StreamExchange Hash([0, 1]) from 2
    ├── Chain { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ a_k1, count, a_k2 ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 0, 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k1, max(count), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2
    │   ├── columns: [ a_k1, a_k2, count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    └── Table 4294967294
        ├── columns: [ max_num, a.k1 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk2_from_aggk1k2
  before:
  - create_tables
  sql: |
    select
      max(num) as max_num
    from (
      select
        count(*) as num, k2
      from A
      group by k1, k2
    )
    group by k2;
  logical_plan: |
    LogicalProject { exprs: [max(count)] }
    └─LogicalAgg { group_key: [a.k2], aggs: [max(count)] }
      └─LogicalProject { exprs: [a.k2, count] }
        └─LogicalProject { exprs: [count, a.k2] }
          └─LogicalAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─LogicalProject { exprs: [a.k1, a.k2] }
              └─LogicalScan { table: a, columns: [a.k1, a.k2, a.k3, a.v, a._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalProject { exprs: [max(count)] }
    └─LogicalAgg { group_key: [a.k2], aggs: [max(count)] }
      └─LogicalAgg { group_key: [a.k1, a.k2], aggs: [count] }
        └─LogicalScan { table: a, columns: [a.k1, a.k2] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(count)] }
      └─BatchHashAgg { group_key: [a.k2], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(a.k2) }
          └─BatchHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(a.k1, a.k2) }
              └─BatchScan { table: a, columns: [a.k1, a.k2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_num, a.k2(hidden)], pk_columns: [a.k2], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(count), a.k2] }
      └─StreamHashAgg { group_key: [a.k2], aggs: [max(count), count] }
        └─StreamExchange { dist: HashShard(a.k2) }
          └─StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
            └─StreamExchange { dist: HashShard(a.k1, a.k2) }
              └─StreamTableScan { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_num, a.k2(hidden)], pk_columns: [a.k2], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(count), a.k2] }
    │       └── StreamHashAgg { group_key: [a.k2], aggs: [max(count), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── StreamExchange Hash([1]) from 1
    ├── StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
    │   ├── result table: 2
    │   ├── state tables: []
    │   ├── distinct tables: []
    │   └── StreamExchange Hash([0, 1]) from 2
    ├── Chain { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ a_k2, count, a_k1 ]
    │   ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    │   ├── value indices: [ 0, 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k2, max(count), count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2
    │   ├── columns: [ a_k1, a_k2, count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    └── Table 4294967294
        ├── columns: [ max_num, a.k2 ]
        ├── primary key: [ $1 ASC ]
        ├── value indices: [ 0, 1 ]
        ├── distribution key: [ 1 ]
        └── read pk prefix len hint: 1
- id: aggk1k2_from_aggk1k2
  before:
  - create_tables
  sql: |
    select
      max(num) as max_num
    from (
      select
        count(*) as num, k1, k2
      from A
      group by k1, k2
    )
    group by k1, k2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [max(count)] }
      └─BatchHashAgg { group_key: [a.k1, a.k2], aggs: [max(count)] }
        └─BatchHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
          └─BatchExchange { order: [], dist: HashShard(a.k1, a.k2) }
            └─BatchScan { table: a, columns: [a.k1, a.k2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [max_num, a.k1(hidden), a.k2(hidden)], pk_columns: [a.k1, a.k2], pk_conflict: "no check" }
    └─StreamProject { exprs: [max(count), a.k1, a.k2] }
      └─StreamHashAgg { group_key: [a.k1, a.k2], aggs: [max(count), count] }
        └─StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
          └─StreamExchange { dist: HashShard(a.k1, a.k2) }
            └─StreamTableScan { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [max_num, a.k1(hidden), a.k2(hidden)], pk_columns: [a.k1, a.k2], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamProject { exprs: [max(count), a.k1, a.k2] }
    │       └── StreamHashAgg { group_key: [a.k1, a.k2], aggs: [max(count), count] }
    │           ├── result table: 1
    │           ├── state tables: [ 0 ]
    │           ├── distinct tables: []
    │           └── StreamHashAgg { group_key: [a.k1, a.k2], aggs: [count] }
    │               ├── result table: 2
    │               ├── state tables: []
    │               ├── distinct tables: []
    │               └── StreamExchange Hash([0, 1]) from 1
    ├── Chain { table: a, columns: [a.k1, a.k2, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ a_k1, a_k2, count ]
    │   ├── primary key: [ $0 ASC, $1 ASC, $2 DESC ]
    │   ├── value indices: [ 0, 1, 2 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    ├── Table 1
    │   ├── columns: [ a_k1, a_k2, max(count), count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2, 3 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    ├── Table 2
    │   ├── columns: [ a_k1, a_k2, count ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2 ]
    │   ├── distribution key: [ 0, 1 ]
    │   └── read pk prefix len hint: 2
    └── Table 4294967294
        ├── columns: [ max_num, a.k1, a.k2 ]
        ├── primary key: [ $1 ASC, $2 ASC ]
        ├── value indices: [ 0, 1, 2 ]
        ├── distribution key: [ 1, 2 ]
        └── read pk prefix len hint: 2
- id: Ak1_join_aggk1_onk1
  before:
  - create_tables
  sql: |
    with B as (
      select
        count(*) as num, k1
      from A
      group by k1
    )
    select A.v, B.num as Bv from Ak1 as A join B using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: ak1.k1 = a.k1, output: [ak1.v, count] }
      ├─BatchExchange { order: [], dist: HashShard(ak1.k1) }
      | └─BatchScan { table: ak1, columns: [ak1.k1, ak1.v], distribution: UpstreamHashShard(ak1.k1) }
      └─BatchProject { exprs: [count, a.k1] }
        └─BatchHashAgg { group_key: [a.k1], aggs: [count] }
          └─BatchExchange { order: [], dist: HashShard(a.k1) }
            └─BatchScan { table: a, columns: [a.k1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), a.k1(hidden)], pk_columns: [ak1.a._row_id, a.k1, ak1.k1], pk_conflict: "no check" }
    └─StreamHashJoin { type: Inner, predicate: ak1.k1 = a.k1, output: [ak1.v, count, ak1.a._row_id, ak1.k1, a.k1] }
      ├─StreamExchange { dist: HashShard(ak1.k1) }
      | └─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
      └─StreamProject { exprs: [count, a.k1] }
        └─StreamHashAgg { group_key: [a.k1], aggs: [count] }
          └─StreamExchange { dist: HashShard(a.k1) }
            └─StreamTableScan { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, ak1.a._row_id(hidden), ak1.k1(hidden), a.k1(hidden)], pk_columns: [ak1.a._row_id, a.k1, ak1.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamHashJoin { type: Inner, predicate: ak1.k1 = a.k1, output: [ak1.v, count, ak1.a._row_id, ak1.k1, a.k1] }
    │       ├── left table: 0
    │       ├── right table: 2
    │       ├── left degree table: 1
    │       ├── right degree table: 3
    │       ├── StreamExchange Hash([0]) from 1
    │       └── StreamProject { exprs: [count, a.k1] }
    │           └── StreamHashAgg { group_key: [a.k1], aggs: [count] } { result table: 4, state tables: [], distinct tables: [] }
    │               └── StreamExchange Hash([0]) from 2
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ ak1_k1, ak1_v, ak1_a__row_id ]
    │   ├── primary key: [ $0 ASC, $2 ASC ]
    │   ├── value indices: [ 0, 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ ak1_k1, ak1_a__row_id, _degree ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2 { columns: [ count, a_k1 ], primary key: [ $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 1 ], read pk prefix len hint: 1 }
    ├── Table 3 { columns: [ a_k1, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }
    ├── Table 4 { columns: [ a_k1, count ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }
    └── Table 4294967294
        ├── columns: [ v, bv, ak1.a._row_id, ak1.k1, a.k1 ]
        ├── primary key: [ $2 ASC, $4 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4 ]
        ├── distribution key: [ 3 ]
        └── read pk prefix len hint: 3
- id: aggk1_join_Ak1_onk1
  before:
  - create_tables
  sql: |
    with B as (
      select
        count(*) as num, k1
      from A
      group by k1
    )
    select A.v, B.num as Bv from B join Ak1 as A using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: a.k1 = ak1.k1, output: [ak1.v, count] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(a.k1) }
        └─BatchProject { exprs: [count, a.k1] }
          └─BatchHashAgg { group_key: [a.k1], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(a.k1) }
              └─BatchScan { table: a, columns: [a.k1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v, bv, a.k1(hidden), ak1.a._row_id(hidden)], pk_columns: [a.k1, ak1.a._row_id], pk_conflict: "no check" }
    └─StreamHashJoin { type: Inner, predicate: a.k1 = ak1.k1, output: [ak1.v, count, a.k1, ak1.a._row_id] }
      ├─StreamProject { exprs: [count, a.k1] }
      | └─StreamHashAgg { group_key: [a.k1], aggs: [count] }
      |   └─StreamExchange { dist: HashShard(a.k1) }
      |     └─StreamTableScan { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
      └─StreamExchange { dist: HashShard(ak1.k1) }
        └─StreamTableScan { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [v, bv, a.k1(hidden), ak1.a._row_id(hidden)], pk_columns: [a.k1, ak1.a._row_id], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamHashJoin { type: Inner, predicate: a.k1 = ak1.k1, output: [ak1.v, count, a.k1, ak1.a._row_id] }
    │       ├── left table: 0
    │       ├── right table: 2
    │       ├── left degree table: 1
    │       ├── right degree table: 3
    │       ├── StreamProject { exprs: [count, a.k1] }
    │       │   └── StreamHashAgg { group_key: [a.k1], aggs: [count] } { result table: 4, state tables: [], distinct tables: [] }
    │       │       └── StreamExchange Hash([0]) from 1
    │       └── StreamExchange Hash([0]) from 2
    ├── Chain { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: ak1, columns: [ak1.k1, ak1.v, ak1.a._row_id], pk: [ak1.a._row_id], dist: UpstreamHashShard(ak1.k1) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ count, a_k1 ]
    │   ├── primary key: [ $1 ASC ]
    │   ├── value indices: [ 0, 1 ]
    │   ├── distribution key: [ 1 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k1, _degree ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2
    │   ├── columns: [ ak1_k1, ak1_v, ak1_a__row_id ]
    │   ├── primary key: [ $0 ASC, $2 ASC ]
    │   ├── value indices: [ 0, 1, 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 3
    │   ├── columns: [ ak1_k1, ak1_a__row_id, _degree ]
    │   ├── primary key: [ $0 ASC, $1 ASC ]
    │   ├── value indices: [ 2 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 4
    │   ├── columns: [ a_k1, count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ v, bv, a.k1, ak1.a._row_id ]
        ├── primary key: [ $2 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3 ]
        ├── distribution key: [ 2 ]
        └── read pk prefix len hint: 2
- id: aggk1_join_aggk1_onk1
  before:
  - create_tables
  sql: |
    with A as (
      select
        count(*) as num, k1
      from A
      group by k1
    ), B as (
      select
        count(*) as num, k1
      from B
      group by k1
    )
    select A.num, B.num as Bv from A join B using(k1)
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: a.k1 = b.k1, output: [count, count] }
      ├─BatchProject { exprs: [count, a.k1] }
      | └─BatchHashAgg { group_key: [a.k1], aggs: [count] }
      |   └─BatchExchange { order: [], dist: HashShard(a.k1) }
      |     └─BatchScan { table: a, columns: [a.k1], distribution: SomeShard }
      └─BatchProject { exprs: [count, b.k1] }
        └─BatchHashAgg { group_key: [b.k1], aggs: [count] }
          └─BatchExchange { order: [], dist: HashShard(b.k1) }
            └─BatchScan { table: b, columns: [b.k1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [num, bv, a.k1(hidden), b.k1(hidden)], pk_columns: [a.k1, b.k1], pk_conflict: "no check" }
    └─StreamHashJoin { type: Inner, predicate: a.k1 = b.k1, output: [count, count, a.k1, b.k1] }
      ├─StreamProject { exprs: [count, a.k1] }
      | └─StreamHashAgg { group_key: [a.k1], aggs: [count] }
      |   └─StreamExchange { dist: HashShard(a.k1) }
      |     └─StreamTableScan { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
      └─StreamProject { exprs: [count, b.k1] }
        └─StreamHashAgg { group_key: [b.k1], aggs: [count] }
          └─StreamExchange { dist: HashShard(b.k1) }
            └─StreamTableScan { table: b, columns: [b.k1, b._row_id], pk: [b._row_id], dist: UpstreamHashShard(b._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [num, bv, a.k1(hidden), b.k1(hidden)], pk_columns: [a.k1, b.k1], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamHashJoin { type: Inner, predicate: a.k1 = b.k1, output: [count, count, a.k1, b.k1] }
    │       ├── left table: 0
    │       ├── right table: 2
    │       ├── left degree table: 1
    │       ├── right degree table: 3
    │       ├── StreamProject { exprs: [count, a.k1] }
    │       │   └── StreamHashAgg { group_key: [a.k1], aggs: [count] }
    │       │       ├── result table: 4
    │       │       ├── state tables: []
    │       │       ├── distinct tables: []
    │       │       └── StreamExchange Hash([0]) from 1
    │       └── StreamProject { exprs: [count, b.k1] }
    │           └── StreamHashAgg { group_key: [b.k1], aggs: [count] }
    │               ├── result table: 5
    │               ├── state tables: []
    │               ├── distinct tables: []
    │               └── StreamExchange Hash([0]) from 2
    ├── Chain { table: a, columns: [a.k1, a._row_id], pk: [a._row_id], dist: UpstreamHashShard(a._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Chain { table: b, columns: [b.k1, b._row_id], pk: [b._row_id], dist: UpstreamHashShard(b._row_id) }
    │   ├── Upstream
    │   └── BatchPlanNode
    ├── Table 0
    │   ├── columns: [ count, a_k1 ]
    │   ├── primary key: [ $1 ASC ]
    │   ├── value indices: [ 0, 1 ]
    │   ├── distribution key: [ 1 ]
    │   └── read pk prefix len hint: 1
    ├── Table 1
    │   ├── columns: [ a_k1, _degree ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 2
    │   ├── columns: [ count, b_k1 ]
    │   ├── primary key: [ $1 ASC ]
    │   ├── value indices: [ 0, 1 ]
    │   ├── distribution key: [ 1 ]
    │   └── read pk prefix len hint: 1
    ├── Table 3
    │   ├── columns: [ b_k1, _degree ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 4
    │   ├── columns: [ a_k1, count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    ├── Table 5
    │   ├── columns: [ b_k1, count ]
    │   ├── primary key: [ $0 ASC ]
    │   ├── value indices: [ 1 ]
    │   ├── distribution key: [ 0 ]
    │   └── read pk prefix len hint: 1
    └── Table 4294967294
        ├── columns: [ num, bv, a.k1, b.k1 ]
        ├── primary key: [ $2 ASC, $3 ASC ]
        ├── value indices: [ 0, 1, 2, 3 ]
        ├── distribution key: [ 2 ]
        └── read pk prefix len hint: 2
- sql: |
    create table t1 (row_id int, uid int, v int, created_at timestamp);
    select * from hop(t1, created_at, interval '15' minute, interval '30' minute);
  logical_plan: |
    LogicalProject { exprs: [t1.row_id, t1.uid, t1.v, t1.created_at, window_start, window_end] }
    └─LogicalHopWindow { time_col: t1.created_at, slide: 00:15:00, size: 00:30:00, output: all }
      └─LogicalFilter { predicate: IsNotNull(t1.created_at) }
        └─LogicalScan { table: t1, columns: [t1.row_id, t1.uid, t1.v, t1.created_at, t1._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalHopWindow { time_col: t1.created_at, slide: 00:15:00, size: 00:30:00, output: all }
    └─LogicalScan { table: t1, columns: [t1.row_id, t1.uid, t1.v, t1.created_at], predicate: IsNotNull(t1.created_at) }
  batch_plan: |
    BatchHopWindow { time_col: t1.created_at, slide: 00:15:00, size: 00:30:00, output: all }
    └─BatchExchange { order: [], dist: Single }
      └─BatchFilter { predicate: IsNotNull(t1.created_at) }
        └─BatchScan { table: t1, columns: [t1.row_id, t1.uid, t1.v, t1.created_at], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [row_id, uid, v, created_at, window_start, window_end, t1._row_id(hidden)], pk_columns: [t1._row_id, window_start, window_end], pk_conflict: "no check" }
    └─StreamHopWindow { time_col: t1.created_at, slide: 00:15:00, size: 00:30:00, output: [t1.row_id, t1.uid, t1.v, t1.created_at, window_start, window_end, t1._row_id] }
      └─StreamFilter { predicate: IsNotNull(t1.created_at) }
        └─StreamTableScan { table: t1, columns: [t1.row_id, t1.uid, t1.v, t1.created_at, t1._row_id], pk: [t1._row_id], dist: UpstreamHashShard(t1._row_id) }
  stream_dist_plan: |2-

    ┌── StreamMaterialize { columns: [row_id, uid, v, created_at, window_start, window_end, t1._row_id(hidden)], pk_columns: [t1._row_id, window_start, window_end], pk_conflict: "no check" }
    │   ├── materialized table: 4294967294
    │   └── StreamHopWindow { time_col: t1.created_at, slide: 00:15:00, size: 00:30:00, output: [t1.row_id, t1.uid, t1.v, t1.created_at, window_start, window_end, t1._row_id] }
    │       └── StreamFilter { predicate: IsNotNull(t1.created_at) }
    │           └── Chain { table: t1, columns: [t1.row_id, t1.uid, t1.v, t1.created_at, t1._row_id], pk: [t1._row_id], dist: UpstreamHashShard(t1._row_id) }
    │               ├── Upstream
    │               └── BatchPlanNode
    └── Table 4294967294
        ├── columns: [ row_id, uid, v, created_at, window_start, window_end, t1._row_id ]
        ├── primary key: [ $6 ASC, $4 ASC, $5 ASC ]
        ├── value indices: [ 0, 1, 2, 3, 4, 5, 6 ]
        ├── distribution key: [ 6 ]
        └── read pk prefix len hint: 3
