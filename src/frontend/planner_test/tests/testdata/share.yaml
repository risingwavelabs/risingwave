# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: create_sources
  sql: |
    create source auction (id BIGINT, "item_name" VARCHAR, description VARCHAR, "initial_bid" BIGINT, reserve BIGINT, "date_time" TIMESTAMP, expires TIMESTAMP, seller BIGINT, category BIGINT, "extra" VARCHAR)
    with (
    connector = 'nexmark',
    nexmark.table.type = 'Auction',
    nexmark.split.num = '4',
    nexmark.min.event.gap.in.ns = '1000'
    );
    create source bid (auction BIGINT, bidder BIGINT, price BIGINT, "channel" VARCHAR, "url" VARCHAR, "date_time" TIMESTAMP, "extra" VARCHAR)
    with (
    connector = 'nexmark',
    nexmark.table.type = 'Bid',
    nexmark.split.num = '4',
    nexmark.min.event.gap.in.ns = '1000'
    );
- id: self_join
  before:
  - create_sources
  sql: |
    select count(*) cnt from auction A join auction B on A.id = B.id where A.initial_bid = 1 and B.initial_bid = 2;
  batch_plan: |
    BatchSimpleAgg { aggs: [sum0(count)] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [count] }
        └─BatchHashJoin { type: Inner, predicate: id = id, output: [] }
          ├─BatchExchange { order: [], dist: HashShard(id) }
          | └─BatchFilter { predicate: (initial_bid = 1:Int32) }
          |   └─BatchSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"], filter: (None, None) }
          └─BatchExchange { order: [], dist: HashShard(id) }
            └─BatchFilter { predicate: (initial_bid = 2:Int32) }
              └─BatchSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"], filter: (None, None) }
  stream_plan: |
    StreamMaterialize { columns: [cnt], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamAppendOnlySimpleAgg { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamAppendOnlyHashJoin { type: Inner, predicate: id = id, output: [_row_id, id, _row_id] }
              ├─StreamExchange { dist: HashShard(id) }
              | └─StreamFilter { predicate: (initial_bid = 1:Int32) }
              |   └─StreamShare { id = 4 }
              |     └─StreamProject { exprs: [id, initial_bid, _row_id] }
              |       └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
              |         └─StreamRowIdGen { row_id_index: 10 }
              |           └─StreamSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"] }
              └─StreamExchange { dist: HashShard(id) }
                └─StreamFilter { predicate: (initial_bid = 2:Int32) }
                  └─StreamShare { id = 4 }
                    └─StreamProject { exprs: [id, initial_bid, _row_id] }
                      └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
                        └─StreamRowIdGen { row_id_index: 10 }
                          └─StreamSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"] }
- id: nexmark_q5
  before:
  - create_sources
  sql: |
    SELECT AuctionBids.auction, AuctionBids.num FROM (
      SELECT
        bid.auction,
        count(*) AS num,
        window_start AS starttime
      FROM
        HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
      GROUP BY
        window_start,
        bid.auction
    ) AS AuctionBids
    JOIN (
      SELECT
        max(CountBids.num) AS maxn,
        CountBids.starttime_c
      FROM (
        SELECT
          count(*) AS num,
          window_start AS starttime_c
        FROM HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
        GROUP BY
          bid.auction,
          window_start
      ) AS CountBids
      GROUP BY
        CountBids.starttime_c
    ) AS MaxBids
    ON AuctionBids.starttime = MaxBids.starttime_c AND AuctionBids.num >= MaxBids.maxn;
  logical_plan: |
    LogicalProject { exprs: [auction, count] }
    └─LogicalJoin { type: Inner, on: (window_start = window_start) AND (count >= max(count)), output: all }
      ├─LogicalProject { exprs: [auction, count, window_start] }
      | └─LogicalAgg { group_key: [window_start, auction], aggs: [count] }
      |   └─LogicalProject { exprs: [window_start, auction] }
      |     └─LogicalHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: all }
      |       └─LogicalFilter { predicate: IsNotNull(date_time) }
      |         └─LogicalSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id], time_range: [(Unbounded, Unbounded)] }
      └─LogicalProject { exprs: [max(count), window_start] }
        └─LogicalAgg { group_key: [window_start], aggs: [max(count)] }
          └─LogicalProject { exprs: [window_start, count] }
            └─LogicalProject { exprs: [count, window_start] }
              └─LogicalAgg { group_key: [auction, window_start], aggs: [count] }
                └─LogicalProject { exprs: [auction, window_start] }
                  └─LogicalHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: all }
                    └─LogicalFilter { predicate: IsNotNull(date_time) }
                      └─LogicalSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id], time_range: [(Unbounded, Unbounded)] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: window_start = window_start AND (count >= max(count)), output: [auction, count] }
      ├─BatchExchange { order: [], dist: HashShard(window_start) }
      | └─BatchHashAgg { group_key: [auction, window_start], aggs: [count] }
      |   └─BatchHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start] }
      |     └─BatchExchange { order: [], dist: HashShard(auction) }
      |       └─BatchProject { exprs: [auction, date_time] }
      |         └─BatchFilter { predicate: IsNotNull(date_time) }
      |           └─BatchSource { source: "bid", columns: ["auction", "bidder", "price", "channel", "url", "date_time", "extra", "_row_id"], filter: (None, None) }
      └─BatchHashAgg { group_key: [window_start], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(window_start) }
          └─BatchHashAgg { group_key: [auction, window_start], aggs: [count] }
            └─BatchHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start] }
              └─BatchExchange { order: [], dist: HashShard(auction) }
                └─BatchProject { exprs: [auction, date_time] }
                  └─BatchFilter { predicate: IsNotNull(date_time) }
                    └─BatchSource { source: "bid", columns: ["auction", "bidder", "price", "channel", "url", "date_time", "extra", "_row_id"], filter: (None, None) }
  stream_plan: |
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start, window_start#1], pk_columns: [auction, window_start, window_start#1], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [auction, count, window_start, window_start] }
      └─StreamFilter { predicate: (count >= max(count)) }
        └─StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all }
          ├─StreamExchange { dist: HashShard(window_start) }
          | └─StreamShare { id = 7 }
          |   └─StreamAppendOnlyHashAgg { group_key: [auction, window_start], aggs: [count] }
          |     └─StreamExchange { dist: HashShard(auction, window_start) }
          |       └─StreamHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start, _row_id] }
          |         └─StreamProject { exprs: [auction, date_time, _row_id] }
          |           └─StreamFilter { predicate: IsNotNull(date_time) }
          |             └─StreamRowIdGen { row_id_index: 7 }
          |               └─StreamSource { source: "bid", columns: ["auction", "bidder", "price", "channel", "url", "date_time", "extra", "_row_id"] }
          └─StreamProject { exprs: [window_start, max(count)] }
            └─StreamHashAgg { group_key: [window_start], aggs: [max(count), count] }
              └─StreamExchange { dist: HashShard(window_start) }
                └─StreamShare { id = 7 }
                  └─StreamAppendOnlyHashAgg { group_key: [auction, window_start], aggs: [count] }
                    └─StreamExchange { dist: HashShard(auction, window_start) }
                      └─StreamHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start, _row_id] }
                        └─StreamProject { exprs: [auction, date_time, _row_id] }
                          └─StreamFilter { predicate: IsNotNull(date_time) }
                            └─StreamRowIdGen { row_id_index: 7 }
                              └─StreamSource { source: "bid", columns: ["auction", "bidder", "price", "channel", "url", "date_time", "extra", "_row_id"] }
- sql: |
    set rw_enable_share_plan=true;
    create table t(a int, b int);
    with cte as (select count(*) from t) select * from cte union all select * from cte;
  stream_plan: |
    StreamMaterialize { columns: [count, 0:Int32(hidden)], stream_key: [0:Int32], pk_columns: [0:Int32], pk_conflict: "NoCheck" }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(0:Int32) }
      | └─StreamProject { exprs: [sum0(count), 0:Int32] }
      |   └─StreamShare { id = 5 }
      |     └─StreamProject { exprs: [sum0(count)] }
      |       └─StreamSimpleAgg { aggs: [sum0(count), count] }
      |         └─StreamExchange { dist: Single }
      |           └─StreamStatelessSimpleAgg { aggs: [count] }
      |             └─StreamTableScan { table: t, columns: [t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
      └─StreamExchange { dist: HashShard(1:Int32) }
        └─StreamProject { exprs: [sum0(count), 1:Int32] }
          └─StreamShare { id = 5 }
            └─StreamProject { exprs: [sum0(count)] }
              └─StreamSimpleAgg { aggs: [sum0(count), count] }
                └─StreamExchange { dist: Single }
                  └─StreamStatelessSimpleAgg { aggs: [count] }
                    └─StreamTableScan { table: t, columns: [t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    set rw_enable_share_plan=false;
    create table t(a int, b int);
    with cte as (select count(*) from t) select * from cte union all select * from cte;
  stream_plan: |
    StreamMaterialize { columns: [count, 0:Int32(hidden)], stream_key: [0:Int32], pk_columns: [0:Int32], pk_conflict: "NoCheck" }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(0:Int32) }
      | └─StreamProject { exprs: [sum0(count), 0:Int32] }
      |   └─StreamSimpleAgg { aggs: [sum0(count), count] }
      |     └─StreamExchange { dist: Single }
      |       └─StreamStatelessSimpleAgg { aggs: [count] }
      |         └─StreamTableScan { table: t, columns: [t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
      └─StreamExchange { dist: HashShard(1:Int32) }
        └─StreamProject { exprs: [sum0(count), 1:Int32] }
          └─StreamSimpleAgg { aggs: [sum0(count), count] }
            └─StreamExchange { dist: Single }
              └─StreamStatelessSimpleAgg { aggs: [count] }
                └─StreamTableScan { table: t, columns: [t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- id: force_share_source_for_self_join
  before:
  - create_sources
  sql: |
    set rw_enable_share_plan=false;
    select count(*) cnt from auction A join auction B on A.id = B.id;
  stream_plan: |
    StreamMaterialize { columns: [cnt], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamAppendOnlySimpleAgg { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamAppendOnlyHashJoin { type: Inner, predicate: id = id, output: [_row_id, id, _row_id] }
              ├─StreamExchange { dist: HashShard(id) }
              | └─StreamShare { id = 3 }
              |   └─StreamProject { exprs: [id, _row_id] }
              |     └─StreamRowIdGen { row_id_index: 10 }
              |       └─StreamSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"] }
              └─StreamExchange { dist: HashShard(id) }
                └─StreamShare { id = 3 }
                  └─StreamProject { exprs: [id, _row_id] }
                    └─StreamRowIdGen { row_id_index: 10 }
                      └─StreamSource { source: "auction", columns: ["id", "item_name", "description", "initial_bid", "reserve", "date_time", "expires", "seller", "category", "extra", "_row_id"] }
- id: self_join_multiple_edges
  sql: |
    create table t (a int, b int);
    with cte as (select a, sum(b) sum from t group by a) select count(*) from cte c1 join cte c2 on c1.a = c2.a;
  stream_plan: |
    StreamMaterialize { columns: [count], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamSimpleAgg { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamHashJoin { type: Inner, predicate: t.a = t.a, output: all }
              ├─StreamShare { id = 4 }
              | └─StreamProject { exprs: [t.a] }
              |   └─StreamHashAgg { group_key: [t.a], aggs: [count] }
              |     └─StreamExchange { dist: HashShard(t.a) }
              |       └─StreamTableScan { table: t, columns: [t.a, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
              └─StreamShare { id = 4 }
                └─StreamProject { exprs: [t.a] }
                  └─StreamHashAgg { group_key: [t.a], aggs: [count] }
                    └─StreamExchange { dist: HashShard(t.a) }
                      └─StreamTableScan { table: t, columns: [t.a, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [count], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [sum0(count)] }
        └── StreamSimpleAgg { aggs: [sum0(count), count] }
            ├── result table: 0
            ├── state tables: []
            ├── distinct tables: []
            └──  StreamExchange Single from 1

    Fragment 1
    StreamStatelessSimpleAgg { aggs: [count] }
    └── StreamHashJoin { type: Inner, predicate: t.a = t.a, output: all }
        ├── left table: 1
        ├── right table: 3
        ├── left degree table: 2
        ├── right degree table: 4
        ├──  StreamExchange NoShuffle from 2
        └──  StreamExchange NoShuffle from 4

    Fragment 2
    StreamProject { exprs: [t.a] }
    └── StreamHashAgg { group_key: [t.a], aggs: [count] }
        ├── result table: 5
        ├── state tables: []
        ├── distinct tables: []
        └──  StreamExchange Hash([0]) from 3

    Fragment 3
    Chain { table: t, columns: [t.a, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
    ├── state table: 6
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 4
    StreamNoOp
    └──  StreamExchange NoShuffle from 2

    Table 0
    ├── columns: [ sum0(count), count ]
    ├── primary key: []
    ├── value indices: [ 0, 1 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

    Table 1
    ├── columns: [ t_a ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2
    ├── columns: [ t_a, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 3
    ├── columns: [ t_a ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 4
    ├── columns: [ t_a, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 5
    ├── columns: [ t_a, count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 6
    ├── columns: [ vnode, t__row_id, t_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: []
    └── read pk prefix len hint: 1

    Table 4294967294
    ├── columns: [ count ]
    ├── primary key: []
    ├── value indices: [ 0 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

