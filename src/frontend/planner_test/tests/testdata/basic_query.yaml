# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: values (11, 22), (33+(1+2), 44);
  batch_plan: |
    BatchValues { rows: [[11:Int32, 22:Int32], [36:Int32, 44:Int32]] }
  stream_plan: |
    StreamMaterialize { columns: [*VALUES*_0.column_0, *VALUES*_0.column_1, _row_id(hidden)], pk_columns: [_row_id], pk_conflict: "no check", watermark_columns: [*VALUES*_0.column_0, *VALUES*_0.column_1] }
    └─StreamValues { rows: [[11:Int32, 22:Int32, 0:Int64], [(33:Int32 + (1:Int32 + 2:Int32)), 44:Int32, 1:Int64]] }
- sql: select * from t
  binder_error: 'Catalog error: table or source not found: t'
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], pk_columns: [t._row_id], pk_conflict: "no check" }
    └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select t2.* from t;
  binder_error: 'Item not found: relation "t2"'
- sql: |
    create table t ();
    select * from t where 1>2 and 1=1 and 3<1 and 4<>1 or 1=1 and 2>=1 and 1<=2;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: true }
      └─BatchScan { table: t, columns: [], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [t._row_id(hidden)], pk_columns: [t._row_id], pk_conflict: "no check" }
    └─StreamFilter { predicate: true }
      └─StreamTableScan { table: t, columns: [t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 int);
    select * from t where v1<1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: (t.v1 < 1:Int32) }
      └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, t._row_id(hidden)], pk_columns: [t._row_id], pk_conflict: "no check" }
    └─StreamFilter { predicate: (t.v1 < 1:Int32) }
      └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- name: test boolean expression common factor extraction
  sql: |
    create table t (v1 Boolean, v2 Boolean, v3 Boolean);
    select * from t where v1 AND v2 AND ((v1 AND v2) OR (v2 AND v3));
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: t.v1 AND t.v2 AND (t.v1 OR t.v3) }
      └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: test boolean expression simplification
  sql: |
    create table t (v1 Boolean, v2 Boolean, v3 Boolean);
    select * from t where v1 AND NOT(v1 OR v2 Or NOT(v1 AND v2 AND true));
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: t.v1 AND Not(t.v1) AND Not(t.v2) AND t.v2 }
      └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: test boolean expression simplification
  sql: |
    create table t (v1 Boolean, v2 Boolean);
    select * from t where (v1 AND v2) OR (v1 AND v2);
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: t.v1 AND t.v2 }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- name: constant folding for IS TRUE, IS FALSE, IS NULL
  sql: |
    create table t(a Boolean);
    select * from t where (NULL IS NULL) IS TRUE AND FALSE IS FALSE AND a;
  logical_plan: |
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: t.a }
      └─LogicalScan { table: t, columns: [t.a, t._row_id] }
- name: constant folding for IS NOT TRUE, IS NOT FALSE
  sql: |
    create table t(a Boolean);
    select * from t where (NULL IS NOT TRUE) IS NOT FALSE AND a IS NOT TRUE;
  logical_plan: |
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: IsNotTrue(t.a) }
      └─LogicalScan { table: t, columns: [t.a, t._row_id] }
- name: constant folding IS NOT NULL
  sql: |
    create table t(a double precision);
    select * from t where (a IS NOT NULL AND 3.14 IS NOT NULL) OR (NULL IS NOT NULL);
  logical_plan: |
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: IsNotNull(t.a) }
      └─LogicalScan { table: t, columns: [t.a, t._row_id] }
- sql: |
    create table t (v1 int, v2 int);
    select v1 from t;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [v1, t._row_id(hidden)], pk_columns: [t._row_id], pk_conflict: "no check" }
    └─StreamTableScan { table: t, columns: [t.v1, t._row_id], pk: [t._row_id], dist: UpstreamHashShard(t._row_id) }
- sql: select 1
  batch_plan: |
    BatchValues { rows: [[1:Int32]] }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select a from t as t2(a);
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    create table t (v1 int, v2 int);
    delete from t;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchDelete { table: t }
      └─BatchExchange { order: [], dist: Single }
        └─BatchScan { table: t, columns: [t.v1, t.v2, t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 int, v2 int);
    delete from t where v1 = 1;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchDelete { table: t }
      └─BatchExchange { order: [], dist: Single }
        └─BatchFilter { predicate: (t.v1 = 1:Int32) }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    select * from generate_series('2'::INT,'10'::INT,'2'::INT);
  batch_plan: |
    BatchTableFunction { Generate(2:Int32, 10:Int32, 2:Int32) }
- sql: |
    select * from unnest(Array[1,2,3]);
  batch_plan: |
    BatchTableFunction { Unnest(ARRAY[1, 2, 3]:List { datatype: Int32 }) }
- sql: |
    select * from unnest(Array[Array[1,2,3], Array[4,5,6]]);
  batch_plan: |
    BatchTableFunction { Unnest(ARRAY[{1,2,3}, {4,5,6}]:List { datatype: List { datatype: Int32 } }) }
- sql: |
    create table t1 (x int);
    select * from t1 where EXISTS(select * where t1.x=1);
  binder_error: 'Bind error: SELECT * with no tables specified is not valid'
- sql: |
    select *;
  binder_error: 'Bind error: SELECT * with no tables specified is not valid'
- sql: |
    select * where x = 1;
  binder_error: 'Bind error: SELECT * with no tables specified is not valid'
- sql: |
    create table t ();
    select * from t;
  logical_plan: |
    LogicalProject { exprs: [] }
    └─LogicalScan { table: t, columns: [t._row_id] }
- name: disallow subquery in values
  sql: |
    values(1, (select 1));
  binder_error: |-
    Feature is not yet implemented: Subquery in VALUES
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: disallow correlated_input_ref in values
  sql: |
    create table t(v1 int);
    select v1 from t where exists (values(v1));
  binder_error: |-
    Feature is not yet implemented: CorrelatedInputRef in VALUES
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 1
  batch_plan: |
    BatchLimit { limit: 1, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchLimit { limit: 1, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 limit 1
  batch_plan: |
    BatchTopN { order: "[t.v1 ASC]", limit: 1, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: "[t.v1 ASC]", limit: 1, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 int, v2 int);
    create materialized view mv(A,b) as select * from t;
    select a, b from mv;
  stream_plan: |
    StreamMaterialize { columns: [a, b, mv.t._row_id(hidden)], pk_columns: [mv.t._row_id], pk_conflict: "no check" }
    └─StreamTableScan { table: mv, columns: [mv.a, mv.b, mv.t._row_id], pk: [mv.t._row_id], dist: UpstreamHashShard(mv.t._row_id) }
- sql: |
    create table t (v1 int, v2 int);
    create materialized view mv(a,b) as select v1+1,v2+1 from t;
    select * from mv;
  stream_plan: |
    StreamMaterialize { columns: [a, b, mv.t._row_id(hidden)], pk_columns: [mv.t._row_id], pk_conflict: "no check" }
    └─StreamTableScan { table: mv, columns: [mv.a, mv.b, mv.t._row_id], pk: [mv.t._row_id], dist: UpstreamHashShard(mv.t._row_id) }
- sql: |
    create table t (id int primary key, col int);
    create index idx on t(col);
    select id from idx;
  stream_plan: |
    StreamMaterialize { columns: [id], pk_columns: [id], pk_conflict: "no check" }
    └─StreamExchange { dist: HashShard(idx.id) }
      └─StreamTableScan { table: idx, columns: [idx.id], pk: [idx.id], dist: SomeShard }
