# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: window function call in expression
  sql: |
    create table t(x int, y int);
    select x + y, y, 2, 1+row_number() over(PARTITION BY y + y ORDER BY x-1), sum(x) over(partition by x * x ORDER BY x-1) from t;
  logical_plan: |-
    LogicalProject { exprs: [(t.x + t.y) as $expr4, t.y, 2:Int32, (1:Int32 + row_number) as $expr5, sum] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY $expr1 ORDER BY $expr2 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.x) OVER(PARTITION BY $expr3 ORDER BY $expr2 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp, (t.y + t.y) as $expr1, (t.x - 1:Int32) as $expr2, (t.x * t.x) as $expr3] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
- id: window function call in ORDER BY
  sql: |
    create table t(x int);
    select * from t order by (row_number() over(PARTITION BY x ORDER BY x));
  logical_plan: |-
    LogicalProject { exprs: [t.x] }
    └─LogicalProject { exprs: [t.x, row_number] }
      └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
          └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
- id: window function call in GROUP BY
  sql: |
    create table t(x int);
    select x from t group by (row_number(x) over());
  binder_error: |
    Failed to bind expression: (row_number(x) OVER ())

    Caused by:
      Invalid input syntax: window functions are not allowed in GROUP BY
- id: window function call in HAVING
  sql: |
    create table t(x int);
    select x from t having (row_number(x) over() > 1);
  binder_error: |
    Failed to bind expression: (row_number(x) OVER () > 1)

    Caused by:
      Invalid input syntax: window functions are not allowed in HAVING
- id: window function call in WHERE
  sql: |
    create table t(x int);
    select x from t where (row_number(x) over() > 1);
  binder_error: |
    Failed to bind expression: (row_number(x) OVER () > 1)

    Caused by:
      Invalid input syntax: window functions are not allowed in WHERE
- id: window function call in FILTER
  sql: |
    create table t(x int);
    select sum(x) filter (where row_number() over () > 1) from t;
  binder_error: |
    Failed to bind expression: sum(x) FILTER (WHERE row_number() OVER () > 1)

    Caused by:
      Invalid input syntax: window functions are not allowed in FILTER
- id: lag without over clause
  sql: |
    create table t(x int);
    select lag(x) from t;
  binder_error: |
    Failed to bind expression: lag(x)

    Caused by:
      function lag(integer) does not exist, do you mean log
- id: lag with empty over clause
  sql: |
    create table t(x int);
    select lag(x) over() from t;
  logical_plan: |-
    LogicalProject { exprs: [first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  batch_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
  stream_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
- id: lead with offset argument and empty over clause
  sql: |
    create table t(x int);
    select lead(x, 2) over() from t;
  logical_plan: |-
    LogicalProject { exprs: [first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(ROWS BETWEEN 2 FOLLOWING AND 2 FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp, 2:Int32] }
        └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  batch_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
  stream_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
- id: lead with non-const offset argument and empty over clause
  sql: |
    create table t(x int);
    select lead(x, x + 1) over() from t;
  binder_error: |
    Failed to bind expression: lead(x, x + 1) OVER ()

    Caused by:
      Feature is not yet implemented: non-const `offset` of `lead` function is not supported yet
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- id: lag with over clause
  sql: |
    create table t(x int, y int);
    select x, y, lag(x) over(PARTITION BY y ORDER BY x) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), lag], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: lag with over clause, ignoring frame definition
  sql: |
    create table t(x int, y int);
    select x, y, lag(x) over(PARTITION BY y ORDER BY x ROWS BETWEEN CURRENT ROW AND 2 FOLLOWING) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), lag], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with empty over clause
  sql: |
    create table t(x int);
    select sum(x) over() from t;
    -- should be optimized to Agg+Join
  logical_plan: |-
    LogicalProject { exprs: [sum] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchNestedLoopJoin { type: Inner, predicate: true, output: [sum(sum(t.x))] }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
    └─BatchSimpleAgg { aggs: [sum(sum(t.x))] }
      └─BatchExchange { order: [], dist: Single }
        └─BatchSimpleAgg { aggs: [sum(t.x)] }
          └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
  stream_error: |-
    Not supported: streaming nested-loop join
    HINT: The non-equal join in the query requires a nested-loop join executor, which could be very expensive to run. Consider rewriting the query to use dynamic filter as a substitute if possible.
    See also: https://docs.risingwave.com/docs/current/sql-pattern-dynamic-filters/
- id: aggregate with over clause, without ORDER BY and frame definition
  sql: |
    create table t(x int, y int, z int, w int);
    select x, y, sum(x) over(partition by y), max(x) over(partition by y), min(w) over(partition by y) from t;
    -- should be optimized to Agg+Join
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, sum, max, min] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING), max(t.x) OVER(PARTITION BY t.y ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING), min(t.w) OVER(PARTITION BY t.y ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y, sum(t.x), max(t.x), min(t.w)] }
      ├─BatchExchange { order: [], dist: HashShard(t.y) }
      │ └─BatchScan { table: t, columns: [t.x, t.y, t.w], distribution: SomeShard }
      └─BatchHashAgg { group_key: [t.y], aggs: [sum(t.x), max(t.x), min(t.w)] }
        └─BatchExchange { order: [], dist: HashShard(t.y) }
          └─BatchScan { table: t, columns: [t.x, t.y, t.w], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, sum, max, min, t._row_id(hidden), t.y(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.y, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y, sum(t.x), max(t.x), min(t.w), t._row_id, t.y] }
        ├─StreamExchange { dist: HashShard(t.y) }
        │ └─StreamShare { id: 1 }
        │   └─StreamTableScan { table: t, columns: [t.x, t.y, t.w, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamProject { exprs: [t.y, sum(t.x), max(t.x), min(t.w)] }
          └─StreamHashAgg { group_key: [t.y], aggs: [sum(t.x), max(t.x), min(t.w), count] }
            └─StreamExchange { dist: HashShard(t.y) }
              └─StreamShare { id: 1 }
                └─StreamTableScan { table: t, columns: [t.x, t.y, t.w, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with over clause, rows frame definition with implicit current row, without ORDER BY
  sql: |
    create table t(x int, y int);
    select x, y, min(x) over(PARTITION BY y ROWS 10 PRECEDING) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, min] }
    └─LogicalOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), min], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with over clause, rows frame definition with between, without ORDER BY
  sql: |
    create table t(x int, y int);
    select x, y, min(x) over(PARTITION BY y ROWS BETWEEN 1 PRECEDING AND 2 FOLLOWING) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, min] }
    └─LogicalOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 1 PRECEDING AND 2 FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 1 PRECEDING AND 2 FOLLOWING)] }
      └─BatchExchange { order: [t.y ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), min], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [min(t.x) OVER(PARTITION BY t.y ROWS BETWEEN 1 PRECEDING AND 2 FOLLOWING)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with over clause, invalid frame definition case 1
  sql: |
    create table t(x int, y int);
    select x, y, min(x) over(PARTITION BY y ROWS UNBOUNDED FOLLOWING) from t;
  binder_error: |
    Failed to bind expression: min(x) OVER (PARTITION BY y ROWS UNBOUNDED FOLLOWING)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: frame start cannot be UNBOUNDED FOLLOWING
- id: aggregate with over clause, invalid frame definition case 2
  sql: |
    create table t(x int, y int);
    select x, y, min(x) over(PARTITION BY y ROWS BETWEEN 1 FOLLOWING AND 2 PRECEDING) from t;
  binder_error: |
    Failed to bind expression: min(x) OVER (PARTITION BY y ROWS BETWEEN 1 FOLLOWING AND 2 PRECEDING)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: frame starting from following row cannot have preceding rows
- id: aggregate with over clause, range frame definition with implicit current row
  sql: |
    create table t(x int, y int);
    select x, y, max(x) over(PARTITION BY y ORDER BY x RANGE 100 PRECEDING) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, max] }
    └─LogicalOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), max], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with over clause, range frame definition with between
  sql: |
    create table t(x int, y int);
    select x, y, max(x) over(PARTITION BY y ORDER BY x RANGE BETWEEN 100 PRECEDING and UNBOUNDED FOLLOWING) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, max] }
    └─LogicalOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), max], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with over clause, unbounded range, with ORDER BY
  sql: |
    create table t(x int, y int);
    select x, y, first_value(x) over(PARTITION BY y ORDER BY x DESC) from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x DESC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x DESC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), first_value], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: more aggregate functions
  sql: |
    create table t(x int, y int, z int, w int);
    select * from (
        SELECT x, y, z, stddev_pop(x - y) OVER (PARTITION BY z order by x) as res0, stddev_samp(x) OVER (PARTITION BY z order by x) as res1 FROM t
    )
    WHERE z > 0 and y > 0 and x > 0 and res0 <= 3.0 and res1 > 1.0;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, $expr4, $expr5] }
    └─LogicalFilter { predicate: (t.z > 0:Int32) AND (t.y > 0:Int32) AND (t.x > 0:Int32) AND ($expr4 <= 3.0:Decimal) AND ($expr5 > 1.0:Decimal) }
      └─LogicalProject { exprs: [t.x, t.y, t.z, Case((count = 0:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Int32::Decimal) / count::Decimal))) as $expr4, Case((count <= 1:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Int32::Decimal) / (count - 1:Int32)::Decimal))) as $expr5] }
        └─LogicalOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr2) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr2) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr3) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp, ((t.x - t.y) * (t.x - t.y)) as $expr1, (t.x - t.y) as $expr2, (t.x * t.x) as $expr3] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, Case((count = 0:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / count::Decimal))) as $expr4, Case((count <= 1:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / (count - 1:Int32)::Decimal))) as $expr5] }
      └─BatchFilter { predicate: (t.y > 0:Int32) AND (t.x > 0:Int32) AND (Case((count = 0:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / count::Decimal))) <= 3.0:Decimal) AND (Case((count <= 1:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / (count - 1:Int32)::Decimal))) > 1.0:Decimal) }
        └─BatchOverWindow { window_functions: [sum($expr2) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr1) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr3) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─BatchExchange { order: [t.z ASC, t.x ASC], dist: HashShard(t.z) }
            └─BatchSort { order: [t.z ASC, t.x ASC] }
              └─BatchProject { exprs: [t.x, t.y, t.z, ($expr1 * $expr1) as $expr2, $expr1, (t.x * t.x) as $expr3] }
                └─BatchProject { exprs: [t.x, t.y, t.z, (t.x - t.y) as $expr1] }
                  └─BatchFilter { predicate: (t.z > 0:Int32) }
                    └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, res0, res1, t._row_id(hidden)], stream_key: [t._row_id, z], pk_columns: [t._row_id, z], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, Case((count = 0:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / count::Decimal))) as $expr4, Case((count <= 1:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / (count - 1:Int32)::Decimal))) as $expr5, t._row_id] }
      └─StreamFilter { predicate: (t.y > 0:Int32) AND (t.x > 0:Int32) AND (Case((count = 0:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / count::Decimal))) <= 3.0:Decimal) AND (Case((count <= 1:Int32), null:Decimal, Sqrt((Greatest((sum::Decimal - ((sum::Decimal * sum::Decimal) / count::Decimal)), 0:Decimal) / (count - 1:Int32)::Decimal))) > 1.0:Decimal) }
        └─StreamOverWindow { window_functions: [sum($expr2) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr1) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum($expr3) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamExchange { dist: HashShard(t.z) }
            └─StreamProject { exprs: [t.x, t.y, t.z, ($expr1 * $expr1) as $expr2, $expr1, (t.x * t.x) as $expr3, t._row_id] }
              └─StreamProject { exprs: [t.x, t.y, t.z, (t.x - t.y) as $expr1, t._row_id] }
                └─StreamFilter { predicate: (t.z > 0:Int32) }
                  └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate with expression in func arguments and over clause
  sql: |
    create table t(x int, y int, z int, w int);
    select * from (
        SELECT x, y, z, avg(z * z) OVER (PARTITION BY y + 1 order by abs(w)) as res FROM t
    )
    WHERE z > 0 and y > 0 and x > 0 and res <= 3.0;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, $expr4] }
    └─LogicalFilter { predicate: (t.z > 0:Int32) AND (t.y > 0:Int32) AND (t.x > 0:Int32) AND ($expr4 <= 3.0:Decimal) }
      └─LogicalProject { exprs: [t.x, t.y, t.z, (sum::Decimal / count::Decimal) as $expr4] }
        └─LogicalOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp, (t.z * t.z) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.w) as $expr3] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t.w, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.x, t.y, t.z, (sum::Decimal / count::Decimal) as $expr4] }
    └─LogicalFilter { predicate: (t.z > 0:Int32) AND (t.y > 0:Int32) AND (t.x > 0:Int32) AND ((sum::Decimal / count::Decimal) <= 3.0:Decimal) }
      └─LogicalOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalProject { exprs: [t.x, t.y, t.z, (t.z * t.z) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.w) as $expr3] }
          └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t.w] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, (sum::Decimal / count::Decimal) as $expr4] }
      └─BatchFilter { predicate: (t.z > 0:Int32) AND (t.y > 0:Int32) AND (t.x > 0:Int32) AND ((sum::Decimal / count::Decimal) <= 3.0:Decimal) }
        └─BatchOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─BatchExchange { order: [$expr2 ASC, $expr3 ASC], dist: HashShard($expr2) }
            └─BatchSort { order: [$expr2 ASC, $expr3 ASC] }
              └─BatchProject { exprs: [t.x, t.y, t.z, (t.z * t.z) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.w) as $expr3] }
                └─BatchScan { table: t, columns: [t.x, t.y, t.z, t.w], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, res, t._row_id(hidden), $expr2(hidden)], stream_key: [t._row_id, $expr2], pk_columns: [t._row_id, $expr2], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, (sum::Decimal / count::Decimal) as $expr4, t._row_id, $expr2] }
      └─StreamFilter { predicate: (t.z > 0:Int32) AND (t.y > 0:Int32) AND (t.x > 0:Int32) AND ((sum::Decimal / count::Decimal) <= 3.0:Decimal) }
        └─StreamOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamExchange { dist: HashShard($expr2) }
            └─StreamProject { exprs: [t.x, t.y, t.z, (t.z * t.z) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.w) as $expr3, t._row_id] }
              └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t.w, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: row_number with empty over clause
  sql: |
    create table t(x int);
    select row_number() over() from t;
  planner_error: 'Invalid input syntax: window rank function without order by: row_number() OVER()'
- id: multiple rank function calls
  sql: |
    create table t(x int);
    select row_number() over(PARTITION BY x ORDER BY x), rank() over(PARTITION BY x ORDER BY x), dense_rank() over (PARTITION BY x ORDER BY x) from t;
  logical_plan: |-
    LogicalProject { exprs: [row_number, rank, dense_rank] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [row_number, rank, dense_rank] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalScan { table: t, columns: [t.x] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [row_number, rank, dense_rank] }
      └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [t.x ASC, t.x ASC], dist: HashShard(t.x) }
          └─BatchSort { order: [t.x ASC, t.x ASC] }
            └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [row_number, rank, dense_rank, t._row_id(hidden), t.x(hidden)], stream_key: [t._row_id, t.x], pk_columns: [t._row_id, t.x], pk_conflict: NoCheck }
    └─StreamProject { exprs: [row_number, rank, dense_rank, t._row_id, t.x] }
      └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: row_number with valid over clause
  sql: |
    create table t(x int, y int);
    select row_number() over (PARTITION BY x ORDER BY y) from t;
  logical_plan: |-
    LogicalProject { exprs: [row_number] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [row_number] }
      └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [t.x ASC, t.y ASC], dist: HashShard(t.x) }
          └─BatchSort { order: [t.x ASC, t.y ASC] }
            └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [row_number, t._row_id(hidden), t.x(hidden)], stream_key: [t._row_id, t.x], pk_columns: [t._row_id, t.x], pk_conflict: NoCheck }
    └─StreamProject { exprs: [row_number, t._row_id, t.x] }
      └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN by row_number with rank output
  sql: |
    create table t(x int);
    select * from
      (select *, row_number() over(PARTITION BY x ORDER BY x) rank from t)
    where rank < 3;
  logical_plan: |-
    LogicalProject { exprs: [t.x, row_number] }
    └─LogicalFilter { predicate: (row_number < 3:Int32) }
      └─LogicalProject { exprs: [t.x, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchSort { order: [t.x ASC, t.x ASC] }
        └─BatchGroupTopN { order: [t.x ASC], limit: 2, offset: 0, group_key: [t.x] }
          └─BatchExchange { order: [], dist: HashShard(t.x) }
            └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, t._row_id(hidden), rank], stream_key: [x, t._row_id], pk_columns: [x, t._row_id], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamGroupTopN { order: [t.x ASC], limit: 2, offset: 0, group_key: [t.x] }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN by row_number without rank output, 1
  sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where rank <= 3;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (row_number <= 3:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 3, offset: 0, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [t.x ASC], limit: 3, offset: 0, group_key: [t.y] }
      └─BatchExchange { order: [], dist: HashShard(t.y) }
        └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [y, t._row_id], pk_columns: [y, t._row_id], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [t.x ASC], limit: 3, offset: 0, group_key: [t.y] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN by row_number without rank output, 2
  sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where rank < 3 AND x > y;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (row_number < 3:Int32) AND (t.x > t.y) }
      └─LogicalProject { exprs: [t.x, t.y, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalFilter { predicate: (t.x > t.y) }
    └─LogicalTopN { order: [t.x ASC], limit: 2, offset: 0, group_key: [t.y] }
      └─LogicalScan { table: t, columns: [t.x, t.y] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: (t.x > t.y) }
      └─BatchGroupTopN { order: [t.x ASC], limit: 2, offset: 0, group_key: [t.y] }
        └─BatchExchange { order: [], dist: HashShard(t.y) }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [y, t._row_id], pk_columns: [y, t._row_id], pk_conflict: NoCheck }
    └─StreamFilter { predicate: (t.x > t.y) }
      └─StreamGroupTopN { order: [t.x ASC], limit: 2, offset: 0, group_key: [t.y] }
        └─StreamExchange { dist: HashShard(t.y) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN by rank without rank output
  sql: |
    create table t(x int, y int);
    select x, y from
      (select *, rank() over(PARTITION BY y ORDER BY x) rank from t)
    where rank <= 3;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (rank <= 3:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, rank] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 3, offset: 0, with_ties: true, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [t.x ASC], limit: 3, offset: 0, with_ties: true, group_key: [t.y] }
      └─BatchExchange { order: [], dist: HashShard(t.y) }
        └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [y, t._row_id], pk_columns: [y, t._row_id], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [t.x ASC], limit: 3, offset: 0, with_ties: true, group_key: [t.y] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN by rank, with offset
  sql: |
    create table t(x int, y int);
    select x, y from
      (select *, rank() over(PARTITION BY y ORDER BY x) rank from t)
    where rank <= 3 AND rank > 1;
    -- OFFSET for RANK() is not yet supported
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (rank <= 3:Int32) AND (rank > 1:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, rank] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y] }
      └─BatchFilter { predicate: (rank <= 3:Int32) AND (rank > 1:Int32) }
        └─BatchOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
            └─BatchSort { order: [t.y ASC, t.x ASC] }
              └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t._row_id] }
      └─StreamFilter { predicate: (rank <= 3:Int32) AND (rank > 1:Int32) }
        └─StreamOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamExchange { dist: HashShard(t.y) }
            └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where rank > 3;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 9223372036854775807, offset: 3, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where rank >= 3;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 9223372036854775807, offset: 2, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 <= rank AND rank <= 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 3, offset: 2, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where rank BETWEEN 3 AND 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 3, offset: 2, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 < rank AND rank <= 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 2, offset: 3, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 <= rank AND rank < 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 2, offset: 2, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 < rank AND rank < 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 1, offset: 3, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 < rank AND rank < 6 AND rank >= 4 AND rank < 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 1, offset: 3, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 < rank AND rank = 4 AND rank <= 5;
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.x ASC], limit: 1, offset: 3, group_key: [t.y] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
- sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY y ORDER BY x) rank from t)
    where 3 < rank AND rank = 6 AND rank <= 5;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (3:Int32 < row_number) AND (row_number = 6:Int32) AND (row_number <= 5:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y] }
      └─BatchFilter { predicate: (3:Int32 < row_number) AND (row_number = 6:Int32) AND (row_number <= 5:Int32) }
        └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
            └─BatchSort { order: [t.y ASC, t.x ASC] }
              └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t._row_id] }
      └─StreamFilter { predicate: (3:Int32 < row_number) AND (row_number = 6:Int32) AND (row_number <= 5:Int32) }
        └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamExchange { dist: HashShard(t.y) }
            └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: Deduplication (Top1) by row_number
  sql: |
    create table t(x int, y int);
    select x, y from
      (select *, row_number() over(PARTITION BY x ORDER BY y) rank from t)
    where rank = 1
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (row_number = 1:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
    └─LogicalScan { table: t, columns: [t.x, t.y] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
      └─BatchExchange { order: [], dist: HashShard(t.x) }
        └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [x], pk_columns: [x], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
      └─StreamExchange { dist: HashShard(t.x) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN with intersected partition key and order key
  sql: |
    create table t (x int, y int, z int);
    SELECT z FROM (
      SELECT *, row_number() over (partition by x,y order by x) as rank FROM t
    )
    WHERE rank <=1;
  logical_plan: |-
    LogicalProject { exprs: [t.z] }
    └─LogicalFilter { predicate: (row_number <= 1:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, t.z, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.z] }
    └─LogicalTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.x, t.y] }
      └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.z] }
      └─BatchGroupTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.x, t.y] }
        └─BatchExchange { order: [], dist: HashShard(t.x, t.y) }
          └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [z, t.x(hidden), t.y(hidden)], stream_key: [t.x, t.y], pk_columns: [t.x, t.y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.z, t.x, t.y] }
      └─StreamGroupTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.x, t.y] }
        └─StreamExchange { dist: HashShard(t.x, t.y) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [z, t.x(hidden), t.y(hidden)], stream_key: [t.x, t.y], pk_columns: [t.x, t.y], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [t.z, t.x, t.y] }
        └── StreamGroupTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.x, t.y] } { tables: [ GroupTopN: 0 ] }
            └── StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
    ├── tables: [ StreamScan: 1 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ t_x, t_y, t_z, t__row_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $0 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 1
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ z, t.x, t.y, _rw_timestamp ], primary key: [ $1 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1, 2 ], read pk prefix len hint: 2 }

- id: TopN among multiple window function calls
  sql: |
    create table t (x int, y int, z int);
    select r1
    from (
      select
        *,
        row_number() over (partition by x order by y) r1,
        row_number() over (partition by x, y order by z) r2,
        rank() over (partition by x, y order by z) r3
      from t
    ) Q
    where Q.r1 < 10 and Q.r2 < 10 and Q.r3 < 10;
  logical_plan: |-
    LogicalProject { exprs: [row_number] }
    └─LogicalFilter { predicate: (row_number < 10:Int32) AND (row_number < 10:Int32) AND (rank < 10:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, t.z, row_number, row_number, rank] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [row_number] }
    └─LogicalFilter { predicate: (row_number < 10:Int32) AND (row_number < 10:Int32) }
      └─LogicalTopN { order: [t.z ASC], limit: 9, offset: 0, with_ties: true, group_key: [t.x, t.y] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [row_number] }
      └─BatchFilter { predicate: (row_number < 10:Int32) AND (row_number < 10:Int32) }
        └─BatchGroupTopN { order: [t.z ASC], limit: 9, offset: 0, with_ties: true, group_key: [t.x, t.y] }
          └─BatchExchange { order: [], dist: HashShard(t.x, t.y) }
            └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchSort { order: [t.x ASC, t.y ASC, t.z ASC] }
                └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                  └─BatchExchange { order: [t.x ASC, t.y ASC], dist: HashShard(t.x) }
                    └─BatchSort { order: [t.x ASC, t.y ASC] }
                      └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [r1, t.x(hidden), t.y(hidden), t._row_id(hidden)], stream_key: [t.x, t.y, t._row_id], pk_columns: [t.x, t.y, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [row_number, t.x, t.y, t._row_id] }
      └─StreamFilter { predicate: (row_number < 10:Int32) AND (row_number < 10:Int32) }
        └─StreamGroupTopN { order: [t.z ASC], limit: 9, offset: 0, with_ties: true, group_key: [t.x, t.y] }
          └─StreamExchange { dist: HashShard(t.x, t.y) }
            └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                └─StreamExchange { dist: HashShard(t.x) }
                  └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: TopN among multiple window function calls, some not TopN
  sql: |
    create table t (x int, y int, z int);
    select r2, r3
    from (
      select
        *,
        row_number() over (partition by x order by y) r1,
        row_number() over (partition by x, y order by z) r2,
        rank() over (partition by x, y order by z) r3
      from t
    ) Q
    where Q.r1 < 10;
  logical_plan: |-
    LogicalProject { exprs: [row_number, rank] }
    └─LogicalFilter { predicate: (row_number < 10:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, t.z, row_number, row_number, rank] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [row_number, rank] }
    └─LogicalFilter { predicate: (row_number < 10:Int32) }
      └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [row_number, rank] }
      └─BatchFilter { predicate: (row_number < 10:Int32) }
        └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─BatchSort { order: [t.x ASC, t.y ASC, t.z ASC] }
            └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [t.x ASC, t.y ASC], dist: HashShard(t.x) }
                └─BatchSort { order: [t.x ASC, t.y ASC] }
                  └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [r2, r3, t._row_id(hidden), t.x(hidden), t.y(hidden)], stream_key: [t._row_id, t.x, t.y], pk_columns: [t._row_id, t.x, t.y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [row_number, rank, t._row_id, t.x, t.y] }
      └─StreamFilter { predicate: (row_number < 10:Int32) }
        └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.x, t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─StreamExchange { dist: HashShard(t.x) }
              └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: test ibis window function optimization
  sql: |
    CREATE TABLE t (a INT, b INT, c INT);
    SELECT a, b, c
    FROM (
      SELECT
        a, b, c,
        ROW_NUMBER() OVER (PARTITION BY a ORDER BY b) - 1 AS rn
      FROM t
    )
    WHERE rn < 10;
  logical_plan: |-
    LogicalProject { exprs: [t.a, t.b, t.c] }
    └─LogicalFilter { predicate: ($expr1 < 10:Int32) }
      └─LogicalProject { exprs: [t.a, t.b, t.c, (row_number - 1:Int32) as $expr1] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.b ASC], limit: 10, offset: 0, group_key: [t.a] }
    └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  optimized_logical_plan_for_stream: |-
    LogicalTopN { order: [t.b ASC], limit: 10, offset: 0, group_key: [t.a] }
    └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- name: test arithmetic with addition
  sql: |
    CREATE TABLE t (a INT, b INT, c INT);
    SELECT a, b, c
    FROM (
      SELECT
        a, b, c,
        ROW_NUMBER() OVER (PARTITION BY a ORDER BY b) + 5 AS rn_plus_five
      FROM t
    )
    WHERE rn_plus_five = 6;
  logical_plan: |-
    LogicalProject { exprs: [t.a, t.b, t.c] }
    └─LogicalFilter { predicate: ($expr1 = 6:Int32) }
      └─LogicalProject { exprs: [t.a, t.b, t.c, (row_number + 5:Int32) as $expr1] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [t.b ASC], limit: 1, offset: 0, group_key: [t.a] }
    └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  optimized_logical_plan_for_stream: |-
    LogicalTopN { order: [t.b ASC], limit: 1, offset: 0, group_key: [t.a] }
    └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- name: test optimization when rn column is kept
  sql: |
    CREATE TABLE t (a INT, b INT, c INT);
    SELECT a, b, c, rn_plus_one
    FROM (
      SELECT
        a, b, c,
        ROW_NUMBER() OVER (PARTITION BY a ORDER BY b) + 1 AS rn_plus_one
      FROM t
    )
    WHERE rn_plus_one = 2;
  logical_plan: |-
    LogicalProject { exprs: [t.a, t.b, t.c, $expr1] }
    └─LogicalFilter { predicate: ($expr1 = 2:Int32) }
      └─LogicalProject { exprs: [t.a, t.b, t.c, (row_number + 1:Int32) as $expr1] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.a, t.b, t.c, (row_number + 1:Int32) as $expr1] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalTopN { order: [t.b ASC], limit: 1, offset: 0, group_key: [t.a] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [t.a, t.b, t.c, (row_number + 1:Int32) as $expr1] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalTopN { order: [t.b ASC], limit: 1, offset: 0, group_key: [t.a] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- name: test complex arithmetic not optimized
  sql: |
    CREATE TABLE t (a INT, b INT, c INT);
    SELECT a, b, c, rn
    FROM (
      SELECT
        a, b, c,
        ROW_NUMBER() OVER (PARTITION BY a ORDER BY b) * 2 + 1 AS rn
      FROM t
    )
    WHERE rn = 3;
  logical_plan: |-
    LogicalProject { exprs: [t.a, t.b, t.c, $expr1] }
    └─LogicalFilter { predicate: ($expr1 = 3:Int32) }
      └─LogicalProject { exprs: [t.a, t.b, t.c, ((row_number * 2:Int32) + 1:Int32) as $expr1] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.a, t.b, t.c, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.a, t.b, t.c, ((row_number * 2:Int32) + 1:Int32) as $expr1] }
    └─LogicalFilter { predicate: (((row_number * 2:Int32) + 1:Int32) = 3:Int32) }
      └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [t.a, t.b, t.c, ((row_number * 2:Int32) + 1:Int32) as $expr1] }
    └─LogicalFilter { predicate: (((row_number * 2:Int32) + 1:Int32) = 3:Int32) }
      └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalScan { table: t, columns: [t.a, t.b, t.c] }
- id: create_bid
  sql: |
    /*
    The following example is adapted from
    https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/dev/table/sql/queries/window-topn/

    Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
    with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.
    */
    CREATE TABLE bid (
      "bidtime" TIMESTAMP,
      "price" BIGINT,
      "item" VARCHAR,
      "supplier_id" VARCHAR
    );
- before:
  - create_bid
  sql: |
    -- Window Top-N which follows after Window Aggregation
    -- Top 3 suppliers who have the highest sales for every tumbling 10 minutes window.
    SELECT window_start, window_end, supplier_id, price, cnt
    FROM (
      SELECT *, ROW_NUMBER() OVER (PARTITION BY window_start, window_end ORDER BY price DESC) as rownum
      FROM (
        SELECT window_start, window_end, supplier_id, SUM(price) as price, COUNT(*) as cnt
        FROM
          TUMBLE(Bid, bidtime, INTERVAL '10' MINUTE)
        GROUP BY window_start, window_end, supplier_id
      )
    ) WHERE rownum <= 3;
  stream_plan: |-
    StreamMaterialize { columns: [window_start, window_end, supplier_id, price, cnt], stream_key: [window_start, window_end, supplier_id], pk_columns: [window_start, window_end, supplier_id], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [sum(bid.price) DESC], limit: 3, offset: 0, group_key: [$expr1, $expr2] }
      └─StreamExchange { dist: HashShard($expr1, $expr2) }
        └─StreamHashAgg { group_key: [$expr1, $expr2, bid.supplier_id], aggs: [sum(bid.price), count] }
          └─StreamExchange { dist: HashShard($expr1, $expr2, bid.supplier_id) }
            └─StreamProject { exprs: [$expr1, ($expr1 + '00:10:00':Interval) as $expr2, bid.supplier_id, bid.price, bid._row_id] }
              └─StreamProject { exprs: [bid.bidtime, bid.price, bid.supplier_id, TumbleStart(bid.bidtime, '00:10:00':Interval) as $expr1, bid._row_id] }
                └─StreamTableScan { table: bid, columns: [bid.bidtime, bid.price, bid.supplier_id, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
- before:
  - create_bid
  sql: |
    -- Window Top-N follows directly after Window TVF
    -- Top 3 items which have the highest price for every tumbling 10 minutes window.
    SELECT window_start, window_end, supplier_id, price
    FROM (
      SELECT *, ROW_NUMBER() OVER (PARTITION BY window_start, window_end ORDER BY price DESC) as rownum
        FROM
          TUMBLE(Bid, bidtime, INTERVAL '10' MINUTE)
    ) WHERE rownum <= 3;
  stream_plan: |-
    StreamMaterialize { columns: [window_start, window_end, supplier_id, price, bid._row_id(hidden)], stream_key: [window_start, window_end, bid._row_id], pk_columns: [window_start, window_end, bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [$expr1, $expr2, bid.supplier_id, bid.price, bid._row_id] }
      └─StreamGroupTopN { order: [bid.price DESC], limit: 3, offset: 0, group_key: [$expr1, $expr2] }
        └─StreamExchange { dist: HashShard($expr1, $expr2) }
          └─StreamProject { exprs: [bid.price, bid.supplier_id, $expr1, ($expr1 + '00:10:00':Interval) as $expr2, bid._row_id] }
            └─StreamProject { exprs: [bid.bidtime, bid.price, bid.supplier_id, TumbleStart(bid.bidtime, '00:10:00':Interval) as $expr1, bid._row_id] }
              └─StreamTableScan { table: bid, columns: [bid.bidtime, bid.price, bid.supplier_id, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
- id: cte1
  sql: |
    create table t (x int, y int, z int);
    with cte as (
      SELECT x, y, z FROM (
        SELECT *, row_number() OVER (PARTITION BY x ORDER BY y) AS rank FROM t
      ) WHERE rank <= 3
    ) select z from cte;
  logical_plan: |-
    LogicalProject { exprs: [t.z] }
    └─LogicalShare { id: 6 }
      └─LogicalProject { exprs: [t.x, t.y, t.z] }
        └─LogicalFilter { predicate: (row_number <= 3:Int32) }
          └─LogicalProject { exprs: [t.x, t.y, t.z, row_number] }
            └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
                └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.z] }
      └─BatchGroupTopN { order: [t.y ASC], limit: 3, offset: 0, group_key: [t.x] }
        └─BatchExchange { order: [], dist: HashShard(t.x) }
          └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [z, t.x(hidden), t._row_id(hidden)], stream_key: [t.x, t._row_id], pk_columns: [t.x, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.z, t.x, t._row_id] }
      └─StreamGroupTopN { order: [t.y ASC], limit: 3, offset: 0, group_key: [t.x] }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: cte2
  sql: |
    create table t (x int, y int, z int);
    with cte as (
      select x, z from (
          select x, y, z, row_number() over (partition by x order by y) as rank from t
      ) t
      where rank = 1
    )
    select t1.x as t1x, t2.x as t2x, t1.z as t1z, t2.y as t2y, t2.z as t2z from cte t1
    inner join t t2
    on t1.x = t2.x;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.x, t.z, t.y, t.z] }
    └─LogicalJoin { type: Inner, on: (t.x = t.x), output: all }
      ├─LogicalShare { id: 6 }
      │ └─LogicalProject { exprs: [t.x, t.z] }
      │   └─LogicalFilter { predicate: (row_number = 1:Int32) }
      │     └─LogicalProject { exprs: [t.x, t.y, t.z, row_number] }
      │       └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      │         └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
      │           └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
      └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.x = t.x, output: [t.x, t.x, t.z, t.y, t.z] }
      ├─BatchGroupTopN { order: [t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
      │ └─BatchExchange { order: [], dist: HashShard(t.x) }
      │   └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t.x) }
        └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [t1x, t2x, t1z, t2y, t2z, t._row_id(hidden)], stream_key: [t1x, t._row_id], pk_columns: [t1x, t._row_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.x, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.x = t.x, output: [t.x, t.x, t.z, t.y, t.z, t._row_id] }
        ├─StreamGroupTopN { order: [t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
        │ └─StreamExchange { dist: HashShard(t.x) }
        │   └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: split calls with different ORDER BY or PARTITION BY
  sql: |
    create table t(x int, y int, z int);
    select *, rank() over(PARTITION BY x ORDER BY y) w0, sum(x) over(PARTITION BY z ORDER BY y) w1, row_number() over(PARTITION BY x ORDER BY y) w2, rank() over(PARTITION BY y ORDER BY x) w3 from t;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, rank, sum, row_number, rank] }
    └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.x) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  optimized_logical_plan_for_stream: |-
    LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─BatchExchange { order: [t.x ASC, t.y ASC], dist: HashShard(t.x) }
              └─BatchSort { order: [t.x ASC, t.y ASC] }
                └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                  └─BatchExchange { order: [t.z ASC, t.y ASC], dist: HashShard(t.z) }
                    └─BatchSort { order: [t.z ASC, t.y ASC] }
                      └─BatchOverWindow { window_functions: [rank() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                        └─BatchExchange { order: [t.x ASC, t.y ASC], dist: HashShard(t.x) }
                          └─BatchSort { order: [t.x ASC, t.y ASC] }
                            └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, t._row_id(hidden), w0, w1, w2, w3], stream_key: [t._row_id, x, z, y], pk_columns: [t._row_id, x, z, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─StreamExchange { dist: HashShard(t.x) }
            └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─StreamExchange { dist: HashShard(t.z) }
                └─StreamOverWindow { window_functions: [rank() OVER(PARTITION BY t.x ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                  └─StreamExchange { dist: HashShard(t.x) }
                    └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (id int, cat varchar, rule varchar, at timestamptz);
    select * from (select cat, rule, at, lag(rule) over (partition by cat order by at) as prev_rule from t) as with_prev
    where rule = 'B' and cat is not null and at = '2023-11-23T12:00:42Z'::timestamptz;
  optimized_logical_plan_for_batch: |-
    LogicalFilter { predicate: (t.rule = 'B':Varchar) AND (t.at = '2023-11-23 12:00:42+00:00':Timestamptz) }
    └─LogicalOverWindow { window_functions: [first_value(t.rule) OVER(PARTITION BY t.cat ORDER BY t.at ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalScan { table: t, columns: [t.cat, t.rule, t.at], predicate: IsNotNull(t.cat) }
  optimized_logical_plan_for_stream: |-
    LogicalFilter { predicate: (t.rule = 'B':Varchar) AND (t.at = '2023-11-23 12:00:42+00:00':Timestamptz) }
    └─LogicalOverWindow { window_functions: [first_value(t.rule) OVER(PARTITION BY t.cat ORDER BY t.at ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalScan { table: t, columns: [t.cat, t.rule, t.at], predicate: IsNotNull(t.cat) }
- sql: |
    create table t (id int, cat varchar, rule varchar, at timestamptz);
    select cat, rule, at, lag(rule) over (partition by cat order by at) as prev_rule from t
    where rule = 'B' and cat is not null and at = '2023-11-23T12:00:42Z'::timestamptz;
  optimized_logical_plan_for_batch: |-
    LogicalOverWindow { window_functions: [first_value(t.rule) OVER(PARTITION BY t.cat ORDER BY t.at ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
    └─LogicalScan { table: t, columns: [t.cat, t.rule, t.at], predicate: (t.rule = 'B':Varchar) AND IsNotNull(t.cat) AND (t.at = '2023-11-23 12:00:42+00:00':Timestamptz) }
  optimized_logical_plan_for_stream: |-
    LogicalOverWindow { window_functions: [first_value(t.rule) OVER(PARTITION BY t.cat ORDER BY t.at ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
    └─LogicalScan { table: t, columns: [t.cat, t.rule, t.at], predicate: (t.rule = 'B':Varchar) AND IsNotNull(t.cat) AND (t.at = '2023-11-23 12:00:42+00:00':Timestamptz) }
- sql: |
    create table t (a int, b int, c int);
    select
        count(*) over (partition by 1::int order by b rows between 1 preceding and 10 preceding)
    from t;
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.b ASC ROWS BETWEEN 1 PRECEDING AND 10 PRECEDING)] }
      └─LogicalProject { exprs: [t.b, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.b] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.b ASC ROWS BETWEEN 1 PRECEDING AND 10 PRECEDING)] }
      └─LogicalProject { exprs: [t.b, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.b] }
- sql: |
    create table t (a int, b int, c int);
    select
        count(*) over (partition by 1::int order by b rows between 1 following and current row)
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY b ROWS BETWEEN 1 FOLLOWING AND CURRENT ROW)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: frame starting from following row cannot have preceding rows
- sql: |
    create table t (a int, b int, c int);
    select
        count(*) over (partition by 1::int order by b rows between 1 following and 1 preceding)
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY b ROWS BETWEEN 1 FOLLOWING AND 1 PRECEDING)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: frame starting from following row cannot have preceding rows
- sql: |
    create table t (a int, b int, c int);
    select
        count(*) over (partition by 1::int order by b rows between current row and 1 preceding)
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY b ROWS BETWEEN CURRENT ROW AND 1 PRECEDING)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: frame starting from current row cannot have preceding rows
- sql: |
    create table t (a int, b int, c int);
    select
        count(*) over (partition by 1::int order by b rows between 10 following and 1 following)
    from t;
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.b ASC ROWS BETWEEN 10 FOLLOWING AND 1 FOLLOWING)] }
      └─LogicalProject { exprs: [t.b, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.b] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.b ASC ROWS BETWEEN 10 FOLLOWING AND 1 FOLLOWING)] }
      └─LogicalProject { exprs: [t.b, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.b] }
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by i range 1 preceding) as col1,
        count(*) over (partition by 1::int order by bi range 1 preceding) as col2,
        count(*) over (partition by 1::int order by d range 1.5 preceding) as col3,
        count(*) over (partition by 1::int order by f range 1.5 preceding) as col4,
        -- count(*) over (partition by 1::int order by da range '1 day' preceding) as col5, -- `date` not supported yet
        -- count(*) over (partition by 1::int order by t range '1 min' preceding) as col6, -- `time` not supported yet
        count(*) over (partition by 1::int order by ts range '1 day 1 hour' preceding) as col7,
        count(*) over (partition by 1::int order by tstz range '1 min' preceding) as col8
    from t;
  logical_plan: |-
    LogicalProject { exprs: [count, count, count, count, count, count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.i ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY 1:Int32 ORDER BY t.bi ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY 1:Int32 ORDER BY t.d ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY 1:Int32 ORDER BY t.f ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC RANGE BETWEEN 1 day 01:00:00 PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY 1:Int32 ORDER BY t.tstz ASC RANGE BETWEEN 00:01:00 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.i, t.bi, t.d, t.f, t.da, t.t, t.ts, t.tstz, t.itv, t._row_id, t._rw_timestamp, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.da, t.t, t.ts, t.tstz, t.itv, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [count, count, count, count, count, count] }
    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.tstz ASC RANGE BETWEEN 00:01:00 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.tstz, 1:Int32, count, count, count, count, count] }
        └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC RANGE BETWEEN 1 day 01:00:00 PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.ts, t.tstz, 1:Int32, count, count, count, count] }
            └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.f ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
              └─LogicalProject { exprs: [t.f, t.ts, t.tstz, 1:Int32, count, count, count] }
                └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.d ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
                  └─LogicalProject { exprs: [t.d, t.f, t.ts, t.tstz, 1:Int32, count, count] }
                    └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.bi ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                      └─LogicalProject { exprs: [t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32, count] }
                        └─LogicalOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.i ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                          └─LogicalProject { exprs: [t.i, t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32] }
                            └─LogicalScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.ts, t.tstz] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [count, count, count, count, count, count] }
      └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.tstz ASC RANGE BETWEEN 00:01:00 PRECEDING AND CURRENT ROW)] }
        └─BatchSort { order: [1:Int32 ASC, t.tstz ASC] }
          └─BatchProject { exprs: [t.tstz, 1:Int32, count, count, count, count, count] }
            └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC RANGE BETWEEN 1 day 01:00:00 PRECEDING AND CURRENT ROW)] }
              └─BatchSort { order: [1:Int32 ASC, t.ts ASC] }
                └─BatchProject { exprs: [t.ts, t.tstz, 1:Int32, count, count, count, count] }
                  └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.f ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
                    └─BatchSort { order: [1:Int32 ASC, t.f ASC] }
                      └─BatchProject { exprs: [t.f, t.ts, t.tstz, 1:Int32, count, count, count] }
                        └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.d ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
                          └─BatchSort { order: [1:Int32 ASC, t.d ASC] }
                            └─BatchProject { exprs: [t.d, t.f, t.ts, t.tstz, 1:Int32, count, count] }
                              └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.bi ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                                └─BatchSort { order: [1:Int32 ASC, t.bi ASC] }
                                  └─BatchProject { exprs: [t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32, count] }
                                    └─BatchOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.i ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                                      └─BatchExchange { order: [1:Int32 ASC, t.i ASC], dist: HashShard(1:Int32) }
                                        └─BatchSort { order: [1:Int32 ASC, t.i ASC] }
                                          └─BatchProject { exprs: [t.i, t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32] }
                                            └─BatchScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.ts, t.tstz], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [col1, col2, col3, col4, col7, col8, t._row_id(hidden), 1:Int32(hidden)], stream_key: [t._row_id, 1:Int32], pk_columns: [t._row_id, 1:Int32], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, count, count, count, count, count, t._row_id, 1:Int32] }
      └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.tstz ASC RANGE BETWEEN 00:01:00 PRECEDING AND CURRENT ROW)] }
        └─StreamProject { exprs: [t.tstz, 1:Int32, count, count, count, count, count, t._row_id] }
          └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC RANGE BETWEEN 1 day 01:00:00 PRECEDING AND CURRENT ROW)] }
            └─StreamProject { exprs: [t.ts, t.tstz, 1:Int32, count, count, count, count, t._row_id] }
              └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.f ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
                └─StreamProject { exprs: [t.f, t.ts, t.tstz, 1:Int32, count, count, count, t._row_id] }
                  └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.d ASC RANGE BETWEEN 1.5 PRECEDING AND CURRENT ROW)] }
                    └─StreamProject { exprs: [t.d, t.f, t.ts, t.tstz, 1:Int32, count, count, t._row_id] }
                      └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.bi ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                        └─StreamProject { exprs: [t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32, count, t._row_id] }
                          └─StreamOverWindow { window_functions: [count() OVER(PARTITION BY 1:Int32 ORDER BY t.i ASC RANGE BETWEEN 1 PRECEDING AND CURRENT ROW)] }
                            └─StreamExchange { dist: HashShard(1:Int32) }
                              └─StreamProject { exprs: [t.i, t.bi, t.d, t.f, t.ts, t.tstz, 1:Int32, t._row_id] }
                                └─StreamTableScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.ts, t.tstz, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by da range '1 day' preceding) -- `date` not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY da RANGE '1 day' PRECEDING)

    Caused by:
      Feature is not yet implemented: `RANGE` frame with offset of type `date` is not implemented yet, please manually cast the `ORDER BY` column to `timestamp`
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by t range '1 min' preceding) -- `time` not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY t RANGE '1 min' PRECEDING)

    Caused by:
      Feature is not yet implemented: `RANGE` frame with offset of type `time without time zone` is not implemented yet, please manually cast the `ORDER BY` column to `timestamp`
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by tstz range '1 day 1 hour' preceding) -- `timestamptz` +/- 'x month x day' not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY tstz RANGE '1 day 1 hour' PRECEDING)

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: for frame order column of type `timestamptz`, offset should not have non-zero `month` and `day`
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        first_value(i) over (partition by bi order by i session with gap 10) as col1,
        first_value(bi) over (partition by i order by bi session with gap 10) as col2,
        first_value(i) over (partition by bi order by d session with gap 1.5) as col3,
        first_value(i) over (partition by bi order by f session with gap 1.5) as col4,
        -- first_value(i) over (partition by bi order by da session with gap '1 day') as col5, -- `date` not supported yet
        -- first_value(i) over (partition by bi order by t session with gap '1 min') as col6, -- `time` not supported yet
        first_value(i) over (partition by bi order by ts session with gap '1 day 1 hour') as col7,
        first_value(i) over (partition by bi order by tstz session with gap '1 min') as col8
    from t;
  logical_plan: |-
    LogicalProject { exprs: [first_value, first_value, first_value, first_value, first_value, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.i ASC SESSION WITH GAP 10), first_value(t.bi) OVER(PARTITION BY t.i ORDER BY t.bi ASC SESSION WITH GAP 10), first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.d ASC SESSION WITH GAP 1.5), first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.f ASC SESSION WITH GAP 1.5), first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 1 day 01:00:00), first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.tstz ASC SESSION WITH GAP 00:01:00)] }
      └─LogicalProject { exprs: [t.i, t.bi, t.d, t.f, t.da, t.t, t.ts, t.tstz, t.itv, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.da, t.t, t.ts, t.tstz, t.itv, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [first_value, first_value, first_value, first_value, first_value, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.tstz ASC SESSION WITH GAP 00:01:00)] }
      └─LogicalProject { exprs: [t.i, t.bi, t.tstz, first_value, first_value, first_value, first_value, first_value] }
        └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 1 day 01:00:00)] }
          └─LogicalProject { exprs: [t.i, t.bi, t.ts, t.tstz, first_value, first_value, first_value, first_value] }
            └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.f ASC SESSION WITH GAP 1.5)] }
              └─LogicalProject { exprs: [t.i, t.bi, t.f, t.ts, t.tstz, first_value, first_value, first_value] }
                └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.d ASC SESSION WITH GAP 1.5)] }
                  └─LogicalOverWindow { window_functions: [first_value(t.bi) OVER(PARTITION BY t.i ORDER BY t.bi ASC SESSION WITH GAP 10)] }
                    └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.i ASC SESSION WITH GAP 10)] }
                      └─LogicalScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.ts, t.tstz] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [first_value, first_value, first_value, first_value, first_value, first_value] }
      └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.tstz ASC SESSION WITH GAP 00:01:00)] }
        └─BatchSort { order: [t.bi ASC, t.tstz ASC] }
          └─BatchProject { exprs: [t.i, t.bi, t.tstz, first_value, first_value, first_value, first_value, first_value] }
            └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 1 day 01:00:00)] }
              └─BatchSort { order: [t.bi ASC, t.ts ASC] }
                └─BatchProject { exprs: [t.i, t.bi, t.ts, t.tstz, first_value, first_value, first_value, first_value] }
                  └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.f ASC SESSION WITH GAP 1.5)] }
                    └─BatchSort { order: [t.bi ASC, t.f ASC] }
                      └─BatchProject { exprs: [t.i, t.bi, t.f, t.ts, t.tstz, first_value, first_value, first_value] }
                        └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.d ASC SESSION WITH GAP 1.5)] }
                          └─BatchExchange { order: [t.bi ASC, t.d ASC], dist: HashShard(t.bi) }
                            └─BatchSort { order: [t.bi ASC, t.d ASC] }
                              └─BatchOverWindow { window_functions: [first_value(t.bi) OVER(PARTITION BY t.i ORDER BY t.bi ASC SESSION WITH GAP 10)] }
                                └─BatchExchange { order: [t.i ASC, t.bi ASC], dist: HashShard(t.i) }
                                  └─BatchSort { order: [t.i ASC, t.bi ASC] }
                                    └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.i ASC SESSION WITH GAP 10)] }
                                      └─BatchExchange { order: [t.bi ASC, t.i ASC], dist: HashShard(t.bi) }
                                        └─BatchSort { order: [t.bi ASC, t.i ASC] }
                                          └─BatchScan { table: t, columns: [t.i, t.bi, t.d, t.f, t.ts, t.tstz], distribution: SomeShard }
  stream_error: |-
    Feature is not yet implemented: Session frame is not yet supported in general streaming mode. Please consider using Emit-On-Window-Close mode.
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (i int, bi bigint, ts timestamp, watermark for ts as ts - interval '1 minute') append only;
    select
        first_value(i) over (partition by bi order by ts session with gap '10 minutes') as window_start,
        last_value(i) over (partition by bi order by ts session with gap '10 minutes') as window_end
    from t;
  logical_plan: |-
    LogicalProject { exprs: [first_value, last_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00), last_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00)] }
      └─LogicalProject { exprs: [t.i, t.bi, t.ts, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.i, t.bi, t.ts, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [first_value, last_value] }
      └─BatchOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00), last_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00)] }
        └─BatchExchange { order: [t.bi ASC, t.ts ASC], dist: HashShard(t.bi) }
          └─BatchSort { order: [t.bi ASC, t.ts ASC] }
            └─BatchScan { table: t, columns: [t.i, t.bi, t.ts], distribution: SomeShard }
  eowc_stream_plan: |-
    StreamMaterialize { columns: [window_start, window_end, t._row_id(hidden), t.bi(hidden)], stream_key: [t._row_id, t.bi], pk_columns: [t._row_id, t.bi], pk_conflict: NoCheck }
    └─StreamProject { exprs: [first_value, last_value, t._row_id, t.bi] }
      └─StreamEowcOverWindow { window_functions: [first_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00), last_value(t.i) OVER(PARTITION BY t.bi ORDER BY t.ts ASC SESSION WITH GAP 00:10:00)] }
        └─StreamEowcSort { sort_column: t.ts }
          └─StreamExchange { dist: HashShard(t.bi) }
            └─StreamTableScan { table: t, columns: [t.i, t.bi, t.ts, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by da session with gap '1 day') -- `date` not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY da SESSION WITH GAP '1 day')

    Caused by:
      Feature is not yet implemented: `SESSION` frame with offset of type `date` is not implemented yet, please manually cast the `ORDER BY` column to `timestamp`
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by t session with gap '1 min') -- `time` not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY t SESSION WITH GAP '1 min')

    Caused by:
      Feature is not yet implemented: `SESSION` frame with offset of type `time without time zone` is not implemented yet, please manually cast the `ORDER BY` column to `timestamp`
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (i int, bi bigint, d decimal, f float, da date, t time, ts timestamp, tstz timestamptz, itv interval);
    select
        count(*) over (partition by 1::int order by tstz session with gap '1 day 1 hour') -- `timestamptz` +/- 'x month x day' not supported yet
    from t;
  binder_error: |
    Failed to bind expression: count(*) OVER (PARTITION BY CAST(1 AS INT) ORDER BY tstz SESSION WITH GAP '1 day 1 hour')

    Caused by these errors (recent errors listed first):
      1: Expr error
      2: for session order column of type `timestamptz`, gap should not have non-zero `month` and `day`
- sql: |
    create table t (ts timestamptz, val int);
    select
      first_value(val ignore nulls) over (partition by 1::int order by ts)
    from t;
  logical_plan: |-
    LogicalProject { exprs: [first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.ts, t.val, t._row_id, t._rw_timestamp, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.ts, t.val, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [first_value] }
      └─BatchOverWindow { window_functions: [first_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [1:Int32 ASC, t.ts ASC], dist: HashShard(1:Int32) }
          └─BatchSort { order: [1:Int32 ASC, t.ts ASC] }
            └─BatchProject { exprs: [t.ts, t.val, 1:Int32] }
              └─BatchScan { table: t, columns: [t.ts, t.val], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [first_value, t._row_id(hidden), 1:Int32(hidden)], stream_key: [t._row_id, 1:Int32], pk_columns: [t._row_id, 1:Int32], pk_conflict: NoCheck }
    └─StreamProject { exprs: [first_value, t._row_id, 1:Int32] }
      └─StreamOverWindow { window_functions: [first_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(1:Int32) }
          └─StreamProject { exprs: [t.ts, t.val, 1:Int32, t._row_id] }
            └─StreamTableScan { table: t, columns: [t.ts, t.val, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (ts timestamptz, val int);
    select
      last_value(val ignore nulls) over (partition by 1::int order by ts rows between 1 preceding and 1 following)
    from t;
  logical_plan: |-
    LogicalProject { exprs: [last_value] }
    └─LogicalOverWindow { window_functions: [last_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)] }
      └─LogicalProject { exprs: [t.ts, t.val, t._row_id, t._rw_timestamp, 1:Int32] }
        └─LogicalScan { table: t, columns: [t.ts, t.val, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [last_value] }
      └─BatchOverWindow { window_functions: [last_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)] }
        └─BatchExchange { order: [1:Int32 ASC, t.ts ASC], dist: HashShard(1:Int32) }
          └─BatchSort { order: [1:Int32 ASC, t.ts ASC] }
            └─BatchProject { exprs: [t.ts, t.val, 1:Int32] }
              └─BatchScan { table: t, columns: [t.ts, t.val], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [last_value, t._row_id(hidden), 1:Int32(hidden)], stream_key: [t._row_id, 1:Int32], pk_columns: [t._row_id, 1:Int32], pk_conflict: NoCheck }
    └─StreamProject { exprs: [last_value, t._row_id, 1:Int32] }
      └─StreamOverWindow { window_functions: [last_value(t.val IGNORE NULLS) OVER(PARTITION BY 1:Int32 ORDER BY t.ts ASC ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)] }
        └─StreamExchange { dist: HashShard(1:Int32) }
          └─StreamProject { exprs: [t.ts, t.val, 1:Int32, t._row_id] }
            └─StreamTableScan { table: t, columns: [t.ts, t.val, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (ts timestamptz, val int);
    select
      first_value(val) filter (where val is not null) over (partition by 1::int order by ts) -- not supported yet
    from t;
  binder_error: |
    Failed to bind expression: first_value(val) FILTER (WHERE val IS NOT NULL) OVER (PARTITION BY CAST(1 AS INT) ORDER BY ts)

    Caused by:
      Feature is not yet implemented: `FILTER` is not supported yet
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (ts timestamptz, val int);
    select
      last_value(val) filter (where val is not null) over (partition by 1::int order by ts) -- not supported yet
    from t;
  binder_error: |
    Failed to bind expression: last_value(val) FILTER (WHERE val IS NOT NULL) OVER (PARTITION BY CAST(1 AS INT) ORDER BY ts)

    Caused by:
      Feature is not yet implemented: `FILTER` is not supported yet
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (ts timestamptz, val int);
    select
      lag(val ignore nulls) over (partition by 1::int order by ts) -- not supported yet
    from t;
  binder_error: |
    Failed to bind expression: lag(val IGNORE NULLS) OVER (PARTITION BY CAST(1 AS INT) ORDER BY ts)

    Caused by:
      Feature is not yet implemented: `IGNORE NULLS` is not supported for `lag` yet
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (ts timestamptz, val int);
    select
      lead(val ignore nulls) over (partition by 1::int order by ts) -- not supported yet
    from t;
  binder_error: |
    Failed to bind expression: lead(val IGNORE NULLS) OVER (PARTITION BY CAST(1 AS INT) ORDER BY ts)

    Caused by:
      Feature is not yet implemented: `IGNORE NULLS` is not supported for `lead` yet
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
