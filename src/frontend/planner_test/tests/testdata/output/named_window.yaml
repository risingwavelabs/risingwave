# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: simple named window
  sql: |
    create table t(x int, y int);
    select x, y, sum(x) over w from t window w as (partition by y);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, sum] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y, sum(t.x)] }
      ├─BatchExchange { order: [], dist: HashShard(t.y) }
      │ └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
      └─BatchHashAgg { group_key: [t.y], aggs: [sum(t.x)] }
        └─BatchExchange { order: [], dist: HashShard(t.y) }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, sum, t._row_id(hidden), t.y(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.y, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y, sum(t.x), t._row_id, t.y] }
        ├─StreamExchange { dist: HashShard(t.y) }
        │ └─StreamShare { id: 1 }
        │   └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamProject { exprs: [t.y, sum(t.x)] }
          └─StreamHashAgg { group_key: [t.y], aggs: [sum(t.x), count] }
            └─StreamExchange { dist: HashShard(t.y) }
              └─StreamShare { id: 1 }
                └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window with order by
  sql: |
    create table t(x int, y int);
    select x, y, row_number() over w from t window w as (partition by y order by x);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, row_number] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), row_number], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window with frame specification
  sql: |
    create table t(x int, y int);
    select x, y, sum(x) over w from t window w as (partition by y order by x rows between 1 preceding and current row);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, sum] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), sum], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: multiple named windows
  sql: |
    create table t(x int, y int, z int);
    select x, y, z, sum(x) over w1, avg(y) over w2
    from t
    window w1 as (partition by y order by x),
           w2 as (partition by z order by y);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1] }
      └─BatchOverWindow { window_functions: [sum(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [t.z ASC, t.y ASC], dist: HashShard(t.z) }
          └─BatchSort { order: [t.z ASC, t.y ASC] }
            └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
                └─BatchSort { order: [t.y ASC, t.x ASC] }
                  └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, sum, avg, t._row_id(hidden)], stream_key: [t._row_id, y, z], pk_columns: [t._row_id, y, z], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, t._row_id] }
      └─StreamOverWindow { window_functions: [sum(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.y ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(t.z) }
          └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─StreamExchange { dist: HashShard(t.y) }
              └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: same window different names
  sql: |
    create table t(x int, y int);
    select x, y, sum(x) over w1, count(*) over w2
    from t
    window w1 as (partition by y order by x),
           w2 as (partition by y order by x);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, sum, count] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), sum, count], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window with range frame
  sql: |
    create table t(x int, y int);
    select x, y, max(x) over w
    from t
    window w as (partition by y order by x range between 100 preceding and current row);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, max] }
    └─LogicalOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), max], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [max(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC RANGE BETWEEN 100 PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window with unbounded frame
  sql: |
    create table t(x int, y int);
    select x, y, first_value(x) over w, last_value(x) over w
    from t
    window w as (partition by y order by x rows between unbounded preceding and unbounded following);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, first_value, last_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), first_value, last_value], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: aggregate functions with named window
  sql: |
    create table t(x int, y int, z int);
    select x, y, z,
           sum(x) over w,
           avg(x) over w,
           min(x) over w,
           max(x) over w,
           count(*) over w
    from t
    window w as (partition by y order by z);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, min, max, count] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), min(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), max(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, min, max, count] }
      └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), min(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), max(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [t.y ASC, t.z ASC], dist: HashShard(t.y) }
          └─BatchSort { order: [t.y ASC, t.z ASC] }
            └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, sum, avg, min, max, count, t._row_id(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, min, max, count, t._row_id] }
      └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), min(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), max(t.x) OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.z ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(t.y) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: ranking functions with named window
  sql: |
    create table t(x int, y int);
    select x, y,
           row_number() over w,
           rank() over w,
           dense_rank() over w
    from t
    window w as (partition by y order by x);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, row_number, rank, dense_rank] }
    └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), row_number, rank, dense_rank], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), dense_rank() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: value functions with named window
  sql: |
    create table t(x int, y int);
    select x, y,
           lag(x) over w,
           lead(x) over w,
           first_value(x) over w,
           last_value(x) over w
    from t
    window w as (partition by y order by x);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, first_value, first_value, first_value, last_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
        └─BatchSort { order: [t.y ASC, t.x ASC] }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), lag, lead, first_value, last_value], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING), first_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), last_value(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: undefined named window
  sql: |
    create table t(x int, y int);
    select x, y, sum(x) over w from t;
  binder_error: |
    Failed to bind expression: sum(x) OVER w

    Caused by:
      Invalid input syntax: Window 'w' is not defined. Please ensure the window is defined in the WINDOW clause.
- id: duplicate window names
  sql: |
    create table t(x int, y int);
    select x, y, sum(x) over w1 from t window w1 as (partition by y), w1 as (partition by y order by x);
  binder_error: 'Invalid input syntax: window "w1" is already defined'
- id: mixed named and inline windows
  sql: |
    create table t(x int, y int, z int);
    select x, y, z,
           sum(x) over w,
           avg(y) over (partition by z order by x),
           count(*) over w
    from t
    window w as (partition by y order by x);
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, count] }
    └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), sum(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, count] }
      └─BatchOverWindow { window_functions: [sum(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [t.z ASC, t.x ASC], dist: HashShard(t.z) }
          └─BatchSort { order: [t.z ASC, t.x ASC] }
            └─BatchOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [t.y ASC, t.x ASC], dist: HashShard(t.y) }
                └─BatchSort { order: [t.y ASC, t.x ASC] }
                  └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, sum, avg, count, t._row_id(hidden)], stream_key: [t._row_id, y, z], pk_columns: [t._row_id, y, z], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, sum, (sum::Decimal / count::Decimal) as $expr1, count, t._row_id] }
      └─StreamOverWindow { window_functions: [sum(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count(t.y) OVER(PARTITION BY t.z ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(t.z) }
          └─StreamOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), count() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─StreamExchange { dist: HashShard(t.y) }
              └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: empty named window
  sql: |
    create table t(x int);
    select x, lag(x) over w from t window w as ();
  logical_plan: |-
    LogicalProject { exprs: [t.x, first_value] }
    └─LogicalOverWindow { window_functions: [first_value(t.x) OVER(ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)] }
      └─LogicalProject { exprs: [t.x, t._row_id, t._rw_timestamp] }
        └─LogicalScan { table: t, columns: [t.x, t._row_id, t._rw_timestamp] }
  batch_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
  stream_error: |-
    Feature is not yet implemented: Window function with empty PARTITION BY is not supported because of potential bad performance. If you really need this, please workaround with something like `PARTITION BY 1::int`.
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/11505
- id: expressions in named window spec
  sql: |
    create table t(x int, y int, z int);
    select x, y, z, sum(x * 2) over w
    from t
    window w as (partition by y + 1 order by abs(z));
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y, t.z, sum] }
    └─LogicalOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp, (t.x * 2:Int32) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.z) as $expr3] }
        └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.y, t.z, sum] }
      └─BatchOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [$expr2 ASC, $expr3 ASC], dist: HashShard($expr2) }
          └─BatchSort { order: [$expr2 ASC, $expr3 ASC] }
            └─BatchProject { exprs: [t.x, t.y, t.z, (t.x * 2:Int32) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.z) as $expr3] }
              └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, z, sum, t._row_id(hidden), $expr2(hidden)], stream_key: [t._row_id, $expr2], pk_columns: [t._row_id, $expr2], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, t.z, sum, t._row_id, $expr2] }
      └─StreamOverWindow { window_functions: [sum($expr1) OVER(PARTITION BY $expr2 ORDER BY $expr3 ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard($expr2) }
          └─StreamProject { exprs: [t.x, t.y, t.z, (t.x * 2:Int32) as $expr1, (t.y + 1:Int32) as $expr2, Abs(t.z) as $expr3, t._row_id] }
            └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: topn with named window
  sql: |
    create table t(x int, y int);
    select x, y from (
      select x, y, row_number() over w as rn
      from t
      window w as (partition by y order by x)
    ) where rn <= 3;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (row_number <= 3:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [t.x ASC], limit: 3, offset: 0, group_key: [t.y] }
      └─BatchExchange { order: [], dist: HashShard(t.y) }
        └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden)], stream_key: [y, t._row_id], pk_columns: [y, t._row_id], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [t.x ASC], limit: 3, offset: 0, group_key: [t.y] }
      └─StreamExchange { dist: HashShard(t.y) }
        └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window in subquery
  sql: |
    create table t(x int, y int);
    select x, y from (
      select x, y, sum(x) over w as s
      from t
      window w as (partition by y)
    ) where s > 10;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.y] }
    └─LogicalFilter { predicate: (sum > 10:Int32) }
      └─LogicalProject { exprs: [t.x, t.y, sum] }
        └─LogicalOverWindow { window_functions: [sum(t.x) OVER(PARTITION BY t.y ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
          └─LogicalProject { exprs: [t.x, t.y, t._row_id, t._rw_timestamp] }
            └─LogicalScan { table: t, columns: [t.x, t.y, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y] }
      ├─BatchExchange { order: [], dist: HashShard(t.y) }
      │ └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
      └─BatchFilter { predicate: (sum(t.x) > 10:Int32) }
        └─BatchHashAgg { group_key: [t.y], aggs: [sum(t.x)] }
          └─BatchExchange { order: [], dist: HashShard(t.y) }
            └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, t._row_id(hidden), t.y(hidden)], stream_key: [t._row_id, y], pk_columns: [t._row_id, y], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.y, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.y = t.y, output: [t.x, t.y, t._row_id, t.y] }
        ├─StreamExchange { dist: HashShard(t.y) }
        │ └─StreamShare { id: 1 }
        │   └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamFilter { predicate: (sum(t.x) > 10:Int32) }
          └─StreamProject { exprs: [t.y, sum(t.x)] }
            └─StreamHashAgg { group_key: [t.y], aggs: [sum(t.x), count] }
              └─StreamExchange { dist: HashShard(t.y) }
                └─StreamShare { id: 1 }
                  └─StreamTableScan { table: t, columns: [t.x, t.y, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: named window with cte
  sql: |
    create table t(x int, y int, z int);
    with cte as (
      select x, y, z, row_number() over w as rn
      from t
      window w as (partition by y order by x)
    )
    select x, z from cte where rn = 1;
  logical_plan: |-
    LogicalProject { exprs: [t.x, t.z] }
    └─LogicalFilter { predicate: (row_number = 1:Int32) }
      └─LogicalShare { id: 4 }
        └─LogicalProject { exprs: [t.x, t.y, t.z, row_number] }
          └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY t.y ORDER BY t.x ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─LogicalProject { exprs: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
              └─LogicalScan { table: t, columns: [t.x, t.y, t.z, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.x, t.z] }
      └─BatchGroupTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.y] }
        └─BatchExchange { order: [], dist: HashShard(t.y) }
          └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, z, t.y(hidden)], stream_key: [t.y], pk_columns: [t.y], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.z, t.y] }
      └─StreamGroupTopN { order: [t.x ASC], limit: 1, offset: 0, group_key: [t.y] }
        └─StreamExchange { dist: HashShard(t.y) }
          └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
