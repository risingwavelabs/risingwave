# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- name: desc
  sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc;
  batch_plan: |-
    BatchExchange { order: [t.v1 DESC], dist: Single }
    └─BatchSort { order: [t.v1 DESC] }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [v1, t._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: output names are not qualified after table names
  sql: |
    create table t (v1 bigint, v2 double precision);
    select t.* from t order by v1;
  batch_plan: |-
    BatchExchange { order: [t.v1 ASC], dist: Single }
    └─BatchSort { order: [t.v1 ASC] }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select v1, v1+1 from t order by v1;
  batch_plan: |-
    BatchExchange { order: [t.v1 ASC], dist: Single }
    └─BatchProject { exprs: [t.v1, (t.v1 + 1:Int32) as $expr1] }
      └─BatchSort { order: [t.v1 ASC] }
        └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select t.v1 from t order by v1;
  batch_plan: |-
    BatchExchange { order: [t.v1 ASC], dist: Single }
    └─BatchSort { order: [t.v1 ASC] }
      └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- name: order by output alias
  sql: |
    create table t (v1 bigint, v2 double precision);
    select v1 as a1 from t order by a1;
  batch_plan: |-
    BatchExchange { order: [t.v1 ASC], dist: Single }
    └─BatchSort { order: [t.v1 ASC] }
      └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- name: order by ambiguous
  sql: |
    create table t (v1 bigint, v2 double precision);
    select v1 as a, v2 as a from t order by a;
  binder_error: 'Bind error: ORDER BY "a" is ambiguous'
- name: ambiguous output name is okay as long as not used in order by
  sql: |
    create table t (v1 bigint, v2 double precision);
    select v1 as a, v2 as a from t order by 2;
  batch_plan: |-
    BatchExchange { order: [t.v2 ASC], dist: Single }
    └─BatchSort { order: [t.v2 ASC] }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by 1+1;
  batch_plan: |-
    BatchProject { exprs: [t.v1, t.v2] }
    └─BatchExchange { order: [2:Int32 ASC], dist: Single }
      └─BatchSort { order: [2:Int32 ASC] }
        └─BatchProject { exprs: [t.v1, t.v2, 2:Int32] }
          └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, 2:Int32(hidden), t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [2:Int32, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.v1, t.v2, 2:Int32, t._row_id] }
      └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v;
  binder_error: |
    Failed to bind expression: v

    Caused by:
      Item not found: Invalid column: v
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc limit 5;
  batch_plan: |-
    BatchTopN { order: [t.v1 DESC], limit: 5, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: [t.v1 DESC], limit: 5, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [v1, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.v1, t.v2, t._row_id] }
      └─StreamTopN { order: [t.v1 DESC], limit: 5, offset: 0 }
        └─StreamExchange { dist: Single }
          └─StreamGroupTopN { order: [t.v1 DESC], limit: 5, offset: 0, group_key: [_vnode] }
            └─StreamProject { exprs: [t.v1, t.v2, t._row_id, Vnode(t._row_id) as _vnode] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 3 offset 4;
  batch_plan: |-
    BatchLimit { limit: 3, offset: 4 }
    └─BatchExchange { order: [], dist: Single, sequential: true }
      └─BatchLimit { limit: 7, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], limit: 7, distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 5;
  batch_plan: |-
    BatchLimit { limit: 5, offset: 0 }
    └─BatchExchange { order: [], dist: Single, sequential: true }
      └─BatchLimit { limit: 5, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], limit: 5, distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 desc limit 5 offset 7;
  batch_plan: |-
    BatchTopN { order: [t.v1 DESC], limit: 5, offset: 7 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: [t.v1 DESC], limit: 12, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [v1, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.v1, t.v2, t._row_id] }
      └─StreamTopN { order: [t.v1 DESC], limit: 5, offset: 7 }
        └─StreamExchange { dist: Single }
          └─StreamGroupTopN { order: [t.v1 DESC], limit: 12, offset: 0, group_key: [_vnode] }
            └─StreamProject { exprs: [t.v1, t.v2, t._row_id, Vnode(t._row_id) as _vnode] }
              └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by expression that would be valid in select list
  sql: |
    create table t (x int, y int, z int);
    select x, y from t order by x + y, z;
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.x, t.y, (t.x + t.y) as $expr1, t.z] }
    └─LogicalScan { table: t, columns: [t.x, t.y, t.z] }
  batch_plan: |-
    BatchProject { exprs: [t.x, t.y] }
    └─BatchExchange { order: [$expr1 ASC, t.z ASC], dist: Single }
      └─BatchSort { order: [$expr1 ASC, t.z ASC] }
        └─BatchProject { exprs: [t.x, t.y, (t.x + t.y) as $expr1, t.z] }
          └─BatchScan { table: t, columns: [t.x, t.y, t.z], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, $expr1(hidden), t.z(hidden), t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [$expr1, t.z, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.y, (t.x + t.y) as $expr1, t.z, t._row_id] }
      └─StreamTableScan { table: t, columns: [t.x, t.y, t.z, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: order by the number of an output column
  sql: |
    create table t (x int, y int);
    select x, y from t order by 2;
  optimized_logical_plan_for_batch: 'LogicalScan { table: t, columns: [t.x, t.y] }'
  batch_plan: |-
    BatchExchange { order: [t.y ASC], dist: Single }
    └─BatchSort { order: [t.y ASC] }
      └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
- name: index exceeds the number of select items
  sql: |
    create table t (x int, y int);
    select x from t order by 2;
  binder_error: 'Invalid input syntax: Invalid ordinal number in ORDER BY: 2'
- name: an output column name cannot be used in an expression
  sql: |
    create table t (x int, y int);
    select x + y as sum from t order by sum + 1;
  binder_error: |
    Failed to bind expression: sum + 1

    Caused by:
      Item not found: Invalid column: sum
- name: select distinct with order by expressions not appear in select list
  sql: |
    create table t (x int, y int);
    select distinct x from t order by y;
  planner_error: 'Invalid input syntax: for SELECT DISTINCT, ORDER BY expressions must appear in select list'
- name: No BatchSort needed, when input is already sorted
  sql: |
    create table t(v int);
    create materialized view mv as select * from t order by v asc;
    select * from mv order by v asc;
  batch_plan: |-
    BatchExchange { order: [mv.v ASC], dist: Single }
    └─BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- name: BatchSort needed, when input is sorted in wrong order
  sql: |
    create table t(v int);
    create materialized view mv as select * from t order by v asc;
    select * from mv order by v desc;
  batch_plan: |-
    BatchExchange { order: [mv.v DESC], dist: Single }
    └─BatchSort { order: [mv.v DESC] }
      └─BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- name: No BatchSort needed, when input is already sorted
  sql: |
    create table t(v int);
    create materialized view mv as select * from t order by v desc;
    select * from mv order by v desc;
  batch_plan: |-
    BatchExchange { order: [mv.v DESC], dist: Single }
    └─BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- name: BatchSort needed, because our BatchScan can not get a ordered result when scan from ranges
  sql: |
    create table t(v int);
    create materialized view mv as select * from t order by v asc;
    select * from mv where v = 1 or v = 2 order by v asc;
  batch_plan: |-
    BatchExchange { order: [mv.v ASC], dist: Single }
    └─BatchSort { order: [mv.v ASC] }
      └─BatchScan { table: mv, columns: [mv.v], scan_ranges: [mv.v = Int32(1), mv.v = Int32(2)], distribution: SomeShard }
- name: BatchSort needed, when input is sorted in wrong order
  sql: |
    create table t(v int);
    create materialized view mv as select * from t order by v desc;
    select * from mv order by v asc;
  batch_plan: |-
    BatchExchange { order: [mv.v ASC], dist: Single }
    └─BatchSort { order: [mv.v ASC] }
      └─BatchScan { table: mv, columns: [mv.v], distribution: SomeShard }
- sql: |
    CREATE TABLE test (a INTEGER, b INTEGER);
    SELECT b % 2 AS f, SUM(a) FROM test GROUP BY b % 2 ORDER BY f;
  batch_plan: |-
    BatchExchange { order: [$expr1 ASC], dist: Single }
    └─BatchSort { order: [$expr1 ASC] }
      └─BatchHashAgg { group_key: [$expr1], aggs: [sum(test.a)] }
        └─BatchExchange { order: [], dist: HashShard($expr1) }
          └─BatchProject { exprs: [(test.b % 2:Int32) as $expr1, test.a] }
            └─BatchScan { table: test, columns: [test.a, test.b], distribution: SomeShard }
- name: Orderby with always-false predicate
  sql: |
    create table t1 (v1 int);
    select
        1 as col_0
    from
        t1 as t_0
    where
        false
    group by
        t_0.v1
    order by
        t_0.v1 asc;
  batch_plan: |-
    BatchProject { exprs: [1:Int32] }
    └─BatchExchange { order: [t1.v1 ASC], dist: Single }
      └─BatchProject { exprs: [1:Int32, t1.v1] }
        └─BatchSort { order: [t1.v1 ASC] }
          └─BatchHashAgg { group_key: [t1.v1], aggs: [] }
            └─BatchExchange { order: [], dist: HashShard(t1.v1) }
              └─BatchValues { rows: [] }
- name: distinct on order by
  sql: |
    create table t (x int, y int);
    select distinct on(x) x,y from t order by x,y;
  batch_plan: |-
    BatchExchange { order: [t.x ASC, t.y ASC], dist: Single }
    └─BatchSort { order: [t.x ASC, t.y ASC] }
      └─BatchGroupTopN { order: [t.x ASC, t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
        └─BatchExchange { order: [], dist: HashShard(t.x) }
          └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
- name: distinct on order by in cte
  sql: |
    create table t (x int, y int);
    with cte as (select distinct on(x) x,y from t order by x,y) select * from cte;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [t.x ASC, t.y ASC], limit: 1, offset: 0, group_key: [t.x] }
      └─BatchExchange { order: [], dist: HashShard(t.x) }
        └─BatchScan { table: t, columns: [t.x, t.y], distribution: SomeShard }
