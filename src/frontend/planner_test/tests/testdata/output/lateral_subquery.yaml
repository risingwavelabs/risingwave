# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- name: lateral join 1
  sql: |
    create table all_sales (salesperson_id int, customer_name varchar, amount int );
    create table salesperson (id int, name varchar );
    SELECT
    salesperson.name,
    max_sale.amount,
    max_sale_customer.customer_name
    FROM
    salesperson,
    -- calculate maximum size, cache it in transient derived table max_sale
    LATERAL
    (SELECT MAX(amount) AS amount
    FROM all_sales
    WHERE all_sales.salesperson_id = salesperson.id)
    AS max_sale,
    -- find customer, reusing cached maximum size
    LATERAL
    (SELECT customer_name
    FROM all_sales
    WHERE all_sales.salesperson_id = salesperson.id
    AND all_sales.amount =
    -- the cached maximum size
    max_sale.amount)
    AS max_sale_customer;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: salesperson.id = all_sales.salesperson_id AND max(all_sales.amount) = all_sales.amount, output: [salesperson.name, max(all_sales.amount), all_sales.customer_name] }
      ├─BatchExchange { order: [], dist: HashShard(salesperson.id, max(all_sales.amount)) }
      │ └─BatchHashJoin { type: Inner, predicate: salesperson.id = all_sales.salesperson_id, output: [salesperson.id, salesperson.name, max(all_sales.amount)] }
      │   ├─BatchExchange { order: [], dist: HashShard(salesperson.id) }
      │   │ └─BatchScan { table: salesperson, columns: [salesperson.id, salesperson.name], distribution: SomeShard }
      │   └─BatchHashAgg { group_key: [all_sales.salesperson_id], aggs: [max(all_sales.amount)] }
      │     └─BatchExchange { order: [], dist: HashShard(all_sales.salesperson_id) }
      │       └─BatchScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.amount], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(all_sales.salesperson_id, all_sales.amount) }
        └─BatchScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [name, amount, customer_name, salesperson._row_id(hidden), salesperson.id(hidden), all_sales._row_id(hidden)], stream_key: [salesperson._row_id, salesperson.id, all_sales._row_id, amount], pk_columns: [salesperson._row_id, salesperson.id, all_sales._row_id, amount], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(max(all_sales.amount), salesperson._row_id, salesperson.id, all_sales._row_id) }
      └─StreamHashJoin { type: Inner, predicate: salesperson.id = all_sales.salesperson_id AND max(all_sales.amount) = all_sales.amount, output: [salesperson.name, max(all_sales.amount), all_sales.customer_name, salesperson._row_id, salesperson.id, all_sales._row_id] }
        ├─StreamExchange { dist: HashShard(salesperson.id, max(all_sales.amount)) }
        │ └─StreamHashJoin { type: Inner, predicate: salesperson.id = all_sales.salesperson_id, output: [salesperson.id, salesperson.name, max(all_sales.amount), salesperson._row_id, all_sales.salesperson_id] }
        │   ├─StreamExchange { dist: HashShard(salesperson.id) }
        │   │ └─StreamTableScan { table: salesperson, columns: [salesperson.id, salesperson.name, salesperson._row_id], stream_scan_type: ArrangementBackfill, stream_key: [salesperson._row_id], pk: [_row_id], dist: UpstreamHashShard(salesperson._row_id) }
        │   └─StreamProject { exprs: [all_sales.salesperson_id, max(all_sales.amount)] }
        │     └─StreamHashAgg { group_key: [all_sales.salesperson_id], aggs: [max(all_sales.amount), count] }
        │       └─StreamExchange { dist: HashShard(all_sales.salesperson_id) }
        │         └─StreamTableScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.amount, all_sales._row_id], stream_scan_type: ArrangementBackfill, stream_key: [all_sales._row_id], pk: [_row_id], dist: UpstreamHashShard(all_sales._row_id) }
        └─StreamExchange { dist: HashShard(all_sales.salesperson_id, all_sales.amount) }
          └─StreamTableScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount, all_sales._row_id], stream_scan_type: ArrangementBackfill, stream_key: [all_sales._row_id], pk: [_row_id], dist: UpstreamHashShard(all_sales._row_id) }
- name: lateral join 2
  sql: |
    create table all_sales (salesperson_id int, customer_name varchar, amount int );
    create table salesperson (id int, name varchar );
    SELECT
    salesperson.name,
    max_sale.amount,
    max_sale.customer_name
    FROM
    salesperson,
    -- find maximum size and customer at same time
    LATERAL
    (SELECT amount, customer_name
    FROM all_sales
    WHERE all_sales.salesperson_id = salesperson.id
    ORDER BY amount DESC LIMIT 1)
    AS max_sale;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: salesperson.id IS NOT DISTINCT FROM all_sales.salesperson_id, output: [salesperson.name, all_sales.amount, all_sales.customer_name] }
      ├─BatchExchange { order: [], dist: HashShard(salesperson.id) }
      │ └─BatchScan { table: salesperson, columns: [salesperson.id, salesperson.name], distribution: SomeShard }
      └─BatchGroupTopN { order: [all_sales.amount DESC], limit: 1, offset: 0, group_key: [all_sales.salesperson_id] }
        └─BatchExchange { order: [], dist: HashShard(all_sales.salesperson_id) }
          └─BatchProject { exprs: [all_sales.salesperson_id, all_sales.amount, all_sales.customer_name] }
            └─BatchFilter { predicate: IsNotNull(all_sales.salesperson_id) }
              └─BatchScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [name, amount, customer_name, salesperson._row_id(hidden), salesperson.id(hidden), all_sales.salesperson_id(hidden)], stream_key: [salesperson._row_id, salesperson.id], pk_columns: [salesperson._row_id, salesperson.id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(salesperson._row_id, salesperson.id) }
      └─StreamHashJoin { type: Inner, predicate: salesperson.id IS NOT DISTINCT FROM all_sales.salesperson_id, output: [salesperson.name, all_sales.amount, all_sales.customer_name, salesperson._row_id, salesperson.id, all_sales.salesperson_id] }
        ├─StreamExchange { dist: HashShard(salesperson.id) }
        │ └─StreamTableScan { table: salesperson, columns: [salesperson.id, salesperson.name, salesperson._row_id], stream_scan_type: ArrangementBackfill, stream_key: [salesperson._row_id], pk: [_row_id], dist: UpstreamHashShard(salesperson._row_id) }
        └─StreamGroupTopN { order: [all_sales.amount DESC], limit: 1, offset: 0, group_key: [all_sales.salesperson_id] }
          └─StreamExchange { dist: HashShard(all_sales.salesperson_id) }
            └─StreamProject { exprs: [all_sales.salesperson_id, all_sales.amount, all_sales.customer_name, all_sales._row_id] }
              └─StreamFilter { predicate: IsNotNull(all_sales.salesperson_id) }
                └─StreamTableScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount, all_sales._row_id], stream_scan_type: ArrangementBackfill, stream_key: [all_sales._row_id], pk: [_row_id], dist: UpstreamHashShard(all_sales._row_id) }
- name: lateral join 2 (left join)
  sql: |
    create table all_sales (salesperson_id int, customer_name varchar, amount int );
    create table salesperson (id int, name varchar );
    SELECT
    salesperson.name,
    max_sale.amount,
    max_sale.customer_name
    FROM
    salesperson LEFT JOIN
    -- find maximum size and customer at same time
    LATERAL
    (SELECT amount, customer_name
    FROM all_sales
    WHERE all_sales.salesperson_id = salesperson.id
    ORDER BY amount DESC LIMIT 1)
    AS max_sale on true;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftOuter, predicate: salesperson.id IS NOT DISTINCT FROM all_sales.salesperson_id, output: [salesperson.name, all_sales.amount, all_sales.customer_name] }
      ├─BatchExchange { order: [], dist: HashShard(salesperson.id) }
      │ └─BatchScan { table: salesperson, columns: [salesperson.id, salesperson.name], distribution: SomeShard }
      └─BatchGroupTopN { order: [all_sales.amount DESC], limit: 1, offset: 0, group_key: [all_sales.salesperson_id] }
        └─BatchExchange { order: [], dist: HashShard(all_sales.salesperson_id) }
          └─BatchProject { exprs: [all_sales.salesperson_id, all_sales.amount, all_sales.customer_name] }
            └─BatchFilter { predicate: IsNotNull(all_sales.salesperson_id) }
              └─BatchScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [name, amount, customer_name, salesperson._row_id(hidden), salesperson.id(hidden), all_sales.salesperson_id(hidden)], stream_key: [salesperson._row_id, salesperson.id], pk_columns: [salesperson._row_id, salesperson.id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(salesperson._row_id, salesperson.id) }
      └─StreamHashJoin { type: LeftOuter, predicate: salesperson.id IS NOT DISTINCT FROM all_sales.salesperson_id, output: [salesperson.name, all_sales.amount, all_sales.customer_name, salesperson._row_id, salesperson.id, all_sales.salesperson_id] }
        ├─StreamExchange { dist: HashShard(salesperson.id) }
        │ └─StreamTableScan { table: salesperson, columns: [salesperson.id, salesperson.name, salesperson._row_id], stream_scan_type: ArrangementBackfill, stream_key: [salesperson._row_id], pk: [_row_id], dist: UpstreamHashShard(salesperson._row_id) }
        └─StreamGroupTopN { order: [all_sales.amount DESC], limit: 1, offset: 0, group_key: [all_sales.salesperson_id] }
          └─StreamExchange { dist: HashShard(all_sales.salesperson_id) }
            └─StreamProject { exprs: [all_sales.salesperson_id, all_sales.amount, all_sales.customer_name, all_sales._row_id] }
              └─StreamFilter { predicate: IsNotNull(all_sales.salesperson_id) }
                └─StreamTableScan { table: all_sales, columns: [all_sales.salesperson_id, all_sales.customer_name, all_sales.amount, all_sales._row_id], stream_scan_type: ArrangementBackfill, stream_key: [all_sales._row_id], pk: [_row_id], dist: UpstreamHashShard(all_sales._row_id) }
- name: lateral join 2 (right join) should throw an error
  sql: |
    create table all_sales (salesperson_id int, customer_name varchar, amount int );
    create table salesperson (id int, name varchar );
    SELECT
    salesperson.name,
    max_sale.amount,
    max_sale.customer_name
    FROM
    salesperson RIGHT JOIN
    -- find maximum size and customer at same time
    LATERAL
    (SELECT amount, customer_name
    FROM all_sales
    WHERE all_sales.salesperson_id = salesperson.id
    ORDER BY amount DESC LIMIT 1)
    AS max_sale on true;
  binder_error: 'Invalid input syntax: The combining JOIN type must be INNER or LEFT for a LATERAL reference.'
- name: implicit lateral subquery of correlated table function
  sql: |
    create table t(x int , arr int[]);
    select * from t cross join unnest(arr);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.arr IS NOT DISTINCT FROM t.arr, output: [t.x, t.arr, Unnest($0)] }
      ├─BatchExchange { order: [], dist: HashShard(t.arr) }
      │ └─BatchScan { table: t, columns: [t.x, t.arr], distribution: SomeShard }
      └─BatchProjectSet { select_list: [$0, Unnest($0)] }
        └─BatchHashAgg { group_key: [t.arr], aggs: [] }
          └─BatchExchange { order: [], dist: HashShard(t.arr) }
            └─BatchScan { table: t, columns: [t.arr], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, arr, unnest, t._row_id(hidden), t.arr(hidden), projected_row_id(hidden)], stream_key: [t._row_id, projected_row_id, arr], pk_columns: [t._row_id, projected_row_id, arr], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.arr, t._row_id, projected_row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.arr IS NOT DISTINCT FROM t.arr, output: [t.x, t.arr, Unnest($0), t._row_id, t.arr, projected_row_id] }
        ├─StreamExchange { dist: HashShard(t.arr) }
        │ └─StreamTableScan { table: t, columns: [t.x, t.arr, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamProjectSet { select_list: [$0, Unnest($0)] }
          └─StreamProject { exprs: [t.arr], noop_update_hint: true }
            └─StreamHashAgg { group_key: [t.arr], aggs: [count] }
              └─StreamExchange { dist: HashShard(t.arr) }
                └─StreamTableScan { table: t, columns: [t.arr, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: https://github.com/risingwavelabs/risingwave/issues/12298
  sql: |
    create table t1(c varchar, n varchar, id varchar, d varchar);
    create table t2(c varchar, p varchar, id varchar, d varchar);
    select array_agg(t1.n order by path_idx) from t1
    join t2
    on t1.c = 'abc'
    and t2.c = 'abc'
    cross join unnest((case when t2.p <> '' then (string_to_array(trim(t2.p, ','), ',') || t2.d) else ARRAY[t2.d] end)) WITH ORDINALITY AS path_cols(path_val, path_idx)
    where path_val = t1.id;
  stream_plan: |-
    StreamMaterialize { columns: [array_agg], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    └─StreamProject { exprs: [array_agg(t1.n order_by($expr1 ASC))] }
      └─StreamSimpleAgg { aggs: [array_agg(t1.n order_by($expr1 ASC)), count] }
        └─StreamExchange { dist: Single }
          └─StreamProject { exprs: [t1.n, (projected_row_id + 1:Int64) as $expr1, t1._row_id, t2.p, t2.d, projected_row_id, t1.id, t2._row_id] }
            └─StreamHashJoin { type: Inner, predicate: t2.p IS NOT DISTINCT FROM t2.p AND t2.d IS NOT DISTINCT FROM t2.d, output: [t1.n, t1.id, projected_row_id, t2.p, t2.d, Unnest(Case(($0 <> '':Varchar), ArrayAppend(StringToArray(Trim($0, ',':Varchar), ',':Varchar), $1), Array($1))), t2.p, t2.d, t1._row_id, t2._row_id] }
              ├─StreamExchange { dist: HashShard(t2.p, t2.d) }
              │ └─StreamHashJoin { type: Inner, predicate: t1.id = Unnest(Case(($0 <> '':Varchar), ArrayAppend(StringToArray(Trim($0, ',':Varchar), ',':Varchar), $1), Array($1))), output: [t1.n, t1.id, projected_row_id, t2.p, t2.d, Unnest(Case(($0 <> '':Varchar), ArrayAppend(StringToArray(Trim($0, ',':Varchar), ',':Varchar), $1), Array($1))), t1._row_id] }
              │   ├─StreamExchange { dist: HashShard(t1.id) }
              │   │ └─StreamProject { exprs: [t1.n, t1.id, t1._row_id] }
              │   │   └─StreamFilter { predicate: (t1.c = 'abc':Varchar) }
              │   │     └─StreamTableScan { table: t1, columns: [t1.n, t1.id, t1._row_id, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
              │   └─StreamExchange { dist: HashShard(Unnest(Case(($0 <> '':Varchar), ArrayAppend(StringToArray(Trim($0, ',':Varchar), ',':Varchar), $1), Array($1)))) }
              │     └─StreamProjectSet { select_list: [$0, $1, Unnest(Case(($0 <> '':Varchar), ArrayAppend(StringToArray(Trim($0, ',':Varchar), ',':Varchar), $1), Array($1)))] }
              │       └─StreamProject { exprs: [t2.p, t2.d], noop_update_hint: true }
              │         └─StreamHashAgg { group_key: [t2.p, t2.d], aggs: [count] }
              │           └─StreamExchange { dist: HashShard(t2.p, t2.d) }
              │             └─StreamProject { exprs: [t2.p, t2.d, t2._row_id] }
              │               └─StreamFilter { predicate: (t2.c = 'abc':Varchar) }
              │                 └─StreamTableScan { table: t2, columns: [t2.p, t2.d, t2._row_id, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
              └─StreamExchange { dist: HashShard(t2.p, t2.d) }
                └─StreamProject { exprs: [t2.p, t2.d, t2._row_id] }
                  └─StreamFilter { predicate: (t2.c = 'abc':Varchar) }
                    └─StreamTableScan { table: t2, columns: [t2.p, t2.d, t2._row_id, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
- name: https://github.com/risingwavelabs/risingwave/issues/15337
  sql: |
    CREATE TABLE t1 (c1 varchar, c2 bigint,c3 numeric, c4 timestamp) APPEND ONLY;
    CREATE TABLE t2 (c5 timestamptz, c6 varchar, c7 numeric, c8 numeric, c1 varchar);
    SELECT o.*, b.v1,b.v2
    FROM t2 o
    LEFT JOIN LATERAL (
    SELECT
      sum(t.c2 * t.c3) filter ( WHERE (o.c7) * t.c3 <= (o.c7) * o.c8 ) AS v1,
      sum(t.c2) filter ( WHERE (o.c7) * t.c3 <= (o.c7) * o.c8) AS v2
      FROM t1 t
      WHERE t.c1 = o.c1 AND t.c4 >= o.c5 AND t.c4 :: date = o.c5 :: date
    ) AS b ON TRUE;
  stream_plan: |-
    StreamMaterialize { columns: [c5, c6, c7, c8, c1, v1, v2, t2._row_id(hidden), t2.c7(hidden), t2.c8(hidden), t2.c7#1(hidden), t2.c8#1(hidden), t2.c5(hidden), t2.c1(hidden)], stream_key: [t2._row_id, c7, c8, c5, c1], pk_columns: [t2._row_id, c7, c8, c5, c1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t2.c5, t2.c7, t2.c8, t2.c1, t2._row_id) }
      └─StreamHashJoin { type: LeftOuter, predicate: t2.c7 IS NOT DISTINCT FROM t2.c7 AND t2.c8 IS NOT DISTINCT FROM t2.c8 AND t2.c7 IS NOT DISTINCT FROM t2.c7 AND t2.c8 IS NOT DISTINCT FROM t2.c8 AND t2.c5 IS NOT DISTINCT FROM t2.c5 AND t2.c1 IS NOT DISTINCT FROM t2.c1, output: [t2.c5, t2.c6, t2.c7, t2.c8, t2.c1, sum($expr4) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8))), sum(t1.c2) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8))), t2._row_id, t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1] }
        ├─StreamExchange { dist: HashShard(t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1) }
        │ └─StreamTableScan { table: t2, columns: [t2.c5, t2.c6, t2.c7, t2.c8, t2.c1, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        └─StreamProject { exprs: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, sum($expr4) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8))), sum(t1.c2) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8)))] }
          └─StreamHashAgg { group_key: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1], aggs: [sum($expr4) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8))), sum(t1.c2) filter(((t2.c7 * t1.c3) <= (t2.c7 * t2.c8))), count] }
            └─StreamHashJoin { type: LeftOuter, predicate: t2.c7 IS NOT DISTINCT FROM t2.c7 AND t2.c8 IS NOT DISTINCT FROM t2.c8 AND t2.c7 IS NOT DISTINCT FROM t2.c7 AND t2.c8 IS NOT DISTINCT FROM t2.c8 AND t2.c5 IS NOT DISTINCT FROM t2.c5 AND t2.c1 IS NOT DISTINCT FROM t2.c1, output: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, t1.c3, $expr4, t1.c2, t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, t1._row_id, $expr1] }
              ├─StreamExchange { dist: HashShard(t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1) }
              │ └─StreamProject { exprs: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1], noop_update_hint: true }
              │   └─StreamHashAgg { group_key: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1], aggs: [count] }
              │     └─StreamExchange { dist: HashShard(t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1) }
              │       └─StreamTableScan { table: t2, columns: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
              └─StreamExchange { dist: HashShard(t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1) }
                └─StreamProject { exprs: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, t1.c3, (t1.c2::Decimal * t1.c3) as $expr4, t1.c2, t1._row_id, $expr1] }
                  └─StreamFilter { predicate: (t2.c5 <= $expr2) }
                    └─StreamHashJoin { type: Inner, predicate: t2.c1 = t1.c1 AND $expr1 = $expr3, output: all }
                      ├─StreamExchange { dist: HashShard(t2.c1, $expr1) }
                      │ └─StreamProject { exprs: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, AtTimeZone(t2.c5, 'UTC':Varchar)::Date as $expr1], noop_update_hint: true }
                      │   └─StreamHashAgg { group_key: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1], aggs: [count] }
                      │     └─StreamExchange { dist: HashShard(t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1) }
                      │       └─StreamTableScan { table: t2, columns: [t2.c7, t2.c8, t2.c7, t2.c8, t2.c5, t2.c1, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
                      └─StreamExchange { dist: HashShard(t1.c1, $expr3) }
                        └─StreamProject { exprs: [t1.c1, t1.c2, t1.c3, AtTimeZone(t1.c4, 'UTC':Varchar) as $expr2, t1.c4::Date as $expr3, t1._row_id] }
                          └─StreamTableScan { table: t1, columns: [t1.c1, t1.c2, t1.c3, t1.c4, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
- name: https://github.com/risingwavelabs/risingwave/issues/17382
  sql: |
    CREATE TABLE r(ts TIMESTAMPTZ, src_id int, dev_id int);
    SELECT e.ts AS e_ts, d.*
    FROM (
      SELECT '2024-06-20T19:01:00Z'::TIMESTAMPTZ ts, 1::INT AS src_id) e
    JOIN LATERAL
    (
      SELECT DISTINCT ON(src_id, dev_id) *
      FROM r
      WHERE r.src_id = e.src_id AND r.ts <= e.ts
      ORDER BY src_id, dev_id, ts DESC
    )d on true;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: '2024-06-20 19:01:00+00:00':Timestamptz IS NOT DISTINCT FROM '2024-06-20 19:01:00+00:00':Timestamptz AND 1:Int32 IS NOT DISTINCT FROM 1:Int32, output: ['2024-06-20 19:01:00+00:00':Timestamptz, r.ts, r.src_id, r.dev_id] }
      ├─BatchExchange { order: [], dist: HashShard('2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32) }
      │ └─BatchValues { rows: [['2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32]] }
      └─BatchExchange { order: [], dist: HashShard('2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32) }
        └─BatchGroupTopN { order: [r.src_id ASC, r.dev_id ASC, r.ts DESC], limit: 1, offset: 0, group_key: ['2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32, r.src_id, r.dev_id] }
          └─BatchExchange { order: [], dist: HashShard('2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32, r.src_id, r.dev_id) }
            └─BatchHashJoin { type: Inner, predicate: 1:Int32 = r.src_id AND (r.ts <= '2024-06-20 19:01:00+00:00':Timestamptz), output: all }
              ├─BatchExchange { order: [], dist: HashShard(1:Int32) }
              │ └─BatchHashAgg { group_key: ['2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32], aggs: [] }
              │   └─BatchExchange { order: [], dist: HashShard('2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32) }
              │     └─BatchValues { rows: [['2024-06-20 19:01:00+00:00':Timestamptz, 1:Int32]] }
              └─BatchExchange { order: [], dist: HashShard(r.src_id) }
                └─BatchScan { table: r, columns: [r.ts, r.src_id, r.dev_id], distribution: SomeShard }
- name: lateral join with CTE
  sql: |
    create table t1(x int, y int);
    create table t2(x int, y int);
    select * from t1, lateral (
        with cte as (select * from t2 where t2.y = t1.y)  select x from cte
    );
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t1.y IS NOT DISTINCT FROM t2.y, output: [t1.x, t1.y, t2.x] }
      ├─BatchExchange { order: [], dist: HashShard(t1.y) }
      │ └─BatchScan { table: t1, columns: [t1.x, t1.y], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t2.y) }
        └─BatchFilter { predicate: IsNotNull(t2.y) }
          └─BatchScan { table: t2, columns: [t2.x, t2.y], distribution: SomeShard }
- name: use lateral join to express asof join
  sql: |
    create table t1 (
      price_at date,
      qid varchar,
      price float,
      currency varchar,
    );
    create table t2 (
      ex_date date,
      qid varchar,
      factor float,
    );
    create table t3 (
      price_at date,
      qid varchar
    );
    SELECT
        *
    FROM t1
    LEFT JOIN LATERAL (
        SELECT
            t2.ex_date,
            t2.factor
        FROM (
          select * from t2
        ) t2
        WHERE
            t1.qid = t2.qid
            AND t1.price_at IN (
                SELECT MAX(t3.price_at) AS price_at from t3
                WHERE
                    t3.price_at < t2.ex_date
                    AND t3.qid = t2.qid
            )
        ORDER BY t2.ex_date
        LIMIT 1
    ) t2 ON TRUE;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftOuter, predicate: t1.price_at IS NOT DISTINCT FROM t1.price_at AND t1.qid IS NOT DISTINCT FROM t1.qid, output: [t1.price_at, t1.qid, t1.price, t1.currency, t2.ex_date, t2.factor] }
      ├─BatchExchange { order: [], dist: HashShard(t1.price_at, t1.qid) }
      │ └─BatchScan { table: t1, columns: [t1.price_at, t1.qid, t1.price, t1.currency], distribution: SomeShard }
      └─BatchProject { exprs: [t1.price_at, t1.qid, t2.ex_date, t2.factor] }
        └─BatchGroupTopN { order: [t2.ex_date ASC], limit: 1, offset: 0, group_key: [t1.price_at, t1.qid] }
          └─BatchExchange { order: [], dist: HashShard(t1.price_at, t1.qid) }
            └─BatchProject { exprs: [t1.price_at, t1.qid, t2.ex_date, t2.factor, t2.ex_date] }
              └─BatchHashJoin { type: LeftSemi, predicate: t1.price_at = max(t3.price_at) AND t2.ex_date IS NOT DISTINCT FROM t2.ex_date AND t2.qid IS NOT DISTINCT FROM t2.qid AND t1.price_at IS NOT DISTINCT FROM t1.price_at AND t1.qid IS NOT DISTINCT FROM internal_last_seen_value(t1.qid), output: [t1.price_at, t1.qid, t2.ex_date, t2.factor] }
                ├─BatchExchange { order: [], dist: HashShard(t2.qid) }
                │ └─BatchHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                │   ├─BatchExchange { order: [], dist: HashShard(t1.qid) }
                │   │ └─BatchHashAgg { group_key: [t1.price_at, t1.qid], aggs: [] }
                │   │   └─BatchExchange { order: [], dist: HashShard(t1.price_at, t1.qid) }
                │   │     └─BatchScan { table: t1, columns: [t1.price_at, t1.qid], distribution: SomeShard }
                │   └─BatchExchange { order: [], dist: HashShard(t2.qid) }
                │     └─BatchScan { table: t2, columns: [t2.ex_date, t2.qid, t2.factor], distribution: SomeShard }
                └─BatchHashAgg { group_key: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid], aggs: [max(t3.price_at)] }
                  └─BatchHashJoin { type: LeftOuter, predicate: t2.ex_date IS NOT DISTINCT FROM t2.ex_date AND t2.qid IS NOT DISTINCT FROM t2.qid AND t1.price_at IS NOT DISTINCT FROM t1.price_at AND internal_last_seen_value(t1.qid) IS NOT DISTINCT FROM internal_last_seen_value(t1.qid), output: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid, t3.price_at] }
                    ├─BatchExchange { order: [], dist: HashShard(t2.qid) }
                    │ └─BatchHashAgg { group_key: [t1.price_at, t2.ex_date, t2.qid], aggs: [internal_last_seen_value(t1.qid)] }
                    │   └─BatchExchange { order: [], dist: HashShard(t1.price_at, t2.ex_date, t2.qid) }
                    │     └─BatchHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                    │       ├─BatchExchange { order: [], dist: HashShard(t1.qid) }
                    │       │ └─BatchHashAgg { group_key: [t1.price_at, t1.qid], aggs: [] }
                    │       │   └─BatchExchange { order: [], dist: HashShard(t1.price_at, t1.qid) }
                    │       │     └─BatchScan { table: t1, columns: [t1.price_at, t1.qid], distribution: SomeShard }
                    │       └─BatchExchange { order: [], dist: HashShard(t2.qid) }
                    │         └─BatchScan { table: t2, columns: [t2.ex_date, t2.qid], distribution: SomeShard }
                    └─BatchHashJoin { type: Inner, predicate: t2.qid = t3.qid AND (t3.price_at < t2.ex_date), output: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid, t3.price_at] }
                      ├─BatchExchange { order: [], dist: HashShard(t2.qid) }
                      │ └─BatchHashAgg { group_key: [t1.price_at, t2.ex_date, t2.qid], aggs: [internal_last_seen_value(t1.qid)] }
                      │   └─BatchExchange { order: [], dist: HashShard(t1.price_at, t2.ex_date, t2.qid) }
                      │     └─BatchHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                      │       ├─BatchExchange { order: [], dist: HashShard(t1.qid) }
                      │       │ └─BatchHashAgg { group_key: [t1.price_at, t1.qid], aggs: [] }
                      │       │   └─BatchExchange { order: [], dist: HashShard(t1.price_at, t1.qid) }
                      │       │     └─BatchScan { table: t1, columns: [t1.price_at, t1.qid], distribution: SomeShard }
                      │       └─BatchExchange { order: [], dist: HashShard(t2.qid) }
                      │         └─BatchScan { table: t2, columns: [t2.ex_date, t2.qid], distribution: SomeShard }
                      └─BatchExchange { order: [], dist: HashShard(t3.qid) }
                        └─BatchScan { table: t3, columns: [t3.price_at, t3.qid], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [price_at, qid, price, currency, ex_date, factor, t1._row_id(hidden), t1.price_at(hidden), t1.qid(hidden)], stream_key: [t1._row_id, price_at, qid], pk_columns: [t1._row_id, price_at, qid], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t1.price_at, t1.qid, t1._row_id) }
      └─StreamHashJoin { type: LeftOuter, predicate: t1.price_at IS NOT DISTINCT FROM t1.price_at AND t1.qid IS NOT DISTINCT FROM t1.qid, output: [t1.price_at, t1.qid, t1.price, t1.currency, t2.ex_date, t2.factor, t1._row_id, t1.price_at, t1.qid] }
        ├─StreamExchange { dist: HashShard(t1.price_at, t1.qid) }
        │ └─StreamTableScan { table: t1, columns: [t1.price_at, t1.qid, t1.price, t1.currency, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        └─StreamProject { exprs: [t1.price_at, t1.qid, t2.ex_date, t2.factor] }
          └─StreamGroupTopN { order: [t2.ex_date ASC], limit: 1, offset: 0, group_key: [t1.price_at, t1.qid] }
            └─StreamExchange { dist: HashShard(t1.price_at, t1.qid) }
              └─StreamProject { exprs: [t1.price_at, t1.qid, t2.ex_date, t2.factor, t2.ex_date, t2._row_id, t2.qid] }
                └─StreamHashJoin { type: LeftSemi, predicate: t1.price_at = max(t3.price_at) AND t2.ex_date IS NOT DISTINCT FROM t2.ex_date AND t2.qid IS NOT DISTINCT FROM t2.qid AND t1.price_at IS NOT DISTINCT FROM t1.price_at AND t1.qid IS NOT DISTINCT FROM internal_last_seen_value(t1.qid), output: [t1.price_at, t1.qid, t2.ex_date, t2.factor, t2._row_id, t2.qid] }
                  ├─StreamExchange { dist: HashShard(t2.qid) }
                  │ └─StreamHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                  │   ├─StreamExchange { dist: HashShard(t1.qid) }
                  │   │ └─StreamProject { exprs: [t1.price_at, t1.qid], noop_update_hint: true }
                  │   │   └─StreamHashAgg { group_key: [t1.price_at, t1.qid], aggs: [count] }
                  │   │     └─StreamExchange { dist: HashShard(t1.price_at, t1.qid) }
                  │   │       └─StreamTableScan { table: t1, columns: [t1.price_at, t1.qid, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
                  │   └─StreamExchange { dist: HashShard(t2.qid) }
                  │     └─StreamTableScan { table: t2, columns: [t2.ex_date, t2.qid, t2.factor, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
                  └─StreamProject { exprs: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid, max(t3.price_at)] }
                    └─StreamHashAgg { group_key: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid], aggs: [max(t3.price_at), count] }
                      └─StreamHashJoin { type: LeftOuter, predicate: t2.ex_date IS NOT DISTINCT FROM t2.ex_date AND t2.qid IS NOT DISTINCT FROM t2.qid AND t1.price_at IS NOT DISTINCT FROM t1.price_at AND internal_last_seen_value(t1.qid) IS NOT DISTINCT FROM internal_last_seen_value(t1.qid), output: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid, t3.price_at, t1.price_at, t2.ex_date, t2.qid, t3._row_id] }
                        ├─StreamExchange { dist: HashShard(t2.qid) }
                        │ └─StreamProject { exprs: [t1.price_at, t2.ex_date, t2.qid, internal_last_seen_value(t1.qid)] }
                        │   └─StreamHashAgg { group_key: [t1.price_at, t2.ex_date, t2.qid], aggs: [internal_last_seen_value(t1.qid), count] }
                        │     └─StreamExchange { dist: HashShard(t1.price_at, t2.ex_date, t2.qid) }
                        │       └─StreamHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                        │         ├─StreamExchange { dist: HashShard(t1.qid) }
                        │         │ └─StreamProject { exprs: [t1.price_at, t1.qid], noop_update_hint: true }
                        │         │   └─StreamHashAgg { group_key: [t1.price_at, t1.qid], aggs: [count] }
                        │         │     └─StreamExchange { dist: HashShard(t1.price_at, t1.qid) }
                        │         │       └─StreamTableScan { table: t1, columns: [t1.price_at, t1.qid, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
                        │         └─StreamExchange { dist: HashShard(t2.qid) }
                        │           └─StreamTableScan { table: t2, columns: [t2.ex_date, t2.qid, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
                        └─StreamProject { exprs: [t1.price_at, internal_last_seen_value(t1.qid), t2.ex_date, t2.qid, t3.price_at, t3._row_id] }
                          └─StreamFilter { predicate: (t3.price_at < t2.ex_date) }
                            └─StreamHashJoin { type: Inner, predicate: t2.qid = t3.qid, output: all }
                              ├─StreamExchange { dist: HashShard(t2.qid) }
                              │ └─StreamProject { exprs: [t1.price_at, t2.ex_date, t2.qid, internal_last_seen_value(t1.qid)] }
                              │   └─StreamHashAgg { group_key: [t1.price_at, t2.ex_date, t2.qid], aggs: [internal_last_seen_value(t1.qid), count] }
                              │     └─StreamExchange { dist: HashShard(t1.price_at, t2.ex_date, t2.qid) }
                              │       └─StreamHashJoin { type: Inner, predicate: t1.qid = t2.qid, output: all }
                              │         ├─StreamExchange { dist: HashShard(t1.qid) }
                              │         │ └─StreamProject { exprs: [t1.price_at, t1.qid], noop_update_hint: true }
                              │         │   └─StreamHashAgg { group_key: [t1.price_at, t1.qid], aggs: [count] }
                              │         │     └─StreamExchange { dist: HashShard(t1.price_at, t1.qid) }
                              │         │       └─StreamTableScan { table: t1, columns: [t1.price_at, t1.qid, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
                              │         └─StreamExchange { dist: HashShard(t2.qid) }
                              │           └─StreamTableScan { table: t2, columns: [t2.ex_date, t2.qid, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
                              └─StreamExchange { dist: HashShard(t3.qid) }
                                └─StreamTableScan { table: t3, columns: [t3.price_at, t3.qid, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
