# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    select 1 as k, 2 as v;
  batch_plan: 'BatchValues { rows: [[1:Int32, 2:Int32]] }'
- sql: select 'abc', 1, 1.4 as k from (select 1 as k, 2 from (select 1, 2 union all select 3, 4) union all select * from (select 3, 4) union all select 100, 200 from (select now(), now() - interval '1 hour'));
  batch_plan: 'BatchValues { rows: [[''abc'':Varchar, 1:Int32, 1.4:Decimal], [''abc'':Varchar, 1:Int32, 1.4:Decimal], [''abc'':Varchar, 1:Int32, 1.4:Decimal], [''abc'':Varchar, 1:Int32, 1.4:Decimal]] }'
- id: create_table
  sql: create table t (id int, value string);
- id: create_append_only_table
  sql: create table t (id int, value string) append only;
- before:
  - create_table
  sql: |
    select id, value, openai_embedding('{"api_key":"sk-test-key", "model": "text-embedding-3-small"}'::jsonb, value) as embedding
    from t;
  logical_plan: |-
    LogicalProject { exprs: [t.id, t.value, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
    └─LogicalScan { table: t, columns: [t.id, t.value, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.id, t.value, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
      └─BatchScan { table: t, columns: [t.id, t.value], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, value, embedding, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.id, t.value, $expr1, t._row_id] }
      └─StreamMaterializedExprs { exprs: [OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
        └─StreamTableScan { table: t, columns: [t.id, t.value, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- before:
  - create_table
  sql: |
    select id, value, id + 1 as id_plus_one,
           openai_embedding('{"api_key":"sk-test-key", "model": "text-embedding-3-small"}'::jsonb, value) as embedding,
           upper(value) as upper_value
    from t;
  logical_plan: |-
    LogicalProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr1, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr2, Upper(t.value) as $expr3] }
    └─LogicalScan { table: t, columns: [t.id, t.value, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr1, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr2, Upper(t.value) as $expr3] }
      └─BatchScan { table: t, columns: [t.id, t.value], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, value, id_plus_one, embedding, upper_value, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr2, $expr1, Upper(t.value) as $expr3, t._row_id] }
      └─StreamMaterializedExprs { exprs: [OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
        └─StreamTableScan { table: t, columns: [t.id, t.value, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: materialize impure expressions after singleton (top-n)
  sql: |
    create table t (v int);
    with cte as (select v from t order by v limit 10) select pg_sleep(v) from cte;
  stream_plan: |-
    StreamMaterialize { columns: [pg_sleep, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [$expr1, t._row_id] }
      └─StreamMaterializedExprs { exprs: [PgSleep(t.v::Float64) as $expr1] }
        └─StreamProject { exprs: [t.v, t._row_id] }
          └─StreamTopN { order: [t.v ASC], limit: 10, offset: 0 }
            └─StreamExchange { dist: Single }
              └─StreamGroupTopN { order: [t.v ASC], limit: 10, offset: 0, group_key: [_vnode] }
                └─StreamProject { exprs: [t.v, t._row_id, Vnode(t._row_id) as _vnode] }
                  └─StreamTableScan { table: t, columns: [t.v, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [pg_sleep, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └── StreamProject { exprs: [$expr1, t._row_id] }
        └── StreamMaterializedExprs { exprs: [PgSleep(t.v::Float64) as $expr1] } { tables: [ MaterializedExprs: 0 ] }
            └── StreamProject { exprs: [t.v, t._row_id] }
                └── StreamTopN { order: [t.v ASC], limit: 10, offset: 0 } { tables: [ TopN: 1 ] }
                    └── StreamExchange Single from 1

    Fragment 1
    StreamGroupTopN { order: [t.v ASC], limit: 10, offset: 0, group_key: [_vnode] } { tables: [ GroupTopN: 2 ] }
    └── StreamProject { exprs: [t.v, t._row_id, Vnode(t._row_id) as _vnode] }
        └── StreamTableScan { table: t, columns: [t.v, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
            ├── tables: [ StreamScan: 3 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ t_v, t__row_id, $expr1, _rw_timestamp ], primary key: [ $1 ASC ], value indices: [ 0, 1, 2 ], distribution key: [], read pk prefix len hint: 1 }

    Table 1 { columns: [ t_v, t__row_id, _vnode, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2 ], distribution key: [], read pk prefix len hint: 0 }

    Table 2
    ├── columns: [ t_v, t__row_id, _vnode, _rw_timestamp ]
    ├── primary key: [ $2 ASC, $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 1 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 2

    Table 3
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ pg_sleep, t._row_id, _rw_timestamp ], primary key: [ $1 ASC ], value indices: [ 0, 1 ], distribution key: [], read pk prefix len hint: 1 }

- name: materialized impure expressions after some-shard (full outer join), an exchange is required
  sql: |
    create table t1 (v int);
    create table t2 (v int);
    with cte as (select t1.v v from t1 full outer join t2 on t1.v = t2.v) select pg_sleep(v) from cte;
  stream_plan: |-
    StreamMaterialize { columns: [pg_sleep, t1._row_id(hidden), t2._row_id(hidden), t1.v(hidden), t2.v(hidden)], stream_key: [t1._row_id, t2._row_id, t1.v, t2.v], pk_columns: [t1._row_id, t2._row_id, t1.v, t2.v], pk_conflict: NoCheck }
    └─StreamProject { exprs: [$expr1, t1._row_id, t2._row_id, t1.v, t2.v] }
      └─StreamMaterializedExprs { exprs: [PgSleep(t1.v::Float64) as $expr1] }
        └─StreamExchange { dist: HashShard(t1.v, t1._row_id, t2._row_id, t2.v) }
          └─StreamFilter { predicate: (IsNotNull(t1._row_id) OR IsNotNull(t2._row_id)) }
            └─StreamHashJoin { type: FullOuter, predicate: t1.v = t2.v, output: [t1.v, t1._row_id, t2._row_id, t2.v] }
              ├─StreamExchange { dist: HashShard(t1.v) }
              │ └─StreamTableScan { table: t1, columns: [t1.v, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
              └─StreamExchange { dist: HashShard(t2.v) }
                └─StreamTableScan { table: t2, columns: [t2.v, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [pg_sleep, t1._row_id(hidden), t2._row_id(hidden), t1.v(hidden), t2.v(hidden)], stream_key: [t1._row_id, t2._row_id, t1.v, t2.v], pk_columns: [t1._row_id, t2._row_id, t1.v, t2.v], pk_conflict: NoCheck }
    └── StreamProject { exprs: [$expr1, t1._row_id, t2._row_id, t1.v, t2.v] }
        └── StreamMaterializedExprs { exprs: [PgSleep(t1.v::Float64) as $expr1] } { tables: [ MaterializedExprs: 0 ] }
            └── StreamExchange Hash([0, 1, 2, 3]) from 1

    Fragment 1
    StreamFilter { predicate: (IsNotNull(t1._row_id) OR IsNotNull(t2._row_id)) }
    └── StreamHashJoin { type: FullOuter, predicate: t1.v = t2.v, output: [t1.v, t1._row_id, t2._row_id, t2.v] } { tables: [ HashJoinLeft: 1, HashJoinDegreeLeft: 2, HashJoinRight: 3, HashJoinDegreeRight: 4 ] }
        ├── StreamExchange Hash([0]) from 2
        └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: t1, columns: [t1.v, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) } { tables: [ StreamScan: 5 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: t2, columns: [t2.v, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) } { tables: [ StreamScan: 6 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ t1_v, t1__row_id, t2__row_id, t2_v, $expr1, _rw_timestamp ], primary key: [ $1 ASC, $2 ASC, $0 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 0, 1, 2, 3 ], read pk prefix len hint: 4 }

    Table 1 { columns: [ t1_v, t1__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ t1_v, t1__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ t2_v, t2__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ t2_v, t2__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ pg_sleep, t1._row_id, t2._row_id, t1.v, t2.v, _rw_timestamp ]
    ├── primary key: [ $1 ASC, $2 ASC, $3 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 3, 1, 2, 4 ]
    └── read pk prefix len hint: 4

- before:
  - create_append_only_table
  sql: |
    select id, value, openai_embedding('{"api_key":"sk-test-key", "model": "text-embedding-3-small"}'::jsonb, value) as embedding
    from t;
  logical_plan: |-
    LogicalProject { exprs: [t.id, t.value, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
    └─LogicalScan { table: t, columns: [t.id, t.value, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.id, t.value, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1] }
      └─BatchScan { table: t, columns: [t.id, t.value], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, value, embedding, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.id, t.value, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr1, t._row_id] }
      └─StreamTableScan { table: t, columns: [t.id, t.value, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- before:
  - create_append_only_table
  sql: |
    select id, value, id + 1 as id_plus_one,
           openai_embedding('{"api_key":"sk-test-key", "model": "text-embedding-3-small"}'::jsonb, value) as embedding,
           upper(value) as upper_value
    from t;
  logical_plan: |-
    LogicalProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr1, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr2, Upper(t.value) as $expr3] }
    └─LogicalScan { table: t, columns: [t.id, t.value, t._row_id, t._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr1, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr2, Upper(t.value) as $expr3] }
      └─BatchScan { table: t, columns: [t.id, t.value], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, value, id_plus_one, embedding, upper_value, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.id, t.value, (t.id + 1:Int32) as $expr1, OpenaiEmbedding('{"api_key": "sk-test-key", "model": "text-embedding-3-small"}':Jsonb, t.value) as $expr2, Upper(t.value) as $expr3, t._row_id] }
      └─StreamTableScan { table: t, columns: [t.id, t.value, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
