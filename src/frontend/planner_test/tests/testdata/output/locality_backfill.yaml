# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    set enable_locality_backfill = true;
    create table t (a int, b int, c int);
    select count(*) from t group by b;
  stream_plan: |-
    StreamMaterialize { columns: [count, t.b(hidden)], stream_key: [t.b], pk_columns: [t.b], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, t.b] }
      └─StreamHashAgg { group_key: [t.b], aggs: [count] }
        └─StreamLocalityProvider { locality_columns: [t.b] }
          └─StreamExchange { dist: HashShard(t.b) }
            └─StreamTableScan { table: t, columns: [t.b, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    set enable_locality_backfill = true;
    create table t1 (a int, b int, c int);
    create table t2 (a int, b int, c int);
    select count(*) from t1 join t2 on t1.a = t2.a group by t1.b;
  stream_plan: |-
    StreamMaterialize { columns: [count, t1.b(hidden)], stream_key: [t1.b], pk_columns: [t1.b], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, t1.b] }
      └─StreamHashAgg { group_key: [t1.b], aggs: [count] }
        └─StreamLocalityProvider { locality_columns: [t1.b] }
          └─StreamExchange { dist: HashShard(t1.b) }
            └─StreamHashJoin { type: Inner, predicate: t1.a = t2.a, output: [t1.b, t1._row_id, t1.a, t2._row_id] }
              ├─StreamExchange { dist: HashShard(t1.a) }
              │ └─StreamLocalityProvider { locality_columns: [t1.a] }
              │   └─StreamExchange { dist: HashShard(t1.a) }
              │     └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
              └─StreamExchange { dist: HashShard(t2.a) }
                └─StreamLocalityProvider { locality_columns: [t2.a] }
                  └─StreamExchange { dist: HashShard(t2.a) }
                    └─StreamTableScan { table: t2, columns: [t2.a, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
- sql: |
    set enable_locality_backfill = true;
    create table t (a int, b int, c int, primary key (b, a));
    select count(*) from t group by a, b;
  stream_plan: |-
    StreamMaterialize { columns: [count, t.a(hidden), t.b(hidden)], stream_key: [t.a, t.b], pk_columns: [t.a, t.b], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, t.a, t.b] }
      └─StreamHashAgg { group_key: [t.a, t.b], aggs: [count] }
        └─StreamLocalityProvider { locality_columns: [t.a, t.b] }
          └─StreamExchange [no_shuffle] { dist: UpstreamHashShard(t.b, t.a) }
            └─StreamTableScan { table: t, columns: [t.a, t.b], stream_scan_type: ArrangementBackfill, stream_key: [t.b, t.a], pk: [b, a], dist: UpstreamHashShard(t.b, t.a) }
- sql: |
    set enable_locality_backfill = true;
    create table t (a int, b int, c int);
    select count(*) from t where c > 1 group by a, b;
  stream_plan: |-
    StreamMaterialize { columns: [count, t.a(hidden), t.b(hidden)], stream_key: [t.a, t.b], pk_columns: [t.a, t.b], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, t.a, t.b] }
      └─StreamHashAgg { group_key: [t.a, t.b], aggs: [count] }
        └─StreamLocalityProvider { locality_columns: [t.a, t.b] }
          └─StreamExchange { dist: HashShard(t.a, t.b) }
            └─StreamProject { exprs: [t.a, t.b, t._row_id] }
              └─StreamFilter { predicate: (t.c > 1:Int32) }
                └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id, t.c], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    set enable_locality_backfill = true;
    create table t1 (a int, b int, c int);
    create table t2 (a int, b int, c int);
    select count(*) from t1 join t2 on t1.a = t2.a where t1.c > t2.c group by t1.b;
  stream_plan: |-
    StreamMaterialize { columns: [count, t1.b(hidden)], stream_key: [t1.b], pk_columns: [t1.b], pk_conflict: NoCheck }
    └─StreamProject { exprs: [count, t1.b] }
      └─StreamHashAgg { group_key: [t1.b], aggs: [count] }
        └─StreamLocalityProvider { locality_columns: [t1.b] }
          └─StreamExchange { dist: HashShard(t1.b) }
            └─StreamProject { exprs: [t1.b, t1._row_id, t1.a, t2._row_id] }
              └─StreamFilter { predicate: (t1.c > t2.c) }
                └─StreamHashJoin { type: Inner, predicate: t1.a = t2.a, output: all }
                  ├─StreamExchange { dist: HashShard(t1.a) }
                  │ └─StreamLocalityProvider { locality_columns: [t1.a] }
                  │   └─StreamExchange { dist: HashShard(t1.a) }
                  │     └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
                  └─StreamExchange { dist: HashShard(t2.a) }
                    └─StreamLocalityProvider { locality_columns: [t2.a] }
                      └─StreamExchange { dist: HashShard(t2.a) }
                        └─StreamTableScan { table: t2, columns: [t2.a, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
- sql: |
    set enable_locality_backfill = true;
    create table t (a int, b int, c int);
    select RANK() OVER (PARTITION BY a ORDER BY b) as rank from t;
  stream_plan: |-
    StreamMaterialize { columns: [rank, t._row_id(hidden), t.a(hidden)], stream_key: [t.a, t._row_id], pk_columns: [t.a, t._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [rank, t._row_id, t.a] }
      └─StreamOverWindow { window_functions: [rank() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
        └─StreamLocalityProvider { locality_columns: [t.a] }
          └─StreamExchange { dist: HashShard(t.a) }
            └─StreamTableScan { table: t, columns: [t.a, t.b, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: enforce locality for temporal join for both sides.
  sql: |
    set enable_locality_backfill = true;
    create table stream(id1 int, a1 int, b1 int);
    create table version(id2 int, a2 int, b2 int, primary key (id2));
    create index idx2 on version (a2, b2);
    select id1, a1, id2, a2 from stream left join version FOR SYSTEM_TIME AS OF PROCTIME() on a1 = a2 and b1 = b2;
  stream_plan: |-
    StreamMaterialize { columns: [id1, a1, id2, a2, stream._row_id(hidden), stream.b1(hidden)], stream_key: [a1, stream.b1, stream._row_id, id2], pk_columns: [a1, stream.b1, stream._row_id, id2], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(stream.a1, idx2.id2, stream._row_id, stream.b1) }
      └─StreamTemporalJoin { type: LeftOuter, append_only: false, predicate: stream.a1 = idx2.a2 AND stream.b1 = idx2.b2, nested_loop: false, output: [stream.id1, stream.a1, idx2.id2, idx2.a2, stream._row_id, stream.b1] }
        ├─StreamExchange { dist: HashShard(stream.a1) }
        │ └─StreamLocalityProvider { locality_columns: [stream.a1, stream.b1] }
        │   └─StreamExchange { dist: HashShard(stream.a1, stream.b1) }
        │     └─StreamTableScan { table: stream, columns: [stream.id1, stream.a1, stream.b1, stream._row_id], stream_scan_type: ArrangementBackfill, stream_key: [stream._row_id], pk: [_row_id], dist: UpstreamHashShard(stream._row_id) }
        └─StreamExchange [no_shuffle] { dist: UpstreamHashShard(idx2.a2) }
          └─StreamTableScan { table: idx2, columns: [idx2.id2, idx2.a2, idx2.b2], stream_scan_type: UpstreamOnly, stream_key: [idx2.a2, idx2.id2], pk: [a2, b2, id2], dist: UpstreamHashShard(idx2.a2) }
- sql: |
    set enable_locality_backfill = true;
    create table t(a int, b int, c int) append only;
    select distinct on(a) * from t ;
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c, t._row_id(hidden)], stream_key: [a], pk_columns: [a], pk_conflict: NoCheck }
    └─StreamAppendOnlyDedup { dedup_cols: [t.a] }
      └─StreamExchange { dist: HashShard(t.a) }
        └─StreamLocalityProvider { locality_columns: [t.a] }
          └─StreamExchange { dist: HashShard(t.a) }
            └─StreamTableScan { table: t, columns: [t.a, t.b, t.c, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    set enable_locality_backfill = true;
    create table t(a int, b int, c int);
    SELECT * FROM (
    SELECT
        *,
        row_number() OVER (PARTITION BY a ORDER BY b) AS rank
        FROM t
    ) WHERE rank <= 1;
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c, rank], stream_key: [a], pk_columns: [a], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY t.a ORDER BY t.b ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamLocalityProvider { locality_columns: [t.a] }
        └─StreamExchange [no_shuffle] { dist: UpstreamHashShard(t.a) }
          └─StreamProject { exprs: [t.a, t.b, t.c] }
            └─StreamGroupTopN { order: [t.b ASC], limit: 1, offset: 0, group_key: [t.a] }
              └─StreamLocalityProvider { locality_columns: [t.a] }
                └─StreamExchange { dist: HashShard(t.a) }
                  └─StreamTableScan { table: t, columns: [t.a, t.b, t.c, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
