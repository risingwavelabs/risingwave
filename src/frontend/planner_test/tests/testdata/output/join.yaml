# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v3 int, v4 int);
    create table t3 (v5 int, v6 int);
    select * from t1, t2, t3 where t1.v1 = t2.v3 and t1.v1 = t3.v5;
  logical_plan: |-
    LogicalProject { exprs: [t1.v1, t1.v2, t2.v3, t2.v4, t3.v5, t3.v6] }
    └─LogicalFilter { predicate: (t1.v1 = t2.v3) AND (t1.v1 = t3.v5) }
      └─LogicalJoin { type: Inner, on: true, output: all }
        ├─LogicalJoin { type: Inner, on: true, output: all }
        │ ├─LogicalScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id, t1._rw_timestamp] }
        │ └─LogicalScan { table: t2, columns: [t2.v3, t2.v4, t2._row_id, t2._rw_timestamp] }
        └─LogicalScan { table: t3, columns: [t3.v5, t3.v6, t3._row_id, t3._rw_timestamp] }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, v3, v4, v5, v6, t1._row_id(hidden), t2._row_id(hidden), t3._row_id(hidden)], stream_key: [t1._row_id, t2._row_id, v1, t3._row_id], pk_columns: [t1._row_id, t2._row_id, v1, t3._row_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t1.v1, t1._row_id, t2._row_id, t3._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t1.v1 = t3.v5, output: [t1.v1, t1.v2, t2.v3, t2.v4, t3.v5, t3.v6, t1._row_id, t2._row_id, t3._row_id] }
        ├─StreamHashJoin { type: Inner, predicate: t1.v1 = t2.v3, output: [t1.v1, t1.v2, t2.v3, t2.v4, t1._row_id, t2._row_id] }
        │ ├─StreamExchange { dist: HashShard(t1.v1) }
        │ │ └─StreamTableScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        │ └─StreamExchange { dist: HashShard(t2.v3) }
        │   └─StreamTableScan { table: t2, columns: [t2.v3, t2.v4, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        └─StreamExchange { dist: HashShard(t3.v5) }
          └─StreamTableScan { table: t3, columns: [t3.v5, t3.v6, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
- name: unaligned join
  sql: |
    set streaming_enable_unaligned_join=true;
    create table t1 (v1 int, v2 int);
    create table t2 (v3 int, v4 int);
    create table t3 (v5 int, v6 int);
    select * from t1, t2, t3 where t1.v1 = t2.v3 and t1.v1 = t3.v5;
  logical_plan: |-
    LogicalProject { exprs: [t1.v1, t1.v2, t2.v3, t2.v4, t3.v5, t3.v6] }
    └─LogicalFilter { predicate: (t1.v1 = t2.v3) AND (t1.v1 = t3.v5) }
      └─LogicalJoin { type: Inner, on: true, output: all }
        ├─LogicalJoin { type: Inner, on: true, output: all }
        │ ├─LogicalScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id, t1._rw_timestamp] }
        │ └─LogicalScan { table: t2, columns: [t2.v3, t2.v4, t2._row_id, t2._rw_timestamp] }
        └─LogicalScan { table: t3, columns: [t3.v5, t3.v6, t3._row_id, t3._rw_timestamp] }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, v3, v4, v5, v6, t1._row_id(hidden), t2._row_id(hidden), t3._row_id(hidden)], stream_key: [t1._row_id, t2._row_id, v1, t3._row_id], pk_columns: [t1._row_id, t2._row_id, v1, t3._row_id], pk_conflict: NoCheck }
    └─StreamSyncLogStore { buffer_size: 2048, pause_duration_ms: 256 }
      └─StreamHashJoin { type: Inner, predicate: t1.v1 = t3.v5, output: [t1.v1, t1.v2, t2.v3, t2.v4, t3.v5, t3.v6, t1._row_id, t2._row_id, t3._row_id] }
        ├─StreamSyncLogStore { buffer_size: 2048, pause_duration_ms: 256 }
        │ └─StreamHashJoin { type: Inner, predicate: t1.v1 = t2.v3, output: [t1.v1, t1.v2, t2.v3, t2.v4, t1._row_id, t2._row_id] }
        │   ├─StreamExchange { dist: HashShard(t1.v1) }
        │   │ └─StreamTableScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        │   └─StreamExchange { dist: HashShard(t2.v3) }
        │     └─StreamTableScan { table: t2, columns: [t2.v3, t2.v4, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        └─StreamExchange { dist: HashShard(t3.v5) }
          └─StreamTableScan { table: t3, columns: [t3.v5, t3.v6, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
- name: self join
  sql: |
    create table t (v1 int, v2 int);
    select t1.v1 as t1v1, t2.v1 as t2v1 from t t1 join t t2 on t1.v1 = t2.v1;
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v1] }
    └─LogicalJoin { type: Inner, on: (t.v1 = t.v1), output: all }
      ├─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
  stream_plan: |-
    StreamMaterialize { columns: [t1v1, t2v1, t._row_id(hidden), t._row_id#1(hidden)], stream_key: [t._row_id, t._row_id#1, t1v1], pk_columns: [t._row_id, t._row_id#1, t1v1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.v1, t._row_id, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.v1 = t.v1, output: [t.v1, t.v1, t._row_id, t._row_id] }
        ├─StreamExchange { dist: HashShard(t.v1) }
        │ └─StreamTableScan { table: t, columns: [t.v1, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamExchange { dist: HashShard(t.v1) }
          └─StreamTableScan { table: t, columns: [t.v1, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    create table t3 (v1 int, v2 int);
    select t1.v1 as t1_v1, t1.v2 as t1_v2, t2.v1 as t2_v1, t2.v2 as t2_v2, t3.v1 as t3_v1, t3.v2 as t3_v2 from t1 join t2 on (t1.v1 = t2.v1) join t3 on (t2.v2 = t3.v2);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t2.v2 = t3.v2, output: all }
      ├─BatchExchange { order: [], dist: HashShard(t2.v2) }
      │ └─BatchHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: all }
      │   ├─BatchExchange { order: [], dist: HashShard(t1.v1) }
      │   │ └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
      │   └─BatchExchange { order: [], dist: HashShard(t2.v1) }
      │     └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t3.v2) }
        └─BatchScan { table: t3, columns: [t3.v1, t3.v2], distribution: SomeShard }
  batch_local_plan: |-
    BatchHashJoin { type: Inner, predicate: t2.v2 = t3.v2, output: all }
    ├─BatchHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: all }
    │ ├─BatchExchange { order: [], dist: Single }
    │ │ └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
    │ └─BatchExchange { order: [], dist: Single }
    │   └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t3, columns: [t3.v1, t3.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [t1_v1, t1_v2, t2_v1, t2_v2, t3_v1, t3_v2, t1._row_id(hidden), t2._row_id(hidden), t3._row_id(hidden)], stream_key: [t1._row_id, t2._row_id, t1_v1, t3._row_id, t2_v2], pk_columns: [t1._row_id, t2._row_id, t1_v1, t3._row_id, t2_v2], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t1.v1, t2.v2, t1._row_id, t2._row_id, t3._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t2.v2 = t3.v2, output: [t1.v1, t1.v2, t2.v1, t2.v2, t3.v1, t3.v2, t1._row_id, t2._row_id, t3._row_id] }
        ├─StreamExchange { dist: HashShard(t2.v2) }
        │ └─StreamHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: [t1.v1, t1.v2, t2.v1, t2.v2, t1._row_id, t2._row_id] }
        │   ├─StreamExchange { dist: HashShard(t1.v1) }
        │   │ └─StreamTableScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        │   └─StreamExchange { dist: HashShard(t2.v1) }
        │     └─StreamTableScan { table: t2, columns: [t2.v1, t2.v2, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        └─StreamExchange { dist: HashShard(t3.v2) }
          └─StreamTableScan { table: t3, columns: [t3.v1, t3.v2, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
- sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    select t1.v2 as t1_v2, t2.v2 as t2_v2 from t1 join t2 on t1.v1 = t2.v1;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: [t1.v2, t2.v2] }
      ├─BatchExchange { order: [], dist: HashShard(t1.v1) }
      │ └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t2.v1) }
        └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
  batch_local_plan: |-
    BatchHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: [t1.v2, t2.v2] }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [t1_v2, t2_v2, t1._row_id(hidden), t1.v1(hidden), t2._row_id(hidden)], stream_key: [t1._row_id, t2._row_id, t1.v1], pk_columns: [t1._row_id, t2._row_id, t1.v1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t1._row_id, t1.v1, t2._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: [t1.v2, t2.v2, t1._row_id, t1.v1, t2._row_id] }
        ├─StreamExchange { dist: HashShard(t1.v1) }
        │ └─StreamTableScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        └─StreamExchange { dist: HashShard(t2.v1) }
          └─StreamTableScan { table: t2, columns: [t2.v1, t2.v2, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
- sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    select t1.v2 as t1_v2, t2.v2 as t2_v2 from t1 join t2 on t1.v1 > t2.v1 and t1.v2 < 10;
  batch_plan: |-
    BatchNestedLoopJoin { type: Inner, predicate: (t1.v1 > t2.v1), output: [t1.v2, t2.v2] }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchFilter { predicate: (t1.v2 < 10:Int32) }
    │   └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
  batch_local_plan: |-
    BatchNestedLoopJoin { type: Inner, predicate: (t1.v1 > t2.v1), output: [t1.v2, t2.v2] }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchFilter { predicate: (t1.v2 < 10:Int32) }
    │   └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t2, columns: [t2.v1, t2.v2], distribution: SomeShard }
- sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v3 int);
    select * from t1 join t2 using(v1);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t1.v1 = t2.v1, output: [t1.v1, t1.v2, t2.v3] }
      ├─BatchExchange { order: [], dist: HashShard(t1.v1) }
      │ └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t2.v1) }
        └─BatchScan { table: t2, columns: [t2.v1, t2.v3], distribution: SomeShard }
- sql: |
    create table ab (a int, b int);
    create table bc (b int, c int);
    create table ca (c int, a int);
    select * from ab join bc using(b) join ca using(c);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: bc.c = ca.c, output: [bc.c, ab.b, ab.a, ca.a] }
      ├─BatchExchange { order: [], dist: HashShard(bc.c) }
      │ └─BatchHashJoin { type: Inner, predicate: ab.b = bc.b, output: [ab.a, ab.b, bc.c] }
      │   ├─BatchExchange { order: [], dist: HashShard(ab.b) }
      │   │ └─BatchScan { table: ab, columns: [ab.a, ab.b], distribution: SomeShard }
      │   └─BatchExchange { order: [], dist: HashShard(bc.b) }
      │     └─BatchScan { table: bc, columns: [bc.b, bc.c], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(ca.c) }
        └─BatchScan { table: ca, columns: [ca.c, ca.a], distribution: SomeShard }
- name: Left & right has same SomeShard distribution. There should still be exchanges below hash join
  sql: |
    create table t(x int);
    create index i on t(x);
    select i.x as ix, ii.x as iix from i join i as ii on i.x=ii.x;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: i.x = i.x, output: all, lookup table: i }
      └─BatchScan { table: i, columns: [i.x], distribution: UpstreamHashShard(i.x) }
  stream_plan: |-
    StreamMaterialize { columns: [ix, iix, i.t._row_id(hidden), i.t._row_id#1(hidden)], stream_key: [i.t._row_id, i.t._row_id#1, ix], pk_columns: [i.t._row_id, i.t._row_id#1, ix], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(i.x, i.t._row_id, i.t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: i.x = i.x, output: [i.x, i.x, i.t._row_id, i.t._row_id] }
        ├─StreamExchange { dist: HashShard(i.x) }
        │ └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
        └─StreamExchange { dist: HashShard(i.x) }
          └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
- name: Left & right has same SomeShard distribution. There should still be exchanges below hash join
  sql: |
    create table t(x int);
    create index i on t(x);
    select i.x as ix, t.x as tx from i join t on i.x=t.x;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: i.x = i.x, output: all, lookup table: i }
      └─BatchScan { table: i, columns: [i.x], distribution: UpstreamHashShard(i.x) }
  stream_plan: |-
    StreamMaterialize { columns: [ix, tx, i.t._row_id(hidden), t._row_id(hidden)], stream_key: [i.t._row_id, t._row_id, ix], pk_columns: [i.t._row_id, t._row_id, ix], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(i.x, i.t._row_id, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: i.x = t.x, output: [i.x, t.x, i.t._row_id, t._row_id] }
        ├─StreamExchange { dist: HashShard(i.x) }
        │ └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: Left & right has same HashShard distribution. There should be no exchange below hash join
  sql: |
    create table t(x int);
    create index i on t(x);
    select * from
      (select * from i join i as ii using (x)) t1
    full join
      (select * from i join i as ii using (x)) t2
    using (x);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [Coalesce(i.x, i.x) as $expr1] }
      └─BatchHashJoin { type: FullOuter, predicate: i.x = i.x, output: all }
        ├─BatchExchange { order: [], dist: HashShard(i.x) }
        │ └─BatchLookupJoin { type: Inner, predicate: i.x = i.x, output: [i.x], lookup table: i }
        │   └─BatchScan { table: i, columns: [i.x], distribution: UpstreamHashShard(i.x) }
        └─BatchExchange { order: [], dist: HashShard(i.x) }
          └─BatchLookupJoin { type: Inner, predicate: i.x = i.x, output: [i.x], lookup table: i }
            └─BatchScan { table: i, columns: [i.x], distribution: UpstreamHashShard(i.x) }
  stream_plan: |-
    StreamMaterialize { columns: [x, i.t._row_id(hidden), i.t._row_id#1(hidden), i.x(hidden), i.t._row_id#2(hidden), i.t._row_id#3(hidden), i.x#1(hidden)], stream_key: [i.t._row_id, i.t._row_id#1, i.x, i.t._row_id#2, i.t._row_id#3, i.x#1], pk_columns: [i.t._row_id, i.t._row_id#1, i.x, i.t._row_id#2, i.t._row_id#3, i.x#1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(i.t._row_id, i.t._row_id, i.x, i.t._row_id, i.t._row_id, i.x) }
      └─StreamProject { exprs: [Coalesce(i.x, i.x) as $expr1, i.t._row_id, i.t._row_id, i.x, i.t._row_id, i.t._row_id, i.x] }
        └─StreamFilter { predicate: (((IsNotNull(i.t._row_id) OR IsNotNull(i.t._row_id)) OR (IsNotNull(i.x) OR IsNotNull(i.t._row_id))) OR (IsNotNull(i.t._row_id) OR IsNotNull(i.x))) }
          └─StreamHashJoin { type: FullOuter, predicate: i.x = i.x, output: [i.x, i.x, i.t._row_id, i.t._row_id, i.t._row_id, i.t._row_id] }
            ├─StreamShare { id: 4 }
            │ └─StreamHashJoin { type: Inner, predicate: i.x = i.x, output: [i.x, i.t._row_id, i.t._row_id] }
            │   ├─StreamExchange { dist: HashShard(i.x) }
            │   │ └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
            │   └─StreamExchange { dist: HashShard(i.x) }
            │     └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
            └─StreamShare { id: 4 }
              └─StreamHashJoin { type: Inner, predicate: i.x = i.x, output: [i.x, i.t._row_id, i.t._row_id] }
                ├─StreamExchange { dist: HashShard(i.x) }
                │ └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
                └─StreamExchange { dist: HashShard(i.x) }
                  └─StreamTableScan { table: i, columns: [i.x, i.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [i.t._row_id], pk: [x, t._row_id], dist: UpstreamHashShard(i.x) }
- name: Use lookup join
  sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    create materialized view t3 as select v1, count(v2) as v2 from t2 group by v1;
    select * from t1 cross join t3 where t1.v2 = t3.v1;
  batch_local_plan: |-
    BatchLookupJoin { type: Inner, predicate: t1.v2 = t3.v1, output: all, lookup table: t3 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
  with_config_map:
    QUERY_MODE: local
    RW_BATCH_ENABLE_LOOKUP_JOIN: 'true'
- name: Ensure correct binding of join with USING clause
  sql: |
    create table t1(v1 varchar);
    create table t2(v1 varchar);
    create table t3(v2 varchar);
    select * from t3, t1 join t2 using (v1);
  logical_plan: |-
    LogicalProject { exprs: [t1.v1, t3.v2] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalScan { table: t3, columns: [t3.v2, t3._row_id, t3._rw_timestamp] }
      └─LogicalJoin { type: Inner, on: (t1.v1 = t2.v1), output: all }
        ├─LogicalScan { table: t1, columns: [t1.v1, t1._row_id, t1._rw_timestamp] }
        └─LogicalScan { table: t2, columns: [t2.v1, t2._row_id, t2._rw_timestamp] }
- name: Ensure correct binding of join with ON clause
  sql: |
    create table t1(v1 varchar);
    create table t2(v2 varchar);
    create table t3(v3 varchar);
    select * from t3, t1 join t2 on v1 = v2;
  logical_plan: |-
    LogicalProject { exprs: [t3.v3, t1.v1, t2.v2] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalScan { table: t3, columns: [t3.v3, t3._row_id, t3._rw_timestamp] }
      └─LogicalJoin { type: Inner, on: (t1.v1 = t2.v2), output: all }
        ├─LogicalScan { table: t1, columns: [t1.v1, t1._row_id, t1._rw_timestamp] }
        └─LogicalScan { table: t2, columns: [t2.v2, t2._row_id, t2._rw_timestamp] }
- name: Ensure correct binding with USING clause with left outer join
  sql: |
    create table t1(v1 varchar);
    create table t2(v1 varchar);
    create table t3(v2 varchar);
    select * from t3, t1 left join t2 using (v1);
  logical_plan: |-
    LogicalProject { exprs: [t1.v1, t3.v2] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalScan { table: t3, columns: [t3.v2, t3._row_id, t3._rw_timestamp] }
      └─LogicalJoin { type: LeftOuter, on: (t1.v1 = t2.v1), output: all }
        ├─LogicalScan { table: t1, columns: [t1.v1, t1._row_id, t1._rw_timestamp] }
        └─LogicalScan { table: t2, columns: [t2.v1, t2._row_id, t2._rw_timestamp] }
- name: Ensure correct binding with ON clause with left outer join
  sql: |
    create table t1(v1 varchar);
    create table t2(v2 varchar);
    create table t3(v3 varchar);
    select * from t3, t1 left join t2 on v1 = v2;
  logical_plan: |-
    LogicalProject { exprs: [t3.v3, t1.v1, t2.v2] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalScan { table: t3, columns: [t3.v3, t3._row_id, t3._rw_timestamp] }
      └─LogicalJoin { type: LeftOuter, on: (t1.v1 = t2.v2), output: all }
        ├─LogicalScan { table: t1, columns: [t1.v1, t1._row_id, t1._rw_timestamp] }
        └─LogicalScan { table: t2, columns: [t2.v2, t2._row_id, t2._rw_timestamp] }
- name: Ensure that ON clause cannot reference correlated columns
  sql: |
    create table a(a1 int);
    create table b(b1 int);
    create table c(c1 int);
    select * from a, b join c on a1 + b1 = c1;
  binder_error: |
    Failed to bind expression: a1 + b1 = c1

    Caused by:
      Item not found: Invalid column: a1
- sql: |
    create table a(a1 int);
    create table b(b1 int);
    select * from a cross join lateral (select * from b where a1 = b1);
  logical_plan: |-
    LogicalProject { exprs: [a.a1, b.b1] }
    └─LogicalApply { type: Inner, on: true, correlated_id: 1 }
      ├─LogicalScan { table: a, columns: [a.a1, a._row_id, a._rw_timestamp] }
      └─LogicalProject { exprs: [b.b1] }
        └─LogicalFilter { predicate: (CorrelatedInputRef { index: 0, correlated_id: 1 } = b.b1) }
          └─LogicalScan { table: b, columns: [b.b1, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    create table c(y int);
    select * from a natural join b natural join c;
  logical_plan: |-
    LogicalProject { exprs: [a.x, c.y] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      │ ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.y, c._row_id, c._rw_timestamp] }
- name: Ensure that natural joins can disambiguate columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x, a.x, b.x from a natural join b;
  logical_plan: |-
    LogicalProject { exprs: [a.x, a.x, b.x] }
    └─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    create table c(y int);
    select * from a natural join b natural join c;
  logical_plan: |-
    LogicalProject { exprs: [a.x, c.y] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      │ ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.y, c._row_id, c._rw_timestamp] }
- name: Ensure that natural joins can disambiguate columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x, a.x, b.x from a natural join b;
  logical_plan: |-
    LogicalProject { exprs: [a.x, a.x, b.x] }
    └─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    create table c(y int);
    select * from a natural join b natural join c;
  logical_plan: |-
    LogicalProject { exprs: [a.x, c.y] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      │ ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.y, c._row_id, c._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x from a natural join b;
  logical_plan: |-
    LogicalProject { exprs: [a.x] }
    └─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x from a natural left join b;
  logical_plan: |-
    LogicalProject { exprs: [a.x] }
    └─LogicalJoin { type: LeftOuter, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x, a.x, b.x from a natural right join b;
  logical_plan: |-
    LogicalProject { exprs: [b.x, a.x, b.x] }
    └─LogicalJoin { type: RightOuter, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins bind the correct columns
  sql: |
    create table a(x int);
    create table b(x int);
    select x, a.x, b.x from a natural full join b;
  logical_plan: |-
    LogicalProject { exprs: [Coalesce(a.x, b.x) as $expr1, a.x, b.x] }
    └─LogicalJoin { type: FullOuter, on: (a.x = b.x), output: all }
      ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
      └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
- name: Ensure that natural joins work on materialized views
  sql: |
    create table t (a int, b int, c int);
    create materialized view mv1 as select *, lag(a) over (partition by c) out1 from t;
    create materialized view mv2 as select *, lead(b) over (partition by c) out2 from t;
    select * from mv1 natural join mv2;
  logical_plan: |-
    LogicalProject { exprs: [mv1.c, mv1.b, mv1.a, mv1.out1, mv2.out2] }
    └─LogicalJoin { type: Inner, on: (mv1.a = mv2.a) AND (mv1.b = mv2.b) AND (mv1.c = mv2.c), output: all }
      ├─LogicalScan { table: mv1, columns: [mv1.a, mv1.b, mv1.c, mv1.t._row_id, mv1.out1, mv1._rw_timestamp] }
      └─LogicalScan { table: mv2, columns: [mv2.a, mv2.b, mv2.c, mv2.t._row_id, mv2.out2, mv2._rw_timestamp] }
- name: Ensure that nested natural joins bind and disambiguate columns
  sql: |
    create table a(x int, y int);
    create table b(x int, z int);
    create table c(x int, a int);
    select x, a.x, b.x, c.x from a natural join b natural join c;
  logical_plan: |-
    LogicalProject { exprs: [a.x, a.x, b.x, c.x] }
    └─LogicalJoin { type: Inner, on: (a.x = c.x), output: all }
      ├─LogicalJoin { type: Inner, on: (a.x = b.x), output: all }
      │ ├─LogicalScan { table: a, columns: [a.x, a.y, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b.z, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.x, c.a, c._row_id, c._rw_timestamp] }
- name: Ensure that nested natural joins bind and disambiguate columns
  sql: |
    create table a(x int, y int);
    create table b(x int, z int);
    create table c(x int, a int);
    select x, a.x, b.x, c.x from a natural full join b natural full join c;
  logical_plan: |-
    LogicalProject { exprs: [Coalesce(a.x, b.x, c.x) as $expr1, a.x, b.x, c.x] }
    └─LogicalJoin { type: FullOuter, on: (Coalesce(a.x, b.x) = c.x), output: all }
      ├─LogicalJoin { type: FullOuter, on: (a.x = b.x), output: all }
      │ ├─LogicalScan { table: a, columns: [a.x, a.y, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b.z, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.x, c.a, c._row_id, c._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [Coalesce(a.x, b.x, c.x) as $expr2, a.x, b.x, c.x] }
    └─LogicalJoin { type: FullOuter, on: ($expr1 = c.x), output: [a.x, b.x, c.x] }
      ├─LogicalProject { exprs: [a.x, b.x, Coalesce(a.x, b.x) as $expr1] }
      │ └─LogicalJoin { type: FullOuter, on: (a.x = b.x), output: all }
      │   ├─LogicalScan { table: a, columns: [a.x] }
      │   └─LogicalScan { table: b, columns: [b.x] }
      └─LogicalScan { table: c, columns: [c.x] }
- name: Ensure that nested natural joins bind and disambiguate columns
  sql: |
    create table a(a int, y int);
    create table b(x int, z int);
    create table c(x int, a int);
    select a, x, a.a, c.a, b.x, c.x from a natural full join b natural full join c;
  logical_plan: |-
    LogicalProject { exprs: [Coalesce(a.a, c.a) as $expr1, Coalesce(b.x, c.x) as $expr2, a.a, c.a, b.x, c.x] }
    └─LogicalJoin { type: FullOuter, on: (a.a = c.a) AND (b.x = c.x), output: all }
      ├─LogicalJoin { type: FullOuter, on: true, output: all }
      │ ├─LogicalScan { table: a, columns: [a.a, a.y, a._row_id, a._rw_timestamp] }
      │ └─LogicalScan { table: b, columns: [b.x, b.z, b._row_id, b._rw_timestamp] }
      └─LogicalScan { table: c, columns: [c.x, c.a, c._row_id, c._rw_timestamp] }
- name: Ensure error on non-existent USING col
  sql: |
    create table t1(v1 int, v2 int);
    create table t2(v1 int, v3 int);
    select * from t1 join t2 using (v2);
  binder_error: 'Item not found: column "v2" specified in USING clause does not exist in right table'
- name: Ensure error on non-existent USING col
  sql: |
    create table t1(v1 int, v2 int);
    create table t2(v1 int, v3 int);
    select * from t1 join t2 using (v3);
  binder_error: 'Item not found: column "v3" specified in USING clause does not exist in left table'
- name: Ensure that we can correctly bind nested joins
  sql: |
    create table t1(v1 int, v2 int);
    create table t2(v3 int, v4 int);
    create table t3(v5 int, v6 int);
    create table t4(v7 int, v8 int);
    select * from (t1 join t2 on v1=v3) full join (t3 join t4 on v5=v7) on v2=v6 and v4=v8;
  logical_plan: |-
    LogicalProject { exprs: [t1.v1, t1.v2, t2.v3, t2.v4, t3.v5, t3.v6, t4.v7, t4.v8] }
    └─LogicalJoin { type: FullOuter, on: (t1.v2 = t3.v6) AND (t2.v4 = t4.v8), output: all }
      ├─LogicalJoin { type: Inner, on: (t1.v1 = t2.v3), output: all }
      │ ├─LogicalScan { table: t1, columns: [t1.v1, t1.v2, t1._row_id, t1._rw_timestamp] }
      │ └─LogicalScan { table: t2, columns: [t2.v3, t2.v4, t2._row_id, t2._rw_timestamp] }
      └─LogicalJoin { type: Inner, on: (t3.v5 = t4.v7), output: all }
        ├─LogicalScan { table: t3, columns: [t3.v5, t3.v6, t3._row_id, t3._rw_timestamp] }
        └─LogicalScan { table: t4, columns: [t4.v7, t4.v8, t4._row_id, t4._rw_timestamp] }
- name: Ensure that we can correctly bind nested joins with ambiguous column names
  sql: |
    create table t1(x int);
    create table t2(x int);
    create table t3(x int);
    select *, x, t1.x, t2.x, t3.x from t1 full join (t2 full join t3 using (x)) using (x);
  logical_plan: |-
    LogicalProject { exprs: [Coalesce(t1.x, t2.x, t3.x) as $expr1, Coalesce(t1.x, t2.x, t3.x) as $expr2, t1.x, t2.x, t3.x] }
    └─LogicalJoin { type: FullOuter, on: (t1.x = Coalesce(t2.x, t3.x)), output: all }
      ├─LogicalScan { table: t1, columns: [t1.x, t1._row_id, t1._rw_timestamp] }
      └─LogicalJoin { type: FullOuter, on: (t2.x = t3.x), output: all }
        ├─LogicalScan { table: t2, columns: [t2.x, t2._row_id, t2._rw_timestamp] }
        └─LogicalScan { table: t3, columns: [t3.x, t3._row_id, t3._rw_timestamp] }
- name: Ensure that non-trivial ambiguous references can be resolved
  sql: |
    create table a(x int);
    create table b(x int);
    select 2 * x as Y, x + x as Z from a natural full join b where 2 * x < 10 order by x + x;
  logical_plan: |-
    LogicalProject { exprs: [$expr1, $expr2] }
    └─LogicalProject { exprs: [(2:Int32 * Coalesce(a.x, b.x)) as $expr1, (Coalesce(a.x, b.x) + Coalesce(a.x, b.x)) as $expr2, (Coalesce(a.x, b.x) + Coalesce(a.x, b.x)) as $expr3] }
      └─LogicalFilter { predicate: ((2:Int32 * Coalesce(a.x, b.x)) < 10:Int32) }
        └─LogicalJoin { type: FullOuter, on: (a.x = b.x), output: all }
          ├─LogicalScan { table: a, columns: [a.x, a._row_id, a._rw_timestamp] }
          └─LogicalScan { table: b, columns: [b.x, b._row_id, b._rw_timestamp] }
  batch_plan: |-
    BatchProject { exprs: [$expr3, $expr2] }
    └─BatchExchange { order: [$expr2 ASC], dist: Single }
      └─BatchProject { exprs: [(2:Int32 * $expr1) as $expr3, $expr2, $expr2] }
        └─BatchSort { order: [$expr2 ASC] }
          └─BatchProject { exprs: [a.x, b.x, $expr1, ($expr1 + $expr1) as $expr2] }
            └─BatchProject { exprs: [a.x, b.x, Coalesce(a.x, b.x) as $expr1] }
              └─BatchFilter { predicate: ((2:Int32 * Coalesce(a.x, b.x)) < 10:Int32) }
                └─BatchHashJoin { type: FullOuter, predicate: a.x = b.x, output: all }
                  ├─BatchExchange { order: [], dist: HashShard(a.x) }
                  │ └─BatchScan { table: a, columns: [a.x], distribution: SomeShard }
                  └─BatchExchange { order: [], dist: HashShard(b.x) }
                    └─BatchScan { table: b, columns: [b.x], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [y, z, $expr2(hidden), a._row_id(hidden), b._row_id(hidden), a.x(hidden), b.x(hidden)], stream_key: [a._row_id, b._row_id, a.x, b.x], pk_columns: [$expr2, a._row_id, b._row_id, a.x, b.x], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard($expr2) }
      └─StreamProject { exprs: [(2:Int32 * $expr1) as $expr3, $expr2, $expr2, a._row_id, b._row_id, a.x, b.x] }
        └─StreamProject { exprs: [a.x, b.x, $expr1, ($expr1 + $expr1) as $expr2, a._row_id, b._row_id] }
          └─StreamProject { exprs: [a.x, b.x, Coalesce(a.x, b.x) as $expr1, a._row_id, b._row_id] }
            └─StreamFilter { predicate: ((2:Int32 * Coalesce(a.x, b.x)) < 10:Int32) }
              └─StreamFilter { predicate: (IsNotNull(a._row_id) OR IsNotNull(b._row_id)) }
                └─StreamHashJoin { type: FullOuter, predicate: a.x = b.x, output: [a.x, b.x, a._row_id, b._row_id] }
                  ├─StreamExchange { dist: HashShard(a.x) }
                  │ └─StreamTableScan { table: a, columns: [a.x, a._row_id], stream_scan_type: ArrangementBackfill, stream_key: [a._row_id], pk: [_row_id], dist: UpstreamHashShard(a._row_id) }
                  └─StreamExchange { dist: HashShard(b.x) }
                    └─StreamTableScan { table: b, columns: [b.x, b._row_id], stream_scan_type: ArrangementBackfill, stream_key: [b._row_id], pk: [_row_id], dist: UpstreamHashShard(b._row_id) }
- sql: |
    CREATE TABLE test (a INTEGER, b INTEGER);
    CREATE TABLE test2 (a INTEGER, c INTEGER);
    SELECT test.a, b, c FROM test, test2 WHERE test.a = test2.a AND test.b <> test2.c ORDER BY test.a;
  logical_plan: |-
    LogicalProject { exprs: [test.a, test.b, test2.c] }
    └─LogicalProject { exprs: [test.a, test.b, test2.c, test.a] }
      └─LogicalFilter { predicate: (test.a = test2.a) AND (test.b <> test2.c) }
        └─LogicalJoin { type: Inner, on: true, output: all }
          ├─LogicalScan { table: test, columns: [test.a, test.b, test._row_id, test._rw_timestamp] }
          └─LogicalScan { table: test2, columns: [test2.a, test2.c, test2._row_id, test2._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [test.a, test.b, test2.c, test.a] }
    └─LogicalJoin { type: Inner, on: (test.a = test2.a) AND (test.b <> test2.c), output: [test.a, test.b, test2.c] }
      ├─LogicalScan { table: test, columns: [test.a, test.b] }
      └─LogicalScan { table: test2, columns: [test2.a, test2.c] }
  batch_plan: |-
    BatchProject { exprs: [test.a, test.b, test2.c] }
    └─BatchExchange { order: [test.a ASC], dist: Single }
      └─BatchProject { exprs: [test.a, test.b, test2.c, test.a] }
        └─BatchSort { order: [test.a ASC] }
          └─BatchHashJoin { type: Inner, predicate: test.a = test2.a AND (test.b <> test2.c), output: [test.a, test.b, test2.c] }
            ├─BatchExchange { order: [], dist: HashShard(test.a) }
            │ └─BatchScan { table: test, columns: [test.a, test.b], distribution: SomeShard }
            └─BatchExchange { order: [], dist: HashShard(test2.a) }
              └─BatchScan { table: test2, columns: [test2.a, test2.c], distribution: SomeShard }
- name: Use lookup join with predicate
  sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    create materialized view t3 as select v1, count(v2) as v2 from t2 group by v1;
    select * from t1 cross join t3 where t1.v2 = t3.v1 and t3.v1 > 1;
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: Inner, on: (t1.v2 = t3.v1), output: all }
    ├─LogicalScan { table: t1, columns: [t1.v1, t1.v2], predicate: (t1.v2 > 1:Int32) }
    └─LogicalScan { table: t3, columns: [t3.v1, t3.v2], predicate: (t3.v1 > 1:Int32) }
  batch_local_plan: |-
    BatchLookupJoin { type: Inner, predicate: t1.v2 = t3.v1 AND (t3.v1 > 1:Int32), output: all, lookup table: t3 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchFilter { predicate: (t1.v2 > 1:Int32) }
        └─BatchScan { table: t1, columns: [t1.v1, t1.v2], distribution: SomeShard }
  with_config_map:
    QUERY_MODE: local
    RW_BATCH_ENABLE_LOOKUP_JOIN: 'true'
- name: Use project to do the calculation
  sql: |
    create table t1(x int, y int);
    create table t2(x int, y int);
    select * from t1, t2 where t1.x + t1.y = t2.x + t2.y;
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: Inner, on: ($expr1 = $expr2), output: [t1.x, t1.y, t2.x, t2.y] }
    ├─LogicalProject { exprs: [t1.x, t1.y, (t1.x + t1.y) as $expr1] }
    │ └─LogicalScan { table: t1, columns: [t1.x, t1.y] }
    └─LogicalProject { exprs: [t2.x, t2.y, (t2.x + t2.y) as $expr2] }
      └─LogicalScan { table: t2, columns: [t2.x, t2.y] }
- name: Use project to align return types
  sql: |
    create table t1(x int, y int);
    create table t2(x int, y decimal);
    select * from t1, t2 where t1.x = t2.y;
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: Inner, on: ($expr1 = t2.y), output: [t1.x, t1.y, t2.x, t2.y] }
    ├─LogicalProject { exprs: [t1.x, t1.y, t1.x::Decimal as $expr1] }
    │ └─LogicalScan { table: t1, columns: [t1.x, t1.y] }
    └─LogicalScan { table: t2, columns: [t2.x, t2.y] }
- name: Lookup join with no eq keys after pulling up predicate will revert to hash join
  sql: |
    create table t1 (v1 int, v2 int);
    create table t2 (v1 int, v2 int);
    create materialized view t3 as select v1, count(v2) as v2 from t2 group by v1;
    select * from (select * from t1 where false) as t1_s join (select * from t3 where false) as t3_s on t1_s.v2 = t3_s.v1;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t1.v2 = t3.v1, output: all }
      ├─BatchExchange { order: [], dist: HashShard(t1.v2) }
      │ └─BatchValues { rows: [] }
      └─BatchExchange { order: [], dist: HashShard(t3.v1) }
        └─BatchValues { rows: [] }
- name: Able to join on `IS NOT DISTINCT FROM` on unequal but implicitly castable types
  sql: |
    create table t1 (v1 int);
    create table t2 (v2 bigint);
    select * from t1 join t2 on v1 IS NOT DISTINCT FROM v2;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: $expr1 IS NOT DISTINCT FROM t2.v2, output: [t1.v1, t2.v2] }
      ├─BatchExchange { order: [], dist: HashShard($expr1) }
      │ └─BatchProject { exprs: [t1.v1, t1.v1::Int64 as $expr1] }
      │   └─BatchScan { table: t1, columns: [t1.v1], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t2.v2) }
        └─BatchScan { table: t2, columns: [t2.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, t1._row_id(hidden), $expr1(hidden), t2._row_id(hidden)], stream_key: [t1._row_id, t2._row_id, $expr1], pk_columns: [t1._row_id, t2._row_id, $expr1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t1._row_id, $expr1, t2._row_id) }
      └─StreamHashJoin { type: Inner, predicate: $expr1 IS NOT DISTINCT FROM t2.v2, output: [t1.v1, t2.v2, t1._row_id, $expr1, t2._row_id] }
        ├─StreamExchange { dist: HashShard($expr1) }
        │ └─StreamProject { exprs: [t1.v1, t1.v1::Int64 as $expr1, t1._row_id] }
        │   └─StreamTableScan { table: t1, columns: [t1.v1, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        └─StreamExchange { dist: HashShard(t2.v2) }
          └─StreamTableScan { table: t2, columns: [t2.v2, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
- name: Repeated columns in project should not interfere with join result (https://github.com/risingwavelabs/risingwave/issues/8216)
  sql: |
    create table t(x int);
    SELECT t.x x1, t.x x2 FROM t join t tt ON t.x=tt.x;
  stream_plan: |-
    StreamMaterialize { columns: [x1, x2, t._row_id(hidden), t._row_id#1(hidden)], stream_key: [t._row_id, t._row_id#1, x2], pk_columns: [t._row_id, t._row_id#1, x2], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t.x, t.x, t._row_id, t._row_id] }
      └─StreamHashJoin { type: Inner, predicate: t.x = t.x, output: [t.x, t._row_id, t._row_id] }
        ├─StreamExchange { dist: HashShard(t.x) }
        │ └─StreamTableScan { table: t, columns: [t.x, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamExchange { dist: HashShard(t.x) }
          └─StreamTableScan { table: t, columns: [t.x, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: Choose correct distribution key in pk (https://github.com/risingwavelabs/risingwave/issues/7698)
  sql: |
    create table t (src int, dst int);
    select t1.src p1, t1.dst p2, t2.dst p3 from t t1, t t2, t t3 where t1.dst = t2.src and t2.src = t3.dst and t3.dst = t1.src;
  stream_plan: |-
    StreamMaterialize { columns: [p1, p2, p3, t._row_id(hidden), t._row_id#1(hidden), t.src(hidden), t._row_id#2(hidden)], stream_key: [t._row_id, t._row_id#1, p2, t._row_id#2, t.src, p1], pk_columns: [t._row_id, t._row_id#1, p2, t._row_id#2, t.src, p1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.src, t.dst, t._row_id, t._row_id, t.src, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.src = t.dst AND t.src = t.dst, output: [t.src, t.dst, t.dst, t._row_id, t._row_id, t.src, t._row_id] }
        ├─StreamExchange { dist: HashShard(t.src) }
        │ └─StreamHashJoin { type: Inner, predicate: t.dst = t.src, output: [t.src, t.dst, t.src, t.dst, t._row_id, t._row_id] }
        │   ├─StreamExchange { dist: HashShard(t.dst) }
        │   │ └─StreamTableScan { table: t, columns: [t.src, t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        │   └─StreamExchange { dist: HashShard(t.src) }
        │     └─StreamTableScan { table: t, columns: [t.src, t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamExchange { dist: HashShard(t.dst) }
          └─StreamTableScan { table: t, columns: [t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [p1, p2, p3, t._row_id(hidden), t._row_id#1(hidden), t.src(hidden), t._row_id#2(hidden)], stream_key: [t._row_id, t._row_id#1, p2, t._row_id#2, t.src, p1], pk_columns: [t._row_id, t._row_id#1, p2, t._row_id#2, t.src, p1], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0, 1, 3, 4, 5, 6]) from 1

    Fragment 1
    StreamHashJoin { type: Inner, predicate: t.src = t.dst AND t.src = t.dst, output: [t.src, t.dst, t.dst, t._row_id, t._row_id, t.src, t._row_id] } { tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ] }
    ├── StreamExchange Hash([0]) from 2
    └── StreamExchange Hash([0]) from 5

    Fragment 2
    StreamHashJoin { type: Inner, predicate: t.dst = t.src, output: [t.src, t.dst, t.src, t.dst, t._row_id, t._row_id] } { tables: [ HashJoinLeft: 4, HashJoinDegreeLeft: 5, HashJoinRight: 6, HashJoinDegreeRight: 7 ] }
    ├── StreamExchange Hash([1]) from 3
    └── StreamExchange Hash([0]) from 4

    Fragment 3
    StreamTableScan { table: t, columns: [t.src, t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) } { tables: [ StreamScan: 8 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 4
    StreamTableScan { table: t, columns: [t.src, t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) } { tables: [ StreamScan: 9 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 5
    StreamTableScan { table: t, columns: [t.dst, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) } { tables: [ StreamScan: 10 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ t_src, t_dst, t_src_0, t_dst_0, t__row_id, t__row_id_0, _rw_timestamp ], primary key: [ $2 ASC, $0 ASC, $4 ASC, $5 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 1 { columns: [ t_src, t_src_0, t__row_id, t__row_id_0, t_dst, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC, $4 ASC ], value indices: [ 5 ], distribution key: [ 1 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ t_dst, t__row_id, _rw_timestamp ], primary key: [ $0 ASC, $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 3 { columns: [ t_dst, t_dst_0, t__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 1 ], read pk prefix len hint: 2 }

    Table 4 { columns: [ t_src, t_dst, t__row_id, _rw_timestamp ], primary key: [ $1 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ t_dst, t__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ t_src, t_dst, t__row_id, _rw_timestamp ], primary key: [ $0 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ t_src, t__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 8 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 9 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 10 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ p1, p2, p3, t._row_id, t._row_id#1, t.src, t._row_id#2, _rw_timestamp ]
    ├── primary key: [ $3 ASC, $4 ASC, $1 ASC, $6 ASC, $5 ASC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6 ]
    ├── distribution key: [ 0, 1, 3, 4, 5, 6 ]
    └── read pk prefix len hint: 6

