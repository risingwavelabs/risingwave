# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- name: changlog mv
  sql: |
    create table t1 (v1 int);
    with p as changelog from t1 select _changelog_row_id::bigint as changelog_row_id, * from p
  stream_plan: |-
    StreamMaterialize { columns: [changelog_row_id, v1, changelog_op, _changelog_row_id(hidden)], stream_key: [_changelog_row_id], pk_columns: [_changelog_row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [_changelog_row_id::Int64 as $expr1, t1.v1, changelog_op, _changelog_row_id] }
      └─StreamChangeLog
        └─StreamTableScan { table: t1, columns: [t1.v1, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [changelog_row_id, v1, changelog_op, _changelog_row_id(hidden)], stream_key: [_changelog_row_id], pk_columns: [_changelog_row_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [_changelog_row_id::Int64 as $expr1, t1.v1, changelog_op, _changelog_row_id] }
        └── StreamChangeLog
            └── StreamTableScan { table: t1, columns: [t1.v1, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
                ├── tables: [ StreamScan: 0 ]
                ├── Upstream
                └── BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ changelog_row_id, v1, changelog_op, _changelog_row_id, _rw_timestamp ]
    ├── primary key: [ $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 3 ]
    └── read pk prefix len hint: 1

