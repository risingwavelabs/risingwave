# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, c bigint);
    select * from t1 union all select * from t2;
  batch_plan: |-
    BatchUnion { all: true }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c, t1._row_id(hidden), $src(hidden)], stream_key: [t1._row_id, $src], pk_columns: [t1._row_id, $src], pk_conflict: NoCheck }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(t1._row_id, 0:Int32) }
      │ └─StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
      │   └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
      └─StreamExchange { dist: HashShard(t2._row_id, 1:Int32) }
        └─StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
          └─StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c, t1._row_id(hidden), $src(hidden)], stream_key: [t1._row_id, $src], pk_columns: [t1._row_id, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([3, 4]) from 1
        └── StreamExchange Hash([3, 4]) from 2

    Fragment 1
    StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        ├── tables: [ StreamScan: 0 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 1
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ a, b, c, t1._row_id, $src, _rw_timestamp ]
    ├── primary key: [ $3 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 3, 4 ]
    └── read pk prefix len hint: 2

- sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, c bigint);
    select * from t1 union select * from t2;
  optimized_logical_plan_for_batch: |-
    LogicalAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
    └─LogicalUnion { all: true }
      ├─LogicalScan { table: t1, columns: [t1.a, t1.b, t1.c] }
      └─LogicalScan { table: t2, columns: [t2.a, t2.b, t2.c] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
      └─BatchExchange { order: [], dist: HashShard(t1.a, t1.b, t1.c) }
        └─BatchUnion { all: true }
          ├─BatchExchange { order: [], dist: Single }
          │ └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], distribution: SomeShard }
          └─BatchExchange { order: [], dist: Single }
            └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c], stream_key: [a, b, c], pk_columns: [a, b, c], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t1.a, t1.b, t1.c], noop_update_hint: true }
      └─StreamHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [count] }
        └─StreamExchange { dist: HashShard(t1.a, t1.b, t1.c) }
          └─StreamUnion { all: true }
            ├─StreamExchange { dist: HashShard(t1._row_id, 0:Int32) }
            │ └─StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
            │   └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
            └─StreamExchange { dist: HashShard(t2._row_id, 1:Int32) }
              └─StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
                └─StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c], stream_key: [a, b, c], pk_columns: [a, b, c], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [t1.a, t1.b, t1.c], noop_update_hint: true }
        └── StreamHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [count] } { tables: [ HashAggState: 0 ] }
            └── StreamExchange Hash([0, 1, 2]) from 1

    Fragment 1
    StreamUnion { all: true }
    ├── StreamExchange Hash([3, 4]) from 2
    └── StreamExchange Hash([3, 4]) from 3

    Fragment 2
    StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        ├── tables: [ StreamScan: 2 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ t1_a, t1_b, t1_c, count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 1
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 2
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ a, b, c, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

- sql: |
    create table t1 (a int, b numeric, c bigint, primary key(a));
    create table t2 (a int, b numeric, c bigint, primary key(a));
    select * from t1 union select * from t2;
  optimized_logical_plan_for_batch: |-
    LogicalAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
    └─LogicalUnion { all: true }
      ├─LogicalScan { table: t1, columns: [t1.a, t1.b, t1.c] }
      └─LogicalScan { table: t2, columns: [t2.a, t2.b, t2.c] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
      └─BatchExchange { order: [], dist: HashShard(t1.a, t1.b, t1.c) }
        └─BatchUnion { all: true }
          ├─BatchExchange { order: [], dist: Single }
          │ └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], distribution: UpstreamHashShard(t1.a) }
          └─BatchExchange { order: [], dist: Single }
            └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], distribution: UpstreamHashShard(t2.a) }
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c], stream_key: [a, b, c], pk_columns: [a, b, c], pk_conflict: NoCheck }
    └─StreamProject { exprs: [t1.a, t1.b, t1.c], noop_update_hint: true }
      └─StreamHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [count] }
        └─StreamExchange { dist: HashShard(t1.a, t1.b, t1.c) }
          └─StreamUnion { all: true }
            ├─StreamExchange { dist: HashShard(t1.a, 0:Int32) }
            │ └─StreamProject { exprs: [t1.a, t1.b, t1.c, 0:Int32] }
            │   └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1.a], pk: [a], dist: UpstreamHashShard(t1.a) }
            └─StreamExchange { dist: HashShard(t2.a, 1:Int32) }
              └─StreamProject { exprs: [t2.a, t2.b, t2.c, 1:Int32] }
                └─StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2.a], pk: [a], dist: UpstreamHashShard(t2.a) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c], stream_key: [a, b, c], pk_columns: [a, b, c], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [t1.a, t1.b, t1.c], noop_update_hint: true }
        └── StreamHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [count] } { tables: [ HashAggState: 0 ] }
            └── StreamExchange Hash([0, 1, 2]) from 1

    Fragment 1
    StreamUnion { all: true }
    ├── StreamExchange Hash([0, 3]) from 2
    └── StreamExchange Hash([0, 3]) from 3

    Fragment 2
    StreamProject { exprs: [t1.a, t1.b, t1.c, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1.a], pk: [a], dist: UpstreamHashShard(t1.a) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t2.a, t2.b, t2.c, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2.a], pk: [a], dist: UpstreamHashShard(t2.a) }
        ├── tables: [ StreamScan: 2 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ t1_a, t1_b, t1_c, count, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 3 ]
    ├── distribution key: [ 0, 1, 2 ]
    └── read pk prefix len hint: 3

    Table 1
    ├── columns: [ vnode, a, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 2
    ├── columns: [ vnode, a, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ a, b, c, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0, 1, 2 ]
    └── read pk prefix len hint: 3

- sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, c bigint);
    (select * from t1 limit 1) union (select * from t2 limit 1);
  optimized_logical_plan_for_batch: |-
    LogicalAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
    └─LogicalUnion { all: true }
      ├─LogicalLimit { limit: 1, offset: 0 }
      │ └─LogicalScan { table: t1, columns: [t1.a, t1.b, t1.c] }
      └─LogicalLimit { limit: 1, offset: 0 }
        └─LogicalScan { table: t2, columns: [t2.a, t2.b, t2.c] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
      └─BatchExchange { order: [], dist: HashShard(t1.a, t1.b, t1.c) }
        └─BatchUnion { all: true }
          ├─BatchLimit { limit: 1, offset: 0 }
          │ └─BatchExchange { order: [], dist: Single, sequential: true }
          │   └─BatchLimit { limit: 1, offset: 0 }
          │     └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], limit: 1, distribution: SomeShard }
          └─BatchLimit { limit: 1, offset: 0 }
            └─BatchExchange { order: [], dist: Single, sequential: true }
              └─BatchLimit { limit: 1, offset: 0 }
                └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], limit: 1, distribution: SomeShard }
- sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, c bigint);
    select a from ((select * from t1 limit 1) union (select * from t2 limit 1)) T;
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t1.a] }
    └─LogicalAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
      └─LogicalUnion { all: true }
        ├─LogicalLimit { limit: 1, offset: 0 }
        │ └─LogicalScan { table: t1, columns: [t1.a, t1.b, t1.c] }
        └─LogicalLimit { limit: 1, offset: 0 }
          └─LogicalScan { table: t2, columns: [t2.a, t2.b, t2.c] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [t1.a] }
      └─BatchHashAgg { group_key: [t1.a, t1.b, t1.c], aggs: [] }
        └─BatchExchange { order: [], dist: HashShard(t1.a, t1.b, t1.c) }
          └─BatchUnion { all: true }
            ├─BatchLimit { limit: 1, offset: 0 }
            │ └─BatchExchange { order: [], dist: Single, sequential: true }
            │   └─BatchLimit { limit: 1, offset: 0 }
            │     └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], limit: 1, distribution: SomeShard }
            └─BatchLimit { limit: 1, offset: 0 }
              └─BatchExchange { order: [], dist: Single, sequential: true }
                └─BatchLimit { limit: 1, offset: 0 }
                  └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], limit: 1, distribution: SomeShard }
- sql: |
    select 1 union all select 1
  optimized_logical_plan_for_batch: 'LogicalValues { rows: [[1:Int32], [1:Int32]], schema: Schema { fields: [1:Int32:Int32] } }'
  batch_plan: 'BatchValues { rows: [[1:Int32], [1:Int32]] }'
- sql: |
    select 1 union all select 2 union all select 3 union all select 4 union all select 5
  optimized_logical_plan_for_batch: 'LogicalValues { rows: [[1:Int32], [2:Int32], [3:Int32], [4:Int32], [5:Int32]], schema: Schema { fields: [1:Int32:Int32] } }'
  batch_plan: 'BatchValues { rows: [[1:Int32], [2:Int32], [3:Int32], [4:Int32], [5:Int32]] }'
- sql: |
    select 1 union select 2 union select 3 union select 4 union select 5 union select 5
  optimized_logical_plan_for_batch: |-
    LogicalAgg { group_key: [1:Int32], aggs: [] }
    └─LogicalValues { rows: [[1:Int32], [2:Int32], [3:Int32], [4:Int32], [5:Int32], [5:Int32]], schema: Schema { fields: [1:Int32:Int32] } }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [1:Int32], aggs: [] }
      └─BatchExchange { order: [], dist: HashShard(1:Int32) }
        └─BatchValues { rows: [[1:Int32], [2:Int32], [3:Int32], [4:Int32], [5:Int32], [5:Int32]] }
- name: test merged union stream key (2 columns, row_id + src_col)
  sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, c bigint);
    create table t3 (a int, b numeric, c bigint);
    create table t4 (a int, b numeric, c bigint);
    create table t5 (a int, b numeric, c bigint);
    select * from t1 union all select * from t2 union all select * from t3 union all select * from t4 union all select * from t5;
  batch_plan: |-
    BatchUnion { all: true }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t1, columns: [t1.a, t1.b, t1.c], distribution: SomeShard }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t2, columns: [t2.a, t2.b, t2.c], distribution: SomeShard }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t3, columns: [t3.a, t3.b, t3.c], distribution: SomeShard }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchScan { table: t4, columns: [t4.a, t4.b, t4.c], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t5, columns: [t5.a, t5.b, t5.c], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [a, b, c, t1._row_id(hidden), $src(hidden)], stream_key: [t1._row_id, $src], pk_columns: [t1._row_id, $src], pk_conflict: NoCheck }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(t1._row_id, 0:Int32) }
      │ └─StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
      │   └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
      ├─StreamExchange { dist: HashShard(t2._row_id, 1:Int32) }
      │ └─StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
      │   └─StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
      ├─StreamExchange { dist: HashShard(t3._row_id, 2:Int32) }
      │ └─StreamProject { exprs: [t3.a, t3.b, t3.c, t3._row_id, 2:Int32] }
      │   └─StreamTableScan { table: t3, columns: [t3.a, t3.b, t3.c, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
      ├─StreamExchange { dist: HashShard(t4._row_id, 3:Int32) }
      │ └─StreamProject { exprs: [t4.a, t4.b, t4.c, t4._row_id, 3:Int32] }
      │   └─StreamTableScan { table: t4, columns: [t4.a, t4.b, t4.c, t4._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t4._row_id], pk: [_row_id], dist: UpstreamHashShard(t4._row_id) }
      └─StreamExchange { dist: HashShard(t5._row_id, 4:Int32) }
        └─StreamProject { exprs: [t5.a, t5.b, t5.c, t5._row_id, 4:Int32] }
          └─StreamTableScan { table: t5, columns: [t5.a, t5.b, t5.c, t5._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t5._row_id], pk: [_row_id], dist: UpstreamHashShard(t5._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c, t1._row_id(hidden), $src(hidden)], stream_key: [t1._row_id, $src], pk_columns: [t1._row_id, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([3, 4]) from 1
        ├── StreamExchange Hash([3, 4]) from 2
        ├── StreamExchange Hash([3, 4]) from 3
        ├── StreamExchange Hash([3, 4]) from 4
        └── StreamExchange Hash([3, 4]) from 5

    Fragment 1
    StreamProject { exprs: [t1.a, t1.b, t1.c, t1._row_id, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        ├── tables: [ StreamScan: 0 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [t2.a, t2.b, t2.c, t2._row_id, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t3.a, t3.b, t3.c, t3._row_id, 2:Int32] }
    └── StreamTableScan { table: t3, columns: [t3.a, t3.b, t3.c, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
        ├── tables: [ StreamScan: 2 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 4
    StreamProject { exprs: [t4.a, t4.b, t4.c, t4._row_id, 3:Int32] }
    └── StreamTableScan { table: t4, columns: [t4.a, t4.b, t4.c, t4._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t4._row_id], pk: [_row_id], dist: UpstreamHashShard(t4._row_id) }
        ├── tables: [ StreamScan: 3 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 5
    StreamProject { exprs: [t5.a, t5.b, t5.c, t5._row_id, 4:Int32] }
    └── StreamTableScan { table: t5, columns: [t5.a, t5.b, t5.c, t5._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t5._row_id], pk: [_row_id], dist: UpstreamHashShard(t5._row_id) }
        ├── tables: [ StreamScan: 4 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 1
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 2
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 3
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ a, b, c, t1._row_id, $src, _rw_timestamp ]
    ├── primary key: [ $3 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 3, 4 ]
    └── read pk prefix len hint: 2

- name: test merged union stream key (5 columns, row_id + src_col + a + b + c)
  sql: |
    create table t1 (a int, b numeric, c bigint, primary key (a));
    create table t2 (a int, b numeric, c bigint, primary key (b));
    create table t3 (a int, b numeric, c bigint, primary key (c));
    create table t4 (a int, b numeric, c bigint);
    create table t5 (a int, b numeric, c bigint, primary key (a, b));
    select * from t1 union all select * from t2 union all select * from t3 union all select * from t4 union all select * from t5;
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c, null:Decimal(hidden), null:Int64(hidden), t1.a(hidden), null:Serial(hidden), $src(hidden)], stream_key: [t1.a, null:Decimal, null:Int64, null:Serial, $src], pk_columns: [t1.a, null:Decimal, null:Int64, null:Serial, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([5, 3, 4, 6, 7]) from 1
        ├── StreamExchange Hash([5, 3, 4, 6, 7]) from 2
        ├── StreamExchange Hash([5, 3, 4, 6, 7]) from 3
        ├── StreamExchange Hash([5, 3, 4, 6, 7]) from 4
        └── StreamExchange Hash([5, 3, 4, 6, 7]) from 5

    Fragment 1
    StreamProject { exprs: [t1.a, t1.b, t1.c, null:Decimal, null:Int64, t1.a, null:Serial, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1.a], pk: [a], dist: UpstreamHashShard(t1.a) } { tables: [ StreamScan: 0 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [t2.a, t2.b, t2.c, t2.b, null:Int64, null:Int32, null:Serial, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2.b], pk: [b], dist: UpstreamHashShard(t2.b) } { tables: [ StreamScan: 1 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t3.a, t3.b, t3.c, null:Decimal, t3.c, null:Int32, null:Serial, 2:Int32] }
    └── StreamTableScan { table: t3, columns: [t3.a, t3.b, t3.c], stream_scan_type: ArrangementBackfill, stream_key: [t3.c], pk: [c], dist: UpstreamHashShard(t3.c) } { tables: [ StreamScan: 2 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 4
    StreamProject { exprs: [t4.a, t4.b, t4.c, null:Decimal, null:Int64, null:Int32, t4._row_id, 3:Int32] }
    └── StreamTableScan { table: t4, columns: [t4.a, t4.b, t4.c, t4._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t4._row_id], pk: [_row_id], dist: UpstreamHashShard(t4._row_id) } { tables: [ StreamScan: 3 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 5
    StreamProject { exprs: [t5.a, t5.b, t5.c, t5.b, null:Int64, t5.a, null:Serial, 4:Int32] }
    └── StreamTableScan { table: t5, columns: [t5.a, t5.b, t5.c], stream_scan_type: ArrangementBackfill, stream_key: [t5.a, t5.b], pk: [a, b], dist: UpstreamHashShard(t5.a, t5.b) } { tables: [ StreamScan: 4 ] }
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ vnode, a, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 1 { columns: [ vnode, b, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 2 { columns: [ vnode, c, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 3 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4 { columns: [ vnode, a, b, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3, 4 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ a, b, c, null:Decimal, null:Int64, t1.a, null:Serial, $src, _rw_timestamp ], primary key: [ $5 ASC, $3 ASC, $4 ASC, $6 ASC, $7 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ], distribution key: [ 5, 3, 4, 6, 7 ], read pk prefix len hint: 5 }

- name: test merged union stream key (4 columns, row_id + src_col + a + b)
  sql: |
    create table t1 (a int, b numeric, c bigint, primary key (a));
    create table t2 (a int, b numeric, c bigint, primary key (b));
    create table t3 (a int, b numeric, c bigint);
    create table t4 (a int, b numeric, c bigint);
    create table t5 (a int, b numeric, c bigint, primary key (a, b));
    select * from t1 union all select * from t2 union all select * from t3 union all select * from t4 union all select * from t5;
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c, null:Decimal(hidden), t1.a(hidden), null:Serial(hidden), $src(hidden)], stream_key: [t1.a, null:Decimal, null:Serial, $src], pk_columns: [t1.a, null:Decimal, null:Serial, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([4, 3, 5, 6]) from 1
        ├── StreamExchange Hash([4, 3, 5, 6]) from 2
        ├── StreamExchange Hash([4, 3, 5, 6]) from 3
        ├── StreamExchange Hash([4, 3, 5, 6]) from 4
        └── StreamExchange Hash([4, 3, 5, 6]) from 5

    Fragment 1
    StreamProject { exprs: [t1.a, t1.b, t1.c, null:Decimal, t1.a, null:Serial, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1.a], pk: [a], dist: UpstreamHashShard(t1.a) } { tables: [ StreamScan: 0 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [t2.a, t2.b, t2.c, t2.b, null:Int32, null:Serial, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2.b], pk: [b], dist: UpstreamHashShard(t2.b) } { tables: [ StreamScan: 1 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t3.a, t3.b, t3.c, null:Decimal, null:Int32, t3._row_id, 2:Int32] }
    └── StreamTableScan { table: t3, columns: [t3.a, t3.b, t3.c, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) } { tables: [ StreamScan: 2 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 4
    StreamProject { exprs: [t4.a, t4.b, t4.c, null:Decimal, null:Int32, t4._row_id, 3:Int32] }
    └── StreamTableScan { table: t4, columns: [t4.a, t4.b, t4.c, t4._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t4._row_id], pk: [_row_id], dist: UpstreamHashShard(t4._row_id) } { tables: [ StreamScan: 3 ] }
        ├── Upstream
        └── BatchPlanNode

    Fragment 5
    StreamProject { exprs: [t5.a, t5.b, t5.c, t5.b, t5.a, null:Serial, 4:Int32] }
    └── StreamTableScan { table: t5, columns: [t5.a, t5.b, t5.c], stream_scan_type: ArrangementBackfill, stream_key: [t5.a, t5.b], pk: [a, b], dist: UpstreamHashShard(t5.a, t5.b) } { tables: [ StreamScan: 4 ] }
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ vnode, a, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 1 { columns: [ vnode, b, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 2 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 3 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4 { columns: [ vnode, a, b, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3, 4 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ a, b, c, null:Decimal, t1.a, null:Serial, $src, _rw_timestamp ]
    ├── primary key: [ $4 ASC, $3 ASC, $5 ASC, $6 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6 ]
    ├── distribution key: [ 4, 3, 5, 6 ]
    └── read pk prefix len hint: 4

- name: test merged union stream key (3 columns, src_col + a + b)
  sql: |
    create table t1 (a int, b numeric, c bigint, primary key (a));
    create table t2 (a int, b numeric, c bigint, primary key (b));
    create table t3 (a int, b numeric, c bigint, primary key (b));
    create table t4 (a int, b numeric, c bigint, primary key (b, a));
    create table t5 (a int, b numeric, c bigint, primary key (a, b));
    select * from t1 union all select * from t2 union all select * from t3 union all select * from t4 union all select * from t5;
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [a, b, c, $src(hidden)], stream_key: [a, b, $src], pk_columns: [a, b, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([0, 1, 3]) from 1
        ├── StreamExchange Hash([0, 1, 3]) from 2
        ├── StreamExchange Hash([0, 1, 3]) from 3
        ├── StreamExchange Hash([0, 1, 3]) from 4
        └── StreamExchange Hash([0, 1, 3]) from 5

    Fragment 1
    StreamProject { exprs: [t1.a, t1.b, t1.c, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1.c], stream_scan_type: ArrangementBackfill, stream_key: [t1.a], pk: [a], dist: UpstreamHashShard(t1.a) }
        ├── tables: [ StreamScan: 0 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [t2.a, t2.b, t2.c, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2.c], stream_scan_type: ArrangementBackfill, stream_key: [t2.b], pk: [b], dist: UpstreamHashShard(t2.b) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [t3.a, t3.b, t3.c, 2:Int32] }
    └── StreamTableScan { table: t3, columns: [t3.a, t3.b, t3.c], stream_scan_type: ArrangementBackfill, stream_key: [t3.b], pk: [b], dist: UpstreamHashShard(t3.b) }
        ├── tables: [ StreamScan: 2 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 4
    StreamProject { exprs: [t4.a, t4.b, t4.c, 3:Int32] }
    └── StreamTableScan { table: t4, columns: [t4.a, t4.b, t4.c], stream_scan_type: ArrangementBackfill, stream_key: [t4.b, t4.a], pk: [b, a], dist: UpstreamHashShard(t4.b, t4.a) }
        ├── tables: [ StreamScan: 3 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 5
    StreamProject { exprs: [t5.a, t5.b, t5.c, 4:Int32] }
    └── StreamTableScan { table: t5, columns: [t5.a, t5.b, t5.c], stream_scan_type: ArrangementBackfill, stream_key: [t5.a, t5.b], pk: [a, b], dist: UpstreamHashShard(t5.a, t5.b) }
        ├── tables: [ StreamScan: 4 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ vnode, a, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 1
    ├── columns: [ vnode, b, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 2
    ├── columns: [ vnode, b, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 3
    ├── columns: [ vnode, b, a, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3, 4 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4
    ├── columns: [ vnode, a, b, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3, 4 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ a, b, c, $src, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0, 1, 3 ]
    └── read pk prefix len hint: 3

- name: test corresponding union
  sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, y bigint);
    create table t3 (x int, b numeric, c bigint);
    select * from t1 union corresponding select * from t2 union all corresponding by (b) select * from t3;
  batch_plan: |-
    BatchUnion { all: true }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchProject { exprs: [t1.b] }
    │   └─BatchHashAgg { group_key: [t1.a, t1.b], aggs: [] }
    │     └─BatchExchange { order: [], dist: HashShard(t1.a, t1.b) }
    │       └─BatchUnion { all: true }
    │         ├─BatchExchange { order: [], dist: Single }
    │         │ └─BatchScan { table: t1, columns: [t1.a, t1.b], distribution: SomeShard }
    │         └─BatchExchange { order: [], dist: Single }
    │           └─BatchScan { table: t2, columns: [t2.a, t2.b], distribution: SomeShard }
    └─BatchExchange { order: [], dist: Single }
      └─BatchScan { table: t3, columns: [t3.b], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [b, t1.b(hidden), t1.a(hidden), null:Serial(hidden), $src(hidden)], stream_key: [t1.a, t1.b, null:Serial, $src], pk_columns: [t1.a, t1.b, null:Serial, $src], pk_conflict: NoCheck }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(t1.a, t1.b, null:Serial, 0:Int32) }
      │ └─StreamProject { exprs: [t1.b, t1.b, t1.a, null:Serial, 0:Int32], noop_update_hint: true }
      │   └─StreamHashAgg { group_key: [t1.a, t1.b], aggs: [count] }
      │     └─StreamExchange { dist: HashShard(t1.a, t1.b) }
      │       └─StreamUnion { all: true }
      │         ├─StreamExchange { dist: HashShard(t1._row_id, 0:Int32) }
      │         │ └─StreamProject { exprs: [t1.a, t1.b, t1._row_id, 0:Int32] }
      │         │   └─StreamTableScan { table: t1, columns: [t1.a, t1.b, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
      │         └─StreamExchange { dist: HashShard(t2._row_id, 1:Int32) }
      │           └─StreamProject { exprs: [t2.a, t2.b, t2._row_id, 1:Int32] }
      │             └─StreamTableScan { table: t2, columns: [t2.a, t2.b, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
      └─StreamExchange { dist: HashShard(null:Int32, null:Decimal, t3._row_id, 1:Int32) }
        └─StreamProject { exprs: [t3.b, null:Decimal, null:Int32, t3._row_id, 1:Int32] }
          └─StreamTableScan { table: t3, columns: [t3.b, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [b, t1.b(hidden), t1.a(hidden), null:Serial(hidden), $src(hidden)], stream_key: [t1.a, t1.b, null:Serial, $src], pk_columns: [t1.a, t1.b, null:Serial, $src], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamUnion { all: true }
        ├── StreamExchange Hash([2, 1, 3, 4]) from 1
        └── StreamExchange Hash([2, 1, 3, 4]) from 5

    Fragment 1
    StreamProject { exprs: [t1.b, t1.b, t1.a, null:Serial, 0:Int32], noop_update_hint: true }
    └── StreamHashAgg { group_key: [t1.a, t1.b], aggs: [count] } { tables: [ HashAggState: 0 ] }
        └── StreamExchange Hash([0, 1]) from 2

    Fragment 2
    StreamUnion { all: true }
    ├── StreamExchange Hash([2, 3]) from 3
    └── StreamExchange Hash([2, 3]) from 4

    Fragment 3
    StreamProject { exprs: [t1.a, t1.b, t1._row_id, 0:Int32] }
    └── StreamTableScan { table: t1, columns: [t1.a, t1.b, t1._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t1._row_id], pk: [_row_id], dist: UpstreamHashShard(t1._row_id) }
        ├── tables: [ StreamScan: 1 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 4
    StreamProject { exprs: [t2.a, t2.b, t2._row_id, 1:Int32] }
    └── StreamTableScan { table: t2, columns: [t2.a, t2.b, t2._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t2._row_id], pk: [_row_id], dist: UpstreamHashShard(t2._row_id) }
        ├── tables: [ StreamScan: 2 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 5
    StreamProject { exprs: [t3.b, null:Decimal, null:Int32, t3._row_id, 1:Int32] }
    └── StreamTableScan { table: t3, columns: [t3.b, t3._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t3._row_id], pk: [_row_id], dist: UpstreamHashShard(t3._row_id) }
        ├── tables: [ StreamScan: 3 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ t1_a, t1_b, count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 1
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 2
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 3
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ b, t1.b, t1.a, null:Serial, $src, _rw_timestamp ]
    ├── primary key: [ $2 ASC, $1 ASC, $3 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 2, 1, 3, 4 ]
    └── read pk prefix len hint: 4

- name: test corresponding union error - corresponding list
  sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, y bigint);
    create table t3 (x int, b numeric, c bigint);
    select * from t1 union corresponding select * from t2 union all corresponding by (c) select * from t3;
  binder_error: 'Invalid input syntax: Column name `c` in CORRESPONDING BY is not found in a side of the UNION operation. It shall be included in both sides.'
- name: test corresponding union error - duplicate names
  sql: |
    create table t1 (a int, b numeric, c bigint);
    create table t2 (a int, b numeric, y bigint);
    select a, b as a from t1 union corresponding select * from t2;
  binder_error: 'Invalid input syntax: Duplicated column name `a` in a column list of the query in a UNION operation. Column list of the query: ("a", "a").'
