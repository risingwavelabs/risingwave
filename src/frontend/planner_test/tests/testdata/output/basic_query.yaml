# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: values (11, 22), (33+(1+2), 44);
  batch_plan: 'BatchValues { rows: [[11:Int32, 22:Int32], [36:Int32, 44:Int32]] }'
  stream_plan: |-
    StreamMaterialize { columns: [*VALUES*_0.column_0, *VALUES*_0.column_1, _row_id(hidden)], stream_key: [_row_id], pk_columns: [_row_id], pk_conflict: NoCheck }
    └─StreamValues { rows: [[11:Int32, 22:Int32, 0:Int64], [36:Int32, 44:Int32, 1:Int64]] }
- sql: select * from t
  binder_error: |
    Catalog error

    Caused by:
      table or source not found: t
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, v2, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: t, columns: [t.v1, t.v2, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select t2.* from t;
  binder_error: 'Item not found: relation "t2"'
- sql: |
    create table t ();
    select * from t where 1>2 and 1=1 and 3<1 and 4<>1 or 1=1 and 2>=1 and 1<=2;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamFilter { predicate: true }
      └─StreamTableScan { table: t, columns: [t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 int);
    select * from t where v1<1;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: (t.v1 < 1:Int32) }
      └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamFilter { predicate: (t.v1 < 1:Int32) }
      └─StreamTableScan { table: t, columns: [t.v1, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- name: test boolean expression common factor extraction
  sql: |
    create table t (v1 Boolean, v2 Boolean, v3 Boolean);
    select * from t where v1 AND v2 AND ((v1 AND v2) OR (v2 AND v3));
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: t.v1 AND t.v2 AND (t.v1 OR t.v3) }
      └─BatchScan { table: t, columns: [t.v1, t.v2, t.v3], distribution: SomeShard }
- name: test boolean expression simplification
  sql: |
    create table t (v1 Boolean, v2 Boolean, v3 Boolean);
    select * from t where v1 AND NOT(v1 OR v2 Or NOT(v1 AND v2 AND true));
  batch_plan: 'BatchValues { rows: [] }'
- name: test boolean expression simplification
  sql: |
    create table t (v1 Boolean, v2 Boolean);
    select * from t where (v1 AND v2) OR (v1 AND v2);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: t.v1 AND t.v2 }
      └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- name: constant folding for IS TRUE, IS FALSE, IS NULL
  sql: |
    create table t(a Boolean);
    select * from t where (NULL IS NULL) IS TRUE AND FALSE IS FALSE AND a;
  logical_plan: |-
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: t.a }
      └─LogicalScan { table: t, columns: [t.a, t._row_id, t._rw_timestamp] }
- name: constant folding for IS NOT TRUE, IS NOT FALSE
  sql: |
    create table t(a Boolean);
    select * from t where (NULL IS NOT TRUE) IS NOT FALSE AND a IS NOT TRUE;
  logical_plan: |-
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: IsNotTrue(t.a) }
      └─LogicalScan { table: t, columns: [t.a, t._row_id, t._rw_timestamp] }
- name: constant folding IS NOT NULL
  sql: |
    create table t(a double precision);
    select * from t where (a IS NOT NULL AND 3.14 IS NOT NULL) OR (NULL IS NOT NULL);
  logical_plan: |-
    LogicalProject { exprs: [t.a] }
    └─LogicalFilter { predicate: IsNotNull(t.a) }
      └─LogicalScan { table: t, columns: [t.a, t._row_id, t._rw_timestamp] }
- sql: |
    create table t (v1 int, v2 int);
    select v1 from t;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [v1, t._row_id(hidden)], stream_key: [t._row_id], pk_columns: [t._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: t, columns: [t.v1, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: select 1
  batch_plan: 'BatchValues { rows: [[1:Int32]] }'
- sql: |
    create table t (v1 bigint, v2 double precision);
    select a from t as t2(a);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: t, columns: [t.v1], distribution: SomeShard }
- sql: |
    create table t (v1 int, v2 int);
    delete from t;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchDelete { table: t }
      └─BatchExchange { order: [], dist: Single }
        └─BatchScan { table: t, columns: [t.v1, t.v2, t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 int, v2 int);
    delete from t where v1 = 1;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchDelete { table: t }
      └─BatchExchange { order: [], dist: Single }
        └─BatchFilter { predicate: (t.v1 = 1:Int32) }
          └─BatchScan { table: t, columns: [t.v1, t.v2, t._row_id], distribution: UpstreamHashShard(t._row_id) }
- sql: |
    create table t (v1 int, v2 int);
    delete from t where v1;
  binder_error: argument of WHERE must be boolean, not type Int32
- sql: |
    select * from generate_series('2'::INT,'10'::INT,'2'::INT);
  batch_plan: |-
    BatchProject { exprs: [GenerateSeries(2:Int32, 10:Int32, 2:Int32)] }
    └─BatchProjectSet { select_list: [GenerateSeries(2:Int32, 10:Int32, 2:Int32)] }
      └─BatchValues { rows: [[]] }
- sql: |
    select * from unnest(Array[1,2,3]);
  batch_plan: |-
    BatchProject { exprs: [Unnest(ARRAY[1, 2, 3]:List(Int32))] }
    └─BatchProjectSet { select_list: [Unnest(ARRAY[1, 2, 3]:List(Int32))] }
      └─BatchValues { rows: [[]] }
- sql: |
    select * from unnest(Array[Array[1,2,3], Array[4,5,6]]);
  batch_plan: |-
    BatchProject { exprs: [Unnest(ARRAY[{1,2,3}, {4,5,6}]:List(List(Int32)))] }
    └─BatchProjectSet { select_list: [Unnest(ARRAY[{1,2,3}, {4,5,6}]:List(List(Int32)))] }
      └─BatchValues { rows: [[]] }
- sql: |
    create table t1 (x int);
    select * from t1 where EXISTS(select * where t1.x=1);
  binder_error: |
    Failed to bind expression: EXISTS (SELECT * WHERE t1.x = 1)

    Caused by:
      Bind error: SELECT * with no tables specified is not valid
- sql: |
    select *;
  binder_error: 'Bind error: SELECT * with no tables specified is not valid'
- sql: |
    select * where x = 1;
  binder_error: 'Bind error: SELECT * with no tables specified is not valid'
- sql: |
    create table t ();
    select * from t;
  logical_plan: |-
    LogicalProject { exprs: [] }
    └─LogicalScan { table: t, columns: [t._row_id, t._rw_timestamp] }
- name: disallow subquery in values
  sql: |
    values(1, (select 1));
  binder_error: |-
    Feature is not yet implemented: Subquery in VALUES
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- name: disallow correlated_input_ref in values
  sql: |
    create table t(v1 int);
    select v1 from t where exists (values(v1));
  binder_error: |
    Failed to bind expression: EXISTS (VALUES (v1))

    Caused by:
      Feature is not yet implemented: CorrelatedInputRef in VALUES
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t limit 1
  batch_plan: |-
    BatchLimit { limit: 1, offset: 0 }
    └─BatchExchange { order: [], dist: Single, sequential: true }
      └─BatchLimit { limit: 1, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], limit: 1, distribution: SomeShard }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from t order by v1 limit 1
  batch_plan: |-
    BatchTopN { order: [t.v1 ASC], limit: 1, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: [t.v1 ASC], limit: 1, offset: 0 }
        └─BatchScan { table: t, columns: [t.v1, t.v2], distribution: SomeShard }
- sql: |
    create table t (v1 int, v2 int);
    create materialized view mv(A,b) as select * from t;
    select a, b from mv;
  stream_plan: |-
    StreamMaterialize { columns: [a, b, mv.t._row_id(hidden)], stream_key: [mv.t._row_id], pk_columns: [mv.t._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: mv, columns: [mv.a, mv.b, mv.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [mv.t._row_id], pk: [t._row_id], dist: UpstreamHashShard(mv.t._row_id) }
- sql: |
    create table t (v1 int, v2 int);
    create materialized view mv(a,b) as select v1+1,v2+1 from t;
    select * from mv;
  stream_plan: |-
    StreamMaterialize { columns: [a, b, mv.t._row_id(hidden)], stream_key: [mv.t._row_id], pk_columns: [mv.t._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: mv, columns: [mv.a, mv.b, mv.t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [mv.t._row_id], pk: [t._row_id], dist: UpstreamHashShard(mv.t._row_id) }
- sql: |
    create table t (id int primary key, col int);
    create index idx on t(col);
    select id from idx;
  stream_plan: |-
    StreamMaterialize { columns: [id, idx.col(hidden)], stream_key: [idx.col, id], pk_columns: [idx.col, id], pk_conflict: NoCheck }
    └─StreamTableScan { table: idx, columns: [idx.id, idx.col], stream_scan_type: ArrangementBackfill, stream_key: [idx.col, idx.id], pk: [col, id], dist: UpstreamHashShard(idx.col) }
- sql: |
    select * from generate_series(1, 10000000, 1) where Now() is null;
  batch_plan: 'BatchValues { rows: [] }'
- sql: |
    create table t (v int);
    select * from t natural join (select * from t where 1=0);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: t.v = t.v, output: [t.v] }
      ├─BatchExchange { order: [], dist: HashShard(t.v) }
      │ └─BatchScan { table: t, columns: [t.v], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(t.v) }
        └─BatchValues { rows: [] }
  stream_plan: |-
    StreamMaterialize { columns: [v, t._row_id(hidden), t._row_id#1(hidden)], stream_key: [t._row_id, t._row_id#1, v], pk_columns: [t._row_id, t._row_id#1, v], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.v, t._row_id, t._row_id) }
      └─StreamHashJoin { type: Inner, predicate: t.v = t.v, output: [t.v, t._row_id, t._row_id] }
        ├─StreamExchange { dist: HashShard(t.v) }
        │ └─StreamTableScan { table: t, columns: [t.v, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
        └─StreamExchange { dist: HashShard(t.v) }
          └─StreamFilter { predicate: false:Boolean }
            └─StreamTableScan { table: t, columns: [t.v, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
