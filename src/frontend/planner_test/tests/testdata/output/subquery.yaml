# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- sql: |
    create table t (v1 bigint, v2 double precision);
    select v1 from (select * from t) where v2 > 1;
  logical_plan: |-
    LogicalProject { exprs: [t.v1] }
    └─LogicalFilter { predicate: (t.v2 > 1:Int32::Float64) }
      └─LogicalProject { exprs: [t.v1, t.v2] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
- name: merge and then eliminate
  sql: |
    create table t (v1 bigint, v2 double precision);
    select a1 as v1, a2 as v2 from (select v1 as a1, v2 as a2 from t);
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v2] }
    └─LogicalProject { exprs: [t.v1, t.v2] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: 'LogicalScan { table: t, columns: [t.v1, t.v2] }'
- sql: |
    create table t (v1 bigint, v2 double precision);
    select v1 from (select v2, v1 as v3 from t) where v2 > 1;
  binder_error: |
    Failed to bind expression: v1

    Caused by:
      Item not found: Invalid column: v1
- sql: |
    create table t (v1 bigint, v2 double precision);
    select v3 from (select v2, v1 as v3 from t) where v2 > 1;
  logical_plan: |-
    LogicalProject { exprs: [t.v1] }
    └─LogicalFilter { predicate: (t.v2 > 1:Int32::Float64) }
      └─LogicalProject { exprs: [t.v2, t.v1] }
        └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
- name: consecutive projects are merged
  sql: |
    create table t (v1 bigint, v2 double precision);
    select v1, 2 from (select v1, v2, 1 from t);
  logical_plan: |-
    LogicalProject { exprs: [t.v1, 2:Int32] }
    └─LogicalProject { exprs: [t.v1, t.v2, 1:Int32] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [t.v1, 2:Int32] }
    └─LogicalScan { table: t, columns: [t.v1] }
- sql: |
    create table t (v1 bigint, v2 double precision);
    select * from (select * from t);
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v2] }
    └─LogicalProject { exprs: [t.v1, t.v2] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
  optimized_logical_plan_for_batch: 'LogicalScan { table: t, columns: [t.v1, t.v2] }'
- name: joins
  sql: |
    create table t (v1 bigint, v2 double precision);
    select * from (select * from t), t;
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v2, t.v1, t.v2] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalProject { exprs: [t.v1, t.v2] }
      │ └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
- name: table alias
  sql: |
    create table t (v1 bigint, v2 double precision);
    select * from (select * from t) as tt join t on tt.v1=t.v1;
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v2, t.v1, t.v2] }
    └─LogicalJoin { type: Inner, on: (t.v1 = t.v1), output: all }
      ├─LogicalProject { exprs: [t.v1, t.v2] }
      │ └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
- name: alias less columns than available
  sql: |
    create table t (v1 bigint, v2 double precision);
    select * from (select * from t) as tt(a) join t on a=v1;
  logical_plan: |-
    LogicalProject { exprs: [t.v1, t.v2, t.v1, t.v2] }
    └─LogicalJoin { type: Inner, on: (t.v1 = t.v1), output: all }
      ├─LogicalProject { exprs: [t.v1, t.v2] }
      │ └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
      └─LogicalScan { table: t, columns: [t.v1, t.v2, t._row_id, t._rw_timestamp] }
- name: alias more columns than available
  sql: |
    create table t (v1 bigint, v2 double precision);
    select * from (select * from t) as tt(a, b, c) join t on a=v1;
  binder_error: 'Bind error: table "tt" has 2 columns available but 3 column aliases specified'
- sql: |
    create table t(x int);
    select * from t, (select * from t as t2 order by t.x desc) as t3;
  binder_error: |
    Failed to bind expression: t.x

    Caused by:
      Item not found: Invalid column: x
- sql: |
    create table t(x int);
    select * from t, (select t.x) as t1;
  binder_error: |
    Failed to bind expression: t.x

    Caused by:
      Item not found: Invalid column: x
- sql: |
    create table t(x int);
    select * from t CROSS JOIN (select t.x) as t1;
  binder_error: |
    Failed to bind expression: t.x

    Caused by:
      Item not found: Invalid column: x
- sql: |
    create table ab (a int, b int);
    create table bc (b int, c int);
    create table t (v1 int, v2 varchar);
    select * from ab where exists (
      select * from bc, (
          select * from t where v1 = a
      ) as t0
    );
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(ab.a, t.v1), output: all }
    ├─LogicalScan { table: ab, columns: [ab.a, ab.b] }
    └─LogicalJoin { type: Inner, on: true, output: all }
      ├─LogicalScan { table: bc, columns: [] }
      └─LogicalScan { table: t, columns: [t.v1], predicate: IsNotNull(t.v1) }
- name: We cannot reference columns in left table if not lateral
  sql: |
    create table ab (a int, b int);
    create table bc (b int, c int);
    create table t (v1 int, v2 varchar);
    select * from ab where exists (
      select * from bc, (
          select * from t where v1 = c
      ) as t0
    );
  binder_error: |
    Failed to bind expression: EXISTS (SELECT * FROM bc, (SELECT * FROM t WHERE v1 = c) AS t0)

    Caused by these errors (recent errors listed first):
      1: Failed to bind expression: v1 = c
      2: Item not found: Invalid column: c
- name: We need to ensure doubly nested reference to a left table is not permitted
  sql: |
    create table ab (a int, b int);
    create table bc (b int, c int);
    create table t (v1 int, v2 int);
    select * from ab, (
      select * from bc, (
          select * from t where v1 = a
      ) as t0
    );
  binder_error: |
    Failed to bind expression: v1 = a

    Caused by:
      Item not found: Invalid column: a
- sql: |
    create table t1 (x int, y int);
    create table t2 (x int, y int);
    select count(1) from (select sum(distinct 1) from t1), t2;
  logical_plan: |-
    LogicalProject { exprs: [count(1:Int32)] }
    └─LogicalAgg { aggs: [count(1:Int32)] }
      └─LogicalProject { exprs: [1:Int32] }
        └─LogicalJoin { type: Inner, on: true, output: all }
          ├─LogicalProject { exprs: [sum(distinct 1:Int32)] }
          │ └─LogicalAgg { aggs: [sum(distinct 1:Int32)] }
          │   └─LogicalProject { exprs: [1:Int32] }
          │     └─LogicalScan { table: t1, columns: [t1.x, t1.y, t1._row_id, t1._rw_timestamp] }
          └─LogicalScan { table: t2, columns: [t2.x, t2.y, t2._row_id, t2._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalAgg { aggs: [count(1:Int32)] }
    └─LogicalProject { exprs: [1:Int32] }
      └─LogicalJoin { type: Inner, on: true, output: all }
        ├─LogicalAgg { aggs: [] }
        │ └─LogicalAgg { group_key: [1:Int32], aggs: [] }
        │   └─LogicalProject { exprs: [1:Int32] }
        │     └─LogicalScan { table: t1, columns: [] }
        └─LogicalScan { table: t2, columns: [] }
  batch_plan: |-
    BatchSimpleAgg { aggs: [count(1:Int32)] }
    └─BatchProject { exprs: [1:Int32] }
      └─BatchNestedLoopJoin { type: Inner, predicate: true, output: all }
        ├─BatchSimpleAgg { aggs: [] }
        │ └─BatchExchange { order: [], dist: Single }
        │   └─BatchHashAgg { group_key: [1:Int32], aggs: [] }
        │     └─BatchExchange { order: [], dist: HashShard(1:Int32) }
        │       └─BatchProject { exprs: [1:Int32] }
        │         └─BatchScan { table: t1, columns: [], distribution: SomeShard }
        └─BatchExchange { order: [], dist: Single }
          └─BatchScan { table: t2, columns: [], distribution: SomeShard }
- sql: |
    SELECT (SELECT pg_catalog.pg_get_userbyid(1))
  logical_plan: |-
    LogicalProject { exprs: [$expr1] }
    └─LogicalApply { type: LeftOuter, on: true, correlated_id: 1, max_one_row: true }
      ├─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
      └─LogicalProject { exprs: [PgGetUserbyid(1:Int32) as $expr1] }
        └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: LeftOuter, on: true, output: all }
    ├─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
    └─LogicalProject { exprs: [PgGetUserbyid(1:Int32) as $expr1] }
      └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  batch_plan: |-
    BatchNestedLoopJoin { type: LeftOuter, predicate: true, output: all }
    ├─BatchValues { rows: [[]] }
    └─BatchProject { exprs: [PgGetUserbyid(1:Int32) as $expr1] }
      └─BatchValues { rows: [[]] }
- sql: |
    SELECT n.nspname as "Schema",
    c.relname as "Name",
    CASE c.relkind WHEN 'r' THEN 'table' WHEN 'v' THEN 'view' WHEN 'm' THEN 'materialized view' WHEN 'i' THEN 'index' WHEN 'S' THEN 'sequence' WHEN 's' THEN 'special' WHEN 't' THEN 'TOAST table' WHEN 'f' THEN 'foreign table' WHEN 'p' THEN 'partitioned table' WHEN 'I' THEN 'partitioned index' END as "Type",
    pg_catalog.pg_get_userbyid(c.relowner) as "Owner"
    FROM pg_catalog.pg_class c
    LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
    WHERE c.relkind IN ('r','p','v','m','S','f','')
    AND n.nspname <> 'pg_catalog'
    AND n.nspname !~ '^pg_toast'
    AND n.nspname <> 'information_schema'
    AND pg_catalog.pg_table_is_visible(c.oid)
    ORDER BY 1,2;
  logical_plan: |-
    LogicalProject { exprs: [rw_schemas.name, pg_class.relname, Case((pg_class.relkind = 'r':Varchar), 'table':Varchar, (pg_class.relkind = 'v':Varchar), 'view':Varchar, (pg_class.relkind = 'm':Varchar), 'materialized view':Varchar, (pg_class.relkind = 'i':Varchar), 'index':Varchar, (pg_class.relkind = 'S':Varchar), 'sequence':Varchar, (pg_class.relkind = 's':Varchar), 'special':Varchar, (pg_class.relkind = 't':Varchar), 'TOAST table':Varchar, (pg_class.relkind = 'f':Varchar), 'foreign table':Varchar, (pg_class.relkind = 'p':Varchar), 'partitioned table':Varchar, (pg_class.relkind = 'I':Varchar), 'partitioned index':Varchar) as $expr1, PgGetUserbyid(pg_class.relowner) as $expr2] }
    └─LogicalFilter { predicate: In(pg_class.relkind, 'r':Varchar, 'p':Varchar, 'v':Varchar, 'm':Varchar, 'S':Varchar, 'f':Varchar, '':Varchar) AND (rw_schemas.name <> 'pg_catalog':Varchar) AND Not(RegexpEq(rw_schemas.name, '^pg_toast':Varchar)) AND (rw_schemas.name <> 'information_schema':Varchar) AND PgTableIsVisible(pg_class.oid) }
      └─LogicalJoin { type: LeftOuter, on: (rw_schemas.id = pg_class.relnamespace), output: all }
        ├─LogicalSysScan { table: pg_class, columns: [pg_class.oid, pg_class.relname, pg_class.relnamespace, pg_class.relowner, pg_class.relpersistence, pg_class.relkind, pg_class.relpages, pg_class.relam, pg_class.reltablespace, pg_class.reloptions, pg_class.relispartition, pg_class.relpartbound] }
        └─LogicalShare { id: 2 }
          └─LogicalProject { exprs: [rw_schemas.id, rw_schemas.name, rw_schemas.owner, rw_schemas.acl] }
            └─LogicalSysScan { table: rw_schemas, columns: [rw_schemas.id, rw_schemas.name, rw_schemas.owner, rw_schemas.acl] }
  batch_plan: |-
    BatchExchange { order: [rw_schemas.name ASC, pg_class.relname ASC], dist: Single }
    └─BatchProject { exprs: [rw_schemas.name, pg_class.relname, Case((pg_class.relkind = 'r':Varchar), 'table':Varchar, (pg_class.relkind = 'v':Varchar), 'view':Varchar, (pg_class.relkind = 'm':Varchar), 'materialized view':Varchar, (pg_class.relkind = 'i':Varchar), 'index':Varchar, (pg_class.relkind = 'S':Varchar), 'sequence':Varchar, (pg_class.relkind = 's':Varchar), 'special':Varchar, (pg_class.relkind = 't':Varchar), 'TOAST table':Varchar, (pg_class.relkind = 'f':Varchar), 'foreign table':Varchar, (pg_class.relkind = 'p':Varchar), 'partitioned table':Varchar, (pg_class.relkind = 'I':Varchar), 'partitioned index':Varchar) as $expr1, PgGetUserbyid(pg_class.relowner) as $expr2] }
      └─BatchSort { order: [rw_schemas.name ASC, pg_class.relname ASC] }
        └─BatchHashJoin { type: Inner, predicate: pg_class.relnamespace = rw_schemas.id, output: [pg_class.relname, pg_class.relowner, pg_class.relkind, rw_schemas.name] }
          ├─BatchExchange { order: [], dist: HashShard(pg_class.relnamespace) }
          │ └─BatchProject { exprs: [pg_class.relname, pg_class.relnamespace, pg_class.relowner, pg_class.relkind] }
          │   └─BatchFilter { predicate: In(pg_class.relkind, 'r':Varchar, 'p':Varchar, 'v':Varchar, 'm':Varchar, 'S':Varchar, 'f':Varchar, '':Varchar) AND PgTableIsVisible(pg_class.oid) }
          │     └─BatchScan { table: pg_class, columns: [pg_class.relname, pg_class.relnamespace, pg_class.relowner, pg_class.relkind, pg_class.oid], distribution: Single }
          └─BatchExchange { order: [], dist: HashShard(rw_schemas.id) }
            └─BatchFilter { predicate: (rw_schemas.name <> 'pg_catalog':Varchar) AND Not(RegexpEq(rw_schemas.name, '^pg_toast':Varchar)) AND (rw_schemas.name <> 'information_schema':Varchar) }
              └─BatchScan { table: rw_schemas, columns: [rw_schemas.id, rw_schemas.name], distribution: Single }
- sql: |
    create table auction (date_time date);
    select * from hop( auction, auction.date_time, INTERVAL '1', INTERVAL '3600' ) AS hop_1
    where EXISTS (select hop_1.date_time group by hop_1.date_time);
  logical_plan: |-
    LogicalProject { exprs: [auction.date_time, window_start, window_end] }
    └─LogicalApply { type: LeftSemi, on: true, correlated_id: 1 }
      ├─LogicalHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: all }
      │ └─LogicalFilter { predicate: IsNotNull(auction.date_time) }
      │   └─LogicalScan { table: auction, columns: [auction.date_time, auction._row_id, auction._rw_timestamp] }
      └─LogicalProject { exprs: [CorrelatedInputRef { index: 0, correlated_id: 1 } as $expr2] }
        └─LogicalAgg { group_key: [$expr1], aggs: [] }
          └─LogicalProject { exprs: [CorrelatedInputRef { index: 0, correlated_id: 1 } as $expr1] }
            └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  optimized_logical_plan_for_batch: |-
    LogicalHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: all }
    └─LogicalFilter { predicate: IsNotNull(auction.date_time) }
      └─LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(auction.date_time, auction.date_time), output: all }
        ├─LogicalScan { table: auction, columns: [auction.date_time], predicate: IsNotNull(auction.date_time) }
        └─LogicalAgg { group_key: [auction.date_time], aggs: [] }
          └─LogicalAgg { group_key: [auction.date_time], aggs: [] }
            └─LogicalHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: [auction.date_time] }
              └─LogicalScan { table: auction, columns: [auction.date_time], predicate: IsNotNull(auction.date_time) }
  batch_plan: |-
    BatchHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: all }
    └─BatchExchange { order: [], dist: Single }
      └─BatchFilter { predicate: IsNotNull(auction.date_time) }
        └─BatchHashJoin { type: LeftSemi, predicate: auction.date_time IS NOT DISTINCT FROM auction.date_time, output: all }
          ├─BatchExchange { order: [], dist: HashShard(auction.date_time) }
          │ └─BatchFilter { predicate: IsNotNull(auction.date_time) }
          │   └─BatchScan { table: auction, columns: [auction.date_time], distribution: SomeShard }
          └─BatchHashAgg { group_key: [auction.date_time], aggs: [] }
            └─BatchHashAgg { group_key: [auction.date_time], aggs: [] }
              └─BatchHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: [auction.date_time] }
                └─BatchExchange { order: [], dist: HashShard(auction.date_time) }
                  └─BatchFilter { predicate: IsNotNull(auction.date_time) }
                    └─BatchScan { table: auction, columns: [auction.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [date_time, window_start, window_end, auction._row_id(hidden)], stream_key: [auction._row_id, window_start, window_end, date_time], pk_columns: [auction._row_id, window_start, window_end, date_time], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(auction.date_time, window_start, window_end, auction._row_id) }
      └─StreamHashJoin { type: LeftSemi, predicate: auction.date_time IS NOT DISTINCT FROM auction.date_time, output: all }
        ├─StreamExchange { dist: HashShard(auction.date_time) }
        │ └─StreamShare { id: 3 }
        │   └─StreamHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: [auction.date_time, window_start, window_end, auction._row_id] }
        │     └─StreamFilter { predicate: IsNotNull(auction.date_time) }
        │       └─StreamTableScan { table: auction, columns: [auction.date_time, auction._row_id], stream_scan_type: ArrangementBackfill, stream_key: [auction._row_id], pk: [_row_id], dist: UpstreamHashShard(auction._row_id) }
        └─StreamProject { exprs: [auction.date_time], noop_update_hint: true }
          └─StreamHashAgg { group_key: [auction.date_time], aggs: [count] }
            └─StreamProject { exprs: [auction.date_time], noop_update_hint: true }
              └─StreamHashAgg { group_key: [auction.date_time], aggs: [count] }
                └─StreamExchange { dist: HashShard(auction.date_time) }
                  └─StreamShare { id: 3 }
                    └─StreamHopWindow { time_col: auction.date_time, slide: 00:00:01, size: 01:00:00, output: [auction.date_time, window_start, window_end, auction._row_id] }
                      └─StreamFilter { predicate: IsNotNull(auction.date_time) }
                        └─StreamTableScan { table: auction, columns: [auction.date_time, auction._row_id], stream_scan_type: ArrangementBackfill, stream_key: [auction._row_id], pk: [_row_id], dist: UpstreamHashShard(auction._row_id) }
- sql: |
    CREATE TABLE t (v int);
    SELECT 1 FROM t AS t_inner WHERE EXISTS ( SELECT 1 HAVING t_inner.v > 1);
  logical_plan: |-
    LogicalProject { exprs: [1:Int32] }
    └─LogicalApply { type: LeftSemi, on: true, correlated_id: 1 }
      ├─LogicalScan { table: t, columns: [t.v, t._row_id, t._rw_timestamp] }
      └─LogicalProject { exprs: [1:Int32] }
        └─LogicalFilter { predicate: (CorrelatedInputRef { index: 0, correlated_id: 1 } > 1:Int32) }
          └─LogicalAgg { aggs: [] }
            └─LogicalProject { exprs: [] }
              └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [1:Int32] }
    └─LogicalJoin { type: LeftSemi, on: true, output: all }
      ├─LogicalScan { table: t, output_columns: [], required_columns: [t.v], predicate: (t.v > 1:Int32) }
      └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
- sql: |
    create table a (a1 int, a2 int);
    create table b (b1 int, b2 int);
    create table c (c1 int, c2 int);
    select 1 from a where exists ( select 1 from b having exists ( select a1 from c ));
  logical_plan: |-
    LogicalProject { exprs: [1:Int32] }
    └─LogicalApply { type: LeftSemi, on: true, correlated_id: 1 }
      ├─LogicalScan { table: a, columns: [a.a1, a.a2, a._row_id, a._rw_timestamp] }
      └─LogicalProject { exprs: [1:Int32] }
        └─LogicalApply { type: LeftSemi, on: true, correlated_id: 2 }
          ├─LogicalAgg { aggs: [] }
          │ └─LogicalProject { exprs: [] }
          │   └─LogicalScan { table: b, columns: [b.b1, b.b2, b._row_id, b._rw_timestamp] }
          └─LogicalProject { exprs: [CorrelatedInputRef { index: 0, correlated_id: 1 } as $expr1] }
            └─LogicalScan { table: c, columns: [c.c1, c.c2, c._row_id, c._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [1:Int32] }
    └─LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(a.a1, a.a1), output: [] }
      ├─LogicalScan { table: a, columns: [a.a1] }
      └─LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(a.a1, a.a1), output: all }
        ├─LogicalJoin { type: Inner, on: true, output: all }
        │ ├─LogicalAgg { group_key: [a.a1], aggs: [] }
        │ │ └─LogicalScan { table: a, columns: [a.a1] }
        │ └─LogicalAgg { aggs: [] }
        │   └─LogicalScan { table: b, columns: [] }
        └─LogicalJoin { type: Inner, on: true, output: all }
          ├─LogicalAgg { group_key: [a.a1], aggs: [] }
          │ └─LogicalScan { table: a, columns: [a.a1] }
          └─LogicalScan { table: c, columns: [] }
- sql: |
    create table a(a1 int, a2 int);
    create table b(b1 int, b2 int);
    select * from a where a1 = (select min(b1) from b where b2 = (select min(b1) from (select b1 from b where b1 = a1) as z ) );
  logical_plan: |-
    LogicalProject { exprs: [a.a1, a.a2] }
    └─LogicalFilter { predicate: (a.a1 = min(b.b1)) }
      └─LogicalApply { type: LeftOuter, on: true, correlated_id: 1, max_one_row: true }
        ├─LogicalScan { table: a, columns: [a.a1, a.a2, a._row_id, a._rw_timestamp] }
        └─LogicalProject { exprs: [min(b.b1)] }
          └─LogicalAgg { aggs: [min(b.b1)] }
            └─LogicalProject { exprs: [b.b1] }
              └─LogicalFilter { predicate: (b.b2 = min(b.b1)) }
                └─LogicalApply { type: LeftOuter, on: true, correlated_id: 2, max_one_row: true }
                  ├─LogicalScan { table: b, columns: [b.b1, b.b2, b._row_id, b._rw_timestamp] }
                  └─LogicalProject { exprs: [min(b.b1)] }
                    └─LogicalAgg { aggs: [min(b.b1)] }
                      └─LogicalProject { exprs: [b.b1] }
                        └─LogicalProject { exprs: [b.b1] }
                          └─LogicalFilter { predicate: (b.b1 = CorrelatedInputRef { index: 0, correlated_id: 1 }) }
                            └─LogicalScan { table: b, columns: [b.b1, b.b2, b._row_id, b._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: Inner, on: IsNotDistinctFrom(a.a1, a.a1) AND (a.a1 = min(b.b1)), output: [a.a1, a.a2] }
    ├─LogicalScan { table: a, columns: [a.a1, a.a2] }
    └─LogicalAgg { group_key: [a.a1], aggs: [min(b.b1)] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(a.a1, a.a1), output: [a.a1, b.b1] }
        ├─LogicalAgg { group_key: [a.a1], aggs: [] }
        │ └─LogicalScan { table: a, columns: [a.a1] }
        └─LogicalJoin { type: Inner, on: (b.b2 = min(b.b1)), output: [a.a1, b.b1] }
          ├─LogicalScan { table: b, columns: [b.b1, b.b2] }
          └─LogicalAgg { group_key: [a.a1], aggs: [min(b.b1)] }
            └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(a.a1, b.b1), output: [a.a1, b.b1] }
              ├─LogicalAgg { group_key: [a.a1], aggs: [] }
              │ └─LogicalScan { table: a, columns: [a.a1] }
              └─LogicalProject { exprs: [b.b1, b.b1] }
                └─LogicalScan { table: b, columns: [b.b1], predicate: IsNotNull(b.b1) }
- name: test subquery in join on condition
  sql: |
    create table a (v1 int, v2 int);
    create table b (v1 int, v2 int);
    create table c (v1 int, v2 int);
    select * from a left outer join b on a.v1 = b.v1 and a.v2 = (select v2 from c where v1 = 1 limit 1);
  planner_error: |-
    Feature is not yet implemented: Subquery in join on condition
    No tracking issue yet. Feel free to submit a feature request at https://github.com/risingwavelabs/risingwave/issues/new?labels=type%2Ffeature&template=feature_request.yml
- sql: |
    create table auction (date_time date);
    select * from auction AS hop_1
    where EXISTS (select hop_1.date_time from auction group by hop_1.date_time );
  stream_error: |-
    Not supported: streaming nested-loop join
    HINT: The non-equal join in the query requires a nested-loop join executor, which could be very expensive to run. Consider rewriting the query to use dynamic filter as a substitute if possible.
    See also: https://docs.risingwave.com/docs/current/sql-pattern-dynamic-filters/
- sql: |
    SELECT 1 a, (SELECT regexp_matches('barbeque barbeque', '(bar)(beque)', 'g')) b
  optimized_logical_plan_for_batch: |-
    LogicalProject { exprs: [1:Int32, RegexpMatches('barbeque barbeque':Varchar, '(bar)(beque)':Varchar, 'g':Varchar)] }
    └─LogicalJoin { type: LeftOuter, on: true, output: all }
      ├─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
      └─LogicalMaxOneRow
        └─LogicalProject { exprs: [RegexpMatches('barbeque barbeque':Varchar, '(bar)(beque)':Varchar, 'g':Varchar)] }
          └─LogicalProjectSet { select_list: [RegexpMatches('barbeque barbeque':Varchar, '(bar)(beque)':Varchar, 'g':Varchar)] }
            └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  stream_error: Scalar subquery might produce more than one row.
- sql: |
    create table t1 (a int, b int);
    select a, (select count(*) from t1 where t1.a <> t.b) from t1 as t order by 1;
  logical_plan: |-
    LogicalProject { exprs: [t1.a, count] }
    └─LogicalApply { type: LeftOuter, on: true, correlated_id: 1, max_one_row: true }
      ├─LogicalScan { table: t1, columns: [t1.a, t1.b, t1._row_id, t1._rw_timestamp] }
      └─LogicalProject { exprs: [count] }
        └─LogicalAgg { aggs: [count] }
          └─LogicalProject { exprs: [] }
            └─LogicalFilter { predicate: (t1.a <> CorrelatedInputRef { index: 1, correlated_id: 1 }) }
              └─LogicalScan { table: t1, columns: [t1.a, t1.b, t1._row_id, t1._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t1.b, t1.b), output: [t1.a, count(1:Int32)] }
    ├─LogicalScan { table: t1, columns: [t1.a, t1.b] }
    └─LogicalAgg { group_key: [t1.b], aggs: [count(1:Int32)] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t1.b, t1.b), output: [t1.b, 1:Int32] }
        ├─LogicalAgg { group_key: [t1.b], aggs: [] }
        │ └─LogicalScan { table: t1, columns: [t1.b] }
        └─LogicalProject { exprs: [t1.b, 1:Int32] }
          └─LogicalJoin { type: Inner, on: (t1.a <> t1.b), output: [t1.b] }
            ├─LogicalAgg { group_key: [t1.b], aggs: [] }
            │ └─LogicalScan { table: t1, columns: [t1.b] }
            └─LogicalScan { table: t1, columns: [t1.a] }
- name: test subquery on sources
  sql: |
    create source a (a1 int, a2 int)  with ( connector ='datagen' );
    create source b (b1 int, b2 int)  with ( connector ='datagen' );
    create source c (c1 int, c2 int) with ( connector ='datagen' );
    select 1 from a where exists ( select 1 from b having exists ( select a1 from c ));
  optimized_logical_plan_for_stream: |-
    LogicalProject { exprs: [1:Int32] }
    └─LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(a1, a1), output: [] }
      ├─LogicalShare { id: 2 }
      │ └─LogicalProject { exprs: [a1] }
      │   └─LogicalSource { source: a, columns: [a1, a2, _row_id] }
      └─LogicalJoin { type: LeftSemi, on: IsNotDistinctFrom(a1, a1), output: all }
        ├─LogicalJoin { type: Inner, on: true, output: all }
        │ ├─LogicalAgg { group_key: [a1], aggs: [] }
        │ │ └─LogicalShare { id: 2 }
        │ │   └─LogicalProject { exprs: [a1] }
        │ │     └─LogicalSource { source: a, columns: [a1, a2, _row_id] }
        │ └─LogicalAgg { aggs: [] }
        │   └─LogicalSource { source: b, columns: [b1, b2, _row_id] }
        └─LogicalJoin { type: Inner, on: true, output: [a1] }
          ├─LogicalAgg { group_key: [a1], aggs: [] }
          │ └─LogicalShare { id: 2 }
          │   └─LogicalProject { exprs: [a1] }
          │     └─LogicalSource { source: a, columns: [a1, a2, _row_id] }
          └─LogicalSource { source: c, columns: [c1, c2, _row_id] }
- name: test subquery in table function
  sql: |
    create table t(x int[], y int[], k int primary key);
    select *, (select sum(i) from unnest(x) i) as sum_x from t;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftOuter, predicate: t.x IS NOT DISTINCT FROM t.x, output: [t.x, t.y, t.k, sum(Unnest($0))] }
      ├─BatchExchange { order: [], dist: HashShard(t.x) }
      │ └─BatchScan { table: t, columns: [t.x, t.y, t.k], distribution: UpstreamHashShard(t.k) }
      └─BatchHashAgg { group_key: [t.x], aggs: [sum(Unnest($0))] }
        └─BatchHashJoin { type: LeftOuter, predicate: t.x IS NOT DISTINCT FROM t.x, output: [t.x, Unnest($0)] }
          ├─BatchHashAgg { group_key: [t.x], aggs: [] }
          │ └─BatchExchange { order: [], dist: HashShard(t.x) }
          │   └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
          └─BatchProject { exprs: [t.x, Unnest($0)] }
            └─BatchProjectSet { select_list: [$0, Unnest($0)] }
              └─BatchHashAgg { group_key: [t.x], aggs: [] }
                └─BatchExchange { order: [], dist: HashShard(t.x) }
                  └─BatchScan { table: t, columns: [t.x], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [x, y, k, sum_x, t.x(hidden)], stream_key: [k, x], pk_columns: [k, x], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(t.x, t.k) }
      └─StreamHashJoin { type: LeftOuter, predicate: t.x IS NOT DISTINCT FROM t.x, output: [t.x, t.y, t.k, sum(Unnest($0)), t.x] }
        ├─StreamExchange { dist: HashShard(t.x) }
        │ └─StreamTableScan { table: t, columns: [t.x, t.y, t.k], stream_scan_type: ArrangementBackfill, stream_key: [t.k], pk: [k], dist: UpstreamHashShard(t.k) }
        └─StreamProject { exprs: [t.x, sum(Unnest($0))] }
          └─StreamHashAgg { group_key: [t.x], aggs: [sum(Unnest($0)), count] }
            └─StreamHashJoin { type: LeftOuter, predicate: t.x IS NOT DISTINCT FROM t.x, output: [t.x, Unnest($0), t.x, projected_row_id] }
              ├─StreamProject { exprs: [t.x], noop_update_hint: true }
              │ └─StreamHashAgg { group_key: [t.x], aggs: [count] }
              │   └─StreamExchange { dist: HashShard(t.x) }
              │     └─StreamTableScan { table: t, columns: [t.x, t.k], stream_scan_type: ArrangementBackfill, stream_key: [t.k], pk: [k], dist: UpstreamHashShard(t.k) }
              └─StreamProject { exprs: [t.x, Unnest($0), projected_row_id] }
                └─StreamProjectSet { select_list: [$0, Unnest($0)] }
                  └─StreamProject { exprs: [t.x], noop_update_hint: true }
                    └─StreamHashAgg { group_key: [t.x], aggs: [count] }
                      └─StreamExchange { dist: HashShard(t.x) }
                        └─StreamTableScan { table: t, columns: [t.x, t.k], stream_scan_type: ArrangementBackfill, stream_key: [t.k], pk: [k], dist: UpstreamHashShard(t.k) }
- name: CorrelatedInputRef in ProjectSet and apply on condition is true.
  sql: |
    create table t(x int[], y int[], k int primary key);
    select *, (select sum(i) from (select unnest(x) i) Q ) as sum_x from t;
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, t.x), output: [t.x, t.y, t.k, sum(Unnest($0))] }
    ├─LogicalScan { table: t, columns: [t.x, t.y, t.k] }
    └─LogicalAgg { group_key: [t.x], aggs: [sum(Unnest($0))] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, t.x), output: [t.x, Unnest($0)] }
        ├─LogicalAgg { group_key: [t.x], aggs: [] }
        │ └─LogicalScan { table: t, columns: [t.x] }
        └─LogicalProject { exprs: [t.x, Unnest($0)] }
          └─LogicalProjectSet { select_list: [$0, Unnest($0)] }
            └─LogicalAgg { group_key: [t.x], aggs: [] }
              └─LogicalScan { table: t, columns: [t.x] }
  optimized_logical_plan_for_stream: |-
    LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, t.x), output: [t.x, t.y, t.k, sum(Unnest($0))] }
    ├─LogicalScan { table: t, columns: [t.x, t.y, t.k] }
    └─LogicalAgg { group_key: [t.x], aggs: [sum(Unnest($0))] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, t.x), output: [t.x, Unnest($0)] }
        ├─LogicalAgg { group_key: [t.x], aggs: [] }
        │ └─LogicalScan { table: t, columns: [t.x] }
        └─LogicalProject { exprs: [t.x, Unnest($0)] }
          └─LogicalProjectSet { select_list: [$0, Unnest($0)] }
            └─LogicalAgg { group_key: [t.x], aggs: [] }
              └─LogicalScan { table: t, columns: [t.x] }
- name: CorrelatedInputRef in ProjectSet and apply on condition refers to no table function.
  sql: |
    create table t(x int[], y int[], k int primary key);
    select *, (select sum(i) from (select unnest(x) i, 1 c) Q where k = c ) as sum_x from t;
  optimized_logical_plan_for_batch: |-
    LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, internal_last_seen_value(t.x)) AND IsNotDistinctFrom(t.k, t.k), output: [t.x, t.y, t.k, sum(Unnest($0))] }
    ├─LogicalScan { table: t, columns: [t.x, t.y, t.k] }
    └─LogicalAgg { group_key: [internal_last_seen_value(t.x), t.k], aggs: [sum(Unnest($0))] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(internal_last_seen_value(t.x), internal_last_seen_value(t.x)) AND IsNotDistinctFrom(t.k, t.k), output: [internal_last_seen_value(t.x), t.k, Unnest($0)] }
        ├─LogicalAgg { group_key: [t.k], aggs: [internal_last_seen_value(t.x)] }
        │ └─LogicalScan { table: t, columns: [t.x, t.k] }
        └─LogicalProject { exprs: [internal_last_seen_value(t.x), t.k, Unnest($0)] }
          └─LogicalProjectSet { select_list: [$0, $1, Unnest($0)] }
            └─LogicalJoin { type: Inner, on: true, output: [internal_last_seen_value(t.x), t.k] }
              ├─LogicalAgg { group_key: [t.k], aggs: [internal_last_seen_value(t.x)] }
              │ └─LogicalScan { table: t, columns: [t.x, t.k], predicate: (t.k = 1:Int32) }
              └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
  optimized_logical_plan_for_stream: |-
    LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(t.x, internal_last_seen_value(t.x)) AND IsNotDistinctFrom(t.k, t.k), output: [t.x, t.y, t.k, sum(Unnest($0))] }
    ├─LogicalScan { table: t, columns: [t.x, t.y, t.k] }
    └─LogicalAgg { group_key: [internal_last_seen_value(t.x), t.k], aggs: [sum(Unnest($0))] }
      └─LogicalJoin { type: LeftOuter, on: IsNotDistinctFrom(internal_last_seen_value(t.x), internal_last_seen_value(t.x)) AND IsNotDistinctFrom(t.k, t.k), output: [internal_last_seen_value(t.x), t.k, Unnest($0)] }
        ├─LogicalAgg { group_key: [t.k], aggs: [internal_last_seen_value(t.x)] }
        │ └─LogicalScan { table: t, columns: [t.x, t.k] }
        └─LogicalProject { exprs: [internal_last_seen_value(t.x), t.k, Unnest($0)] }
          └─LogicalProjectSet { select_list: [$0, $1, Unnest($0)] }
            └─LogicalJoin { type: Inner, on: true, output: [internal_last_seen_value(t.x), t.k] }
              ├─LogicalAgg { group_key: [t.k], aggs: [internal_last_seen_value(t.x)] }
              │ └─LogicalScan { table: t, columns: [t.x, t.k], predicate: (t.k = 1:Int32) }
              └─LogicalValues { rows: [[]], schema: Schema { fields: [] } }
- name: CorrelatedInputRef in ProjectSet and apply on condition refers to table function.
  sql: |
    create table t(x int[], y int[], k int primary key);
    select *, (select sum(i) from (select unnest(x) i) Q where k = i ) as sum_x from t;
  optimizer_error: 'internal error: Subquery can not be unnested.'
- name: test over window subquery 1
  sql: |
    CREATE TABLE integers(i INTEGER);
    SELECT i, (SELECT row_number() OVER (ORDER BY i) FROM integers WHERE i1.i=i limit 1) col FROM integers i1 ORDER BY i;
  batch_plan: |-
    BatchExchange { order: [integers.i ASC], dist: Single }
    └─BatchSort { order: [integers.i ASC] }
      └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, row_number] }
        ├─BatchExchange { order: [], dist: HashShard(integers.i) }
        │ └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
        └─BatchGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
          └─BatchProject { exprs: [integers.i, row_number] }
            └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [integers.i ASC, integers.i ASC], dist: HashShard(integers.i) }
                └─BatchSort { order: [integers.i ASC, integers.i ASC] }
                  └─BatchProject { exprs: [integers.i, integers.i] }
                    └─BatchFilter { predicate: IsNotNull(integers.i) }
                      └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [i, col, integers._row_id(hidden), integers.i(hidden)], stream_key: [integers._row_id, i], pk_columns: [i, integers._row_id], pk_conflict: NoCheck }
    └─StreamHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, row_number, integers._row_id, integers.i] }
      ├─StreamExchange { dist: HashShard(integers.i) }
      │ └─StreamTableScan { table: integers, columns: [integers.i, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
      └─StreamGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
        └─StreamProject { exprs: [integers.i, row_number, integers._row_id] }
          └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─StreamExchange { dist: HashShard(integers.i) }
              └─StreamProject { exprs: [integers.i, integers.i, integers._row_id] }
                └─StreamFilter { predicate: IsNotNull(integers.i) }
                  └─StreamTableScan { table: integers, columns: [integers.i, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
- name: test over window subquery 2 (with nested loop join so cannot be transformed into a stream plan)
  sql: |
    CREATE TABLE integers(i INTEGER);
    SELECT i1.i, (SELECT row_number() OVER (ORDER BY i) FROM integers WHERE i1.i=i limit 1) col FROM integers i1, integers i2 ORDER BY i1.i;
  batch_plan: |-
    BatchProject { exprs: [integers.i, row_number] }
    └─BatchExchange { order: [integers.i ASC], dist: Single }
      └─BatchProject { exprs: [integers.i, row_number, integers.i] }
        └─BatchSort { order: [integers.i ASC] }
          └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, row_number] }
            ├─BatchExchange { order: [], dist: HashShard(integers.i) }
            │ └─BatchNestedLoopJoin { type: Inner, predicate: true, output: all }
            │   ├─BatchExchange { order: [], dist: Single }
            │   │ └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
            │   └─BatchExchange { order: [], dist: Single }
            │     └─BatchScan { table: integers, columns: [], distribution: SomeShard }
            └─BatchGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
              └─BatchProject { exprs: [integers.i, row_number] }
                └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
                  └─BatchExchange { order: [integers.i ASC, integers.i ASC], dist: HashShard(integers.i) }
                    └─BatchSort { order: [integers.i ASC, integers.i ASC] }
                      └─BatchProject { exprs: [integers.i, integers.i] }
                        └─BatchFilter { predicate: IsNotNull(integers.i) }
                          └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
  stream_error: |-
    Not supported: streaming nested-loop join
    HINT: The non-equal join in the query requires a nested-loop join executor, which could be very expensive to run. Consider rewriting the query to use dynamic filter as a substitute if possible.
    See also: https://docs.risingwave.com/docs/current/sql-pattern-dynamic-filters/
- name: test over window subquery 3
  sql: |
    CREATE TABLE integers(i INTEGER);
    SELECT i, (SELECT SUM(i) OVER (ORDER BY i) FROM integers WHERE i1.i=i limit 1) col FROM integers i1 ORDER BY i;
  batch_plan: |-
    BatchExchange { order: [integers.i ASC], dist: Single }
    └─BatchSort { order: [integers.i ASC] }
      └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, sum] }
        ├─BatchExchange { order: [], dist: HashShard(integers.i) }
        │ └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
        └─BatchGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
          └─BatchProject { exprs: [integers.i, sum] }
            └─BatchOverWindow { window_functions: [sum(integers.i) OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [integers.i ASC, integers.i ASC], dist: HashShard(integers.i) }
                └─BatchSort { order: [integers.i ASC, integers.i ASC] }
                  └─BatchProject { exprs: [integers.i, integers.i] }
                    └─BatchFilter { predicate: IsNotNull(integers.i) }
                      └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [i, col, integers._row_id(hidden), integers.i(hidden)], stream_key: [integers._row_id, i], pk_columns: [i, integers._row_id], pk_conflict: NoCheck }
    └─StreamHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, sum, integers._row_id, integers.i] }
      ├─StreamExchange { dist: HashShard(integers.i) }
      │ └─StreamTableScan { table: integers, columns: [integers.i, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
      └─StreamGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
        └─StreamProject { exprs: [integers.i, sum, integers._row_id] }
          └─StreamOverWindow { window_functions: [sum(integers.i) OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─StreamExchange { dist: HashShard(integers.i) }
              └─StreamProject { exprs: [integers.i, integers.i, integers._row_id] }
                └─StreamFilter { predicate: IsNotNull(integers.i) }
                  └─StreamTableScan { table: integers, columns: [integers.i, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
- name: test over window subquery 4  (with nested loop join so cannot be transformed into a stream plan)
  sql: |
    CREATE TABLE integers(i INTEGER);
    SELECT i, (SELECT SUM(s1.i) OVER (ORDER BY s1.i) FROM integers s1, integers s2 WHERE i1.i=s1.i LIMIT 1) col FROM integers i1 ORDER BY i;
  batch_plan: |-
    BatchExchange { order: [integers.i ASC], dist: Single }
    └─BatchSort { order: [integers.i ASC] }
      └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, sum] }
        ├─BatchExchange { order: [], dist: HashShard(integers.i) }
        │ └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
        └─BatchGroupTopN { order: [integers.i ASC], limit: 1, offset: 0, group_key: [integers.i] }
          └─BatchProject { exprs: [integers.i, sum] }
            └─BatchOverWindow { window_functions: [sum(integers.i) OVER(PARTITION BY integers.i ORDER BY integers.i ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─BatchExchange { order: [integers.i ASC, integers.i ASC], dist: HashShard(integers.i) }
                └─BatchSort { order: [integers.i ASC, integers.i ASC] }
                  └─BatchProject { exprs: [integers.i, integers.i] }
                    └─BatchNestedLoopJoin { type: Inner, predicate: true, output: all }
                      ├─BatchExchange { order: [], dist: Single }
                      │ └─BatchFilter { predicate: IsNotNull(integers.i) }
                      │   └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
                      └─BatchExchange { order: [], dist: Single }
                        └─BatchScan { table: integers, columns: [], distribution: SomeShard }
  stream_error: |-
    Not supported: streaming nested-loop join
    HINT: The non-equal join in the query requires a nested-loop join executor, which could be very expensive to run. Consider rewriting the query to use dynamic filter as a substitute if possible.
    See also: https://docs.risingwave.com/docs/current/sql-pattern-dynamic-filters/
- name: test over window subquery 5
  sql: |
    CREATE TABLE integers(i INTEGER, correlated_col int);
    CREATE TABLE rows(k int, v int, correlated_col int);
    SELECT i FROM integers where i in (select SUM(v) OVER(PARTITION BY k ORDER BY v) from rows where rows.correlated_col = integers.correlated_col);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftSemi, predicate: $expr1 = sum AND integers.correlated_col IS NOT DISTINCT FROM rows.correlated_col, output: [integers.i] }
      ├─BatchExchange { order: [], dist: HashShard(integers.correlated_col, $expr1) }
      │ └─BatchProject { exprs: [integers.i, integers.correlated_col, integers.i::Int64 as $expr1] }
      │   └─BatchScan { table: integers, columns: [integers.i, integers.correlated_col], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(rows.correlated_col, sum) }
        └─BatchProject { exprs: [rows.correlated_col, sum] }
          └─BatchOverWindow { window_functions: [sum(rows.v) OVER(PARTITION BY rows.correlated_col, rows.k ORDER BY rows.v ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
            └─BatchExchange { order: [rows.correlated_col ASC, rows.k ASC, rows.v ASC], dist: HashShard(rows.correlated_col, rows.k) }
              └─BatchSort { order: [rows.correlated_col ASC, rows.k ASC, rows.v ASC] }
                └─BatchProject { exprs: [rows.correlated_col, rows.k, rows.v] }
                  └─BatchFilter { predicate: IsNotNull(rows.correlated_col) }
                    └─BatchScan { table: rows, columns: [rows.k, rows.v, rows.correlated_col], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [i, integers._row_id(hidden), $expr1(hidden), integers.correlated_col(hidden)], stream_key: [integers._row_id, $expr1, integers.correlated_col], pk_columns: [integers._row_id, $expr1, integers.correlated_col], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(integers._row_id, $expr1, integers.correlated_col) }
      └─StreamHashJoin { type: LeftSemi, predicate: $expr1 = sum AND integers.correlated_col IS NOT DISTINCT FROM rows.correlated_col, output: [integers.i, integers._row_id, $expr1, integers.correlated_col] }
        ├─StreamExchange { dist: HashShard(integers.correlated_col, $expr1) }
        │ └─StreamProject { exprs: [integers.i, integers.correlated_col, integers.i::Int64 as $expr1, integers._row_id] }
        │   └─StreamTableScan { table: integers, columns: [integers.i, integers.correlated_col, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
        └─StreamExchange { dist: HashShard(rows.correlated_col, sum) }
          └─StreamProject { exprs: [rows.correlated_col, sum, rows._row_id, rows.k] }
            └─StreamOverWindow { window_functions: [sum(rows.v) OVER(PARTITION BY rows.correlated_col, rows.k ORDER BY rows.v ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
              └─StreamExchange { dist: HashShard(rows.correlated_col, rows.k) }
                └─StreamProject { exprs: [rows.correlated_col, rows.k, rows.v, rows._row_id] }
                  └─StreamFilter { predicate: IsNotNull(rows.correlated_col) }
                    └─StreamTableScan { table: rows, columns: [rows.k, rows.v, rows.correlated_col, rows._row_id], stream_scan_type: ArrangementBackfill, stream_key: [rows._row_id], pk: [_row_id], dist: UpstreamHashShard(rows._row_id) }
- name: test cardinality visitor with correlated filter
  sql: |
    CREATE TABLE t1(i INT);
    CREATE TABLE t2(j INT);
    select *, (select 1 from (select 1 from t2) where t1.i = 1) from t1;
  optimizer_error: 'internal error: Scalar subquery might produce more than one row.'
- name: test grouping sets subquery 1
  sql: |
    CREATE TABLE integers(i INTEGER);
    SELECT i, (SELECT COUNT(*) FROM (SELECT i1.i FROM integers GROUP BY GROUPING SETS(i1.i)) tbl) AS j FROM integers i1 ORDER BY i;
  batch_plan: |-
    BatchExchange { order: [integers.i ASC], dist: Single }
    └─BatchSort { order: [integers.i ASC] }
      └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, count(1:Int32)] }
        ├─BatchExchange { order: [], dist: HashShard(integers.i) }
        │ └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
        └─BatchHashAgg { group_key: [integers.i], aggs: [count(1:Int32)] }
          └─BatchHashJoin { type: LeftOuter, predicate: integers.i IS NOT DISTINCT FROM integers.i, output: [integers.i, 1:Int32] }
            ├─BatchHashAgg { group_key: [integers.i], aggs: [] }
            │ └─BatchExchange { order: [], dist: HashShard(integers.i) }
            │   └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
            └─BatchExchange { order: [], dist: HashShard(integers.i) }
              └─BatchProject { exprs: [integers.i, 1:Int32] }
                └─BatchHashAgg { group_key: [integers.i, integers.i, 0:Int64], aggs: [] }
                  └─BatchExchange { order: [], dist: HashShard(integers.i, integers.i, 0:Int64) }
                    └─BatchProject { exprs: [integers.i, integers.i, 0:Int64] }
                      └─BatchNestedLoopJoin { type: Inner, predicate: true, output: all }
                        ├─BatchExchange { order: [], dist: Single }
                        │ └─BatchHashAgg { group_key: [integers.i], aggs: [] }
                        │   └─BatchExchange { order: [], dist: HashShard(integers.i) }
                        │     └─BatchScan { table: integers, columns: [integers.i], distribution: SomeShard }
                        └─BatchExchange { order: [], dist: Single }
                          └─BatchScan { table: integers, columns: [], distribution: SomeShard }
- name: test expand operator subquery 1
  sql: |
    CREATE TABLE integers(i INTEGER, correlated_col int);
    CREATE TABLE rows(k int, v int, correlated_col int);
    select * from integers where 2 in (select count(distinct k) + count(distinct v) from rows where correlated_col = integers.correlated_col);
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftSemi, predicate: integers.correlated_col IS NOT DISTINCT FROM integers.correlated_col_expanded AND 2:Int64 = $expr1, output: [integers.i, integers.correlated_col] }
      ├─BatchExchange { order: [], dist: HashShard(integers.correlated_col) }
      │ └─BatchProject { exprs: [integers.i, integers.correlated_col, 2:Int64] }
      │   └─BatchScan { table: integers, columns: [integers.i, integers.correlated_col], distribution: SomeShard }
      └─BatchProject { exprs: [integers.correlated_col_expanded, (count(rows.k_expanded) filter((flag = 0:Int64)) + count(rows.v_expanded) filter((flag = 1:Int64))) as $expr1] }
        └─BatchHashAgg { group_key: [integers.correlated_col_expanded], aggs: [count(rows.k_expanded) filter((flag = 0:Int64)), count(rows.v_expanded) filter((flag = 1:Int64))] }
          └─BatchExchange { order: [], dist: HashShard(integers.correlated_col_expanded) }
            └─BatchHashAgg { group_key: [integers.correlated_col_expanded, rows.k_expanded, rows.v_expanded, flag], aggs: [] }
              └─BatchExchange { order: [], dist: HashShard(integers.correlated_col_expanded, rows.k_expanded, rows.v_expanded, flag) }
                └─BatchExpand { column_subsets: [[integers.correlated_col, rows.k], [integers.correlated_col, rows.v]] }
                  └─BatchHashJoin { type: LeftOuter, predicate: integers.correlated_col IS NOT DISTINCT FROM rows.correlated_col, output: [integers.correlated_col, rows.k, rows.v, 1:Int32] }
                    ├─BatchHashAgg { group_key: [integers.correlated_col], aggs: [] }
                    │ └─BatchExchange { order: [], dist: HashShard(integers.correlated_col) }
                    │   └─BatchScan { table: integers, columns: [integers.correlated_col], distribution: SomeShard }
                    └─BatchExchange { order: [], dist: HashShard(rows.correlated_col) }
                      └─BatchProject { exprs: [rows.correlated_col, rows.k, rows.v, 1:Int32] }
                        └─BatchFilter { predicate: IsNotNull(rows.correlated_col) }
                          └─BatchScan { table: rows, columns: [rows.k, rows.v, rows.correlated_col], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [i, correlated_col, integers._row_id(hidden), 2:Int64(hidden)], stream_key: [integers._row_id, correlated_col, 2:Int64], pk_columns: [integers._row_id, correlated_col, 2:Int64], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(integers.correlated_col, integers._row_id, 2:Int64) }
      └─StreamHashJoin { type: LeftSemi, predicate: integers.correlated_col IS NOT DISTINCT FROM integers.correlated_col AND 2:Int64 = $expr1, output: [integers.i, integers.correlated_col, integers._row_id, 2:Int64] }
        ├─StreamExchange { dist: HashShard(integers.correlated_col) }
        │ └─StreamProject { exprs: [integers.i, integers.correlated_col, 2:Int64, integers._row_id] }
        │   └─StreamTableScan { table: integers, columns: [integers.i, integers.correlated_col, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
        └─StreamProject { exprs: [integers.correlated_col, (count(distinct rows.k) + count(distinct rows.v)) as $expr1] }
          └─StreamHashAgg { group_key: [integers.correlated_col], aggs: [count(distinct rows.k), count(distinct rows.v), count] }
            └─StreamHashJoin { type: LeftOuter, predicate: integers.correlated_col IS NOT DISTINCT FROM rows.correlated_col, output: [integers.correlated_col, rows.k, rows.v, rows._row_id] }
              ├─StreamProject { exprs: [integers.correlated_col], noop_update_hint: true }
              │ └─StreamHashAgg { group_key: [integers.correlated_col], aggs: [count] }
              │   └─StreamExchange { dist: HashShard(integers.correlated_col) }
              │     └─StreamTableScan { table: integers, columns: [integers.correlated_col, integers._row_id], stream_scan_type: ArrangementBackfill, stream_key: [integers._row_id], pk: [_row_id], dist: UpstreamHashShard(integers._row_id) }
              └─StreamExchange { dist: HashShard(rows.correlated_col) }
                └─StreamProject { exprs: [rows.correlated_col, rows.k, rows.v, rows._row_id] }
                  └─StreamFilter { predicate: IsNotNull(rows.correlated_col) }
                    └─StreamTableScan { table: rows, columns: [rows.k, rows.v, rows.correlated_col, rows._row_id], stream_scan_type: ArrangementBackfill, stream_key: [rows._row_id], pk: [_row_id], dist: UpstreamHashShard(rows._row_id) }
- name: test hop window subquery 1
  sql: |
    create table t1 (k int primary key, ts timestamp);
    select * from (select 1 as col union select 2) u , lateral(select * from hop(t1, ts, interval '10' minute, interval '30' minute) where col = k);
  batch_plan: |-
    BatchHopWindow { time_col: t1.ts, slide: 00:10:00, size: 00:30:00, output: all }
    └─BatchExchange { order: [], dist: Single }
      └─BatchFilter { predicate: IsNotNull(t1.ts) }
        └─BatchLookupJoin { type: Inner, predicate: 1:Int32 = t1.k AND IsNotNull(t1.ts), output: all, lookup table: t1 }
          └─BatchExchange { order: [], dist: UpstreamHashShard(1:Int32) }
            └─BatchHashAgg { group_key: [1:Int32], aggs: [] }
              └─BatchExchange { order: [], dist: HashShard(1:Int32) }
                └─BatchValues { rows: [[1:Int32], [2:Int32]] }
  stream_plan: |-
    StreamMaterialize { columns: [col, k, ts, window_start, window_end], stream_key: [col, window_start, window_end], pk_columns: [col, window_start, window_end], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(1:Int32, window_start, window_end) }
      └─StreamHashJoin { type: Inner, predicate: 1:Int32 = t1.k, output: all }
        ├─StreamAppendOnlyDedup { dedup_cols: [1:Int32] }
        │ └─StreamExchange { dist: HashShard(1:Int32) }
        │   └─StreamProject { exprs: [1:Int32] }
        │     └─StreamValues { rows: [[1:Int32, 0:Int64], [2:Int32, 1:Int64]] }
        └─StreamExchange { dist: HashShard(t1.k) }
          └─StreamHopWindow { time_col: t1.ts, slide: 00:10:00, size: 00:30:00, output: all }
            └─StreamFilter { predicate: IsNotNull(t1.ts) }
              └─StreamTableScan { table: t1, columns: [t1.k, t1.ts], stream_scan_type: ArrangementBackfill, stream_key: [t1.k], pk: [k], dist: UpstreamHashShard(t1.k) }
- name: Only table-in-out functions can have subquery parameters.
  sql: |
    SELECT * FROM generate_series(1, (select 1));
  binder_error: 'Invalid input syntax: Only table-in-out functions can have subquery parameters. The table function has subquery parameters is generate_series'
- name: While this one is allowed.
  sql: |
    SELECT generate_series(1, (select 1));
  batch_plan: |-
    BatchProject { exprs: [GenerateSeries(1:Int32, $0)] }
    └─BatchProjectSet { select_list: [GenerateSeries(1:Int32, $0)] }
      └─BatchNestedLoopJoin { type: LeftOuter, predicate: true, output: all }
        ├─BatchValues { rows: [[]] }
        └─BatchValues { rows: [[1:Int32]] }
- name: array subquery
  sql: |
    select Array(select 1 union select 2);
  batch_plan: |-
    BatchNestedLoopJoin { type: LeftOuter, predicate: true, output: all }
    ├─BatchValues { rows: [[]] }
    └─BatchProject { exprs: [Coalesce(array_agg(1:Int32), ARRAY[]:List(Int32)) as $expr1] }
      └─BatchSimpleAgg { aggs: [array_agg(1:Int32)] }
        └─BatchExchange { order: [], dist: Single }
          └─BatchHashAgg { group_key: [1:Int32], aggs: [] }
            └─BatchExchange { order: [], dist: HashShard(1:Int32) }
              └─BatchValues { rows: [[1:Int32], [2:Int32]] }
- name: Only table-in-out functions can have subquery parameters. issue 14734
  sql: |
    SELECT anon_1.f1 AS "IntegerRange(0, -2, 1)" FROM unnest(CASE WHEN (nullif(1, 0) IS NOT NULL AND sign(1) = sign( -2 - 0)) THEN array_remove(array((SELECT generate_series(0,  -2, 1) AS generate_series_1)),  -2) ELSE CAST(ARRAY[] AS SMALLINT[]) END) AS anon_1(f1);
  binder_error: 'Invalid input syntax: Only table-in-out functions can have subquery parameters. The table function has subquery parameters is unnest'
