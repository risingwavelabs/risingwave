# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: create_sources
  sql: |
    create source auction (id BIGINT, "item_name" VARCHAR, description VARCHAR, "initial_bid" BIGINT, reserve BIGINT, "date_time" TIMESTAMP, expires TIMESTAMP, seller BIGINT, category BIGINT, "extra" VARCHAR)
    with (
    connector = 'nexmark',
    nexmark.table.type = 'Auction',
    nexmark.split.num = '4',
    nexmark.min.event.gap.in.ns = '1000'
    );
    create source bid (auction BIGINT, bidder BIGINT, price BIGINT, "channel" VARCHAR, "url" VARCHAR, "date_time" TIMESTAMP, "extra" VARCHAR)
    with (
    connector = 'nexmark',
    nexmark.table.type = 'Bid',
    nexmark.split.num = '4',
    nexmark.min.event.gap.in.ns = '1000'
    );
    create table table_for_fixed_now_timestamp;
- id: self_join
  before:
  - create_sources
  sql: |
    select count(*) cnt from auction A join auction B on A.id = B.id where A.initial_bid = 1 and B.initial_bid = 2;
  batch_plan: |-
    BatchSimpleAgg { aggs: [sum0(count)] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [count] }
        └─BatchHashJoin { type: Inner, predicate: id = id, output: [] }
          ├─BatchExchange { order: [], dist: HashShard(id) }
          │ └─BatchFilter { predicate: (initial_bid = 1:Int32) }
          │   └─BatchSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
          └─BatchExchange { order: [], dist: HashShard(id) }
            └─BatchFilter { predicate: (initial_bid = 2:Int32) }
              └─BatchSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
  stream_plan: |-
    StreamMaterialize { columns: [cnt], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamSimpleAgg [append_only] { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamHashJoin [append_only] { type: Inner, predicate: id = id, output: [_row_id, id, _row_id] }
              ├─StreamExchange { dist: HashShard(id) }
              │ └─StreamFilter { predicate: (initial_bid = 1:Int32) }
              │   └─StreamShare { id: 4 }
              │     └─StreamProject { exprs: [id, initial_bid, _row_id] }
              │       └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
              │         └─StreamRowIdGen { row_id_index: 10 }
              │           └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
              └─StreamExchange { dist: HashShard(id) }
                └─StreamFilter { predicate: (initial_bid = 2:Int32) }
                  └─StreamShare { id: 4 }
                    └─StreamProject { exprs: [id, initial_bid, _row_id] }
                      └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
                        └─StreamRowIdGen { row_id_index: 10 }
                          └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
- id: nexmark_q5
  before:
  - create_sources
  sql: |
    SELECT AuctionBids.auction, AuctionBids.num FROM (
      SELECT
        bid.auction,
        count(*) AS num,
        window_start AS starttime
      FROM
        HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
      GROUP BY
        window_start,
        bid.auction
    ) AS AuctionBids
    JOIN (
      SELECT
        max(CountBids.num) AS maxn,
        CountBids.starttime_c
      FROM (
        SELECT
          count(*) AS num,
          window_start AS starttime_c
        FROM HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
        GROUP BY
          bid.auction,
          window_start
      ) AS CountBids
      GROUP BY
        CountBids.starttime_c
    ) AS MaxBids
    ON AuctionBids.starttime = MaxBids.starttime_c AND AuctionBids.num >= MaxBids.maxn;
  logical_plan: |-
    LogicalProject { exprs: [auction, count] }
    └─LogicalJoin { type: Inner, on: (window_start = window_start) AND (count >= max(count)), output: all }
      ├─LogicalProject { exprs: [auction, count, window_start] }
      │ └─LogicalAgg { group_key: [window_start, auction], aggs: [count] }
      │   └─LogicalProject { exprs: [window_start, auction] }
      │     └─LogicalHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: all }
      │       └─LogicalFilter { predicate: IsNotNull(date_time) }
      │         └─LogicalSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
      └─LogicalProject { exprs: [max(count), window_start] }
        └─LogicalAgg { group_key: [window_start], aggs: [max(count)] }
          └─LogicalProject { exprs: [window_start, count] }
            └─LogicalProject { exprs: [count, window_start] }
              └─LogicalAgg { group_key: [auction, window_start], aggs: [count] }
                └─LogicalProject { exprs: [auction, window_start] }
                  └─LogicalHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: all }
                    └─LogicalFilter { predicate: IsNotNull(date_time) }
                      └─LogicalSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: window_start = window_start AND (count >= max(count)), output: [auction, count] }
      ├─BatchExchange { order: [], dist: HashShard(window_start) }
      │ └─BatchHashAgg { group_key: [auction, window_start], aggs: [count] }
      │   └─BatchHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start] }
      │     └─BatchExchange { order: [], dist: HashShard(auction) }
      │       └─BatchProject { exprs: [auction, date_time] }
      │         └─BatchFilter { predicate: IsNotNull(date_time) }
      │           └─BatchSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
      └─BatchHashAgg { group_key: [window_start], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(window_start) }
          └─BatchHashAgg { group_key: [auction, window_start], aggs: [count] }
            └─BatchHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start] }
              └─BatchExchange { order: [], dist: HashShard(auction) }
                └─BatchProject { exprs: [auction, date_time] }
                  └─BatchFilter { predicate: IsNotNull(date_time) }
                    └─BatchSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
  stream_plan: |-
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start], pk_columns: [auction, window_start], pk_conflict: NoCheck }
    └─StreamProject { exprs: [auction, count, window_start, window_start] }
      └─StreamFilter { predicate: (count >= max(count)) }
        └─StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all }
          ├─StreamExchange { dist: HashShard(window_start) }
          │ └─StreamShare { id: 7 }
          │   └─StreamHashAgg [append_only] { group_key: [auction, window_start], aggs: [count] }
          │     └─StreamExchange { dist: HashShard(auction, window_start) }
          │       └─StreamHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start, _row_id] }
          │         └─StreamProject { exprs: [auction, date_time, _row_id] }
          │           └─StreamFilter { predicate: IsNotNull(date_time) }
          │             └─StreamRowIdGen { row_id_index: 7 }
          │               └─StreamSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
          └─StreamProject { exprs: [window_start, max(count)] }
            └─StreamHashAgg { group_key: [window_start], aggs: [max(count), count] }
              └─StreamExchange { dist: HashShard(window_start) }
                └─StreamShare { id: 7 }
                  └─StreamHashAgg [append_only] { group_key: [auction, window_start], aggs: [count] }
                    └─StreamExchange { dist: HashShard(auction, window_start) }
                      └─StreamHopWindow { time_col: date_time, slide: 00:00:02, size: 00:00:10, output: [auction, window_start, _row_id] }
                        └─StreamProject { exprs: [auction, date_time, _row_id] }
                          └─StreamFilter { predicate: IsNotNull(date_time) }
                            └─StreamRowIdGen { row_id_index: 7 }
                              └─StreamSource { source: bid, columns: [auction, bidder, price, channel, url, date_time, extra, _row_id] }
- sql: |
    set rw_enable_share_plan=true;
    create table t(a int, b int);
    with cte as (select count(*) from t) select * from cte union all select * from cte;
  stream_plan: |-
    StreamMaterialize { columns: [count, $src(hidden)], stream_key: [$src], pk_columns: [$src], pk_conflict: NoCheck }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(0:Int32) }
      │ └─StreamProject { exprs: [sum0(count), 0:Int32] }
      │   └─StreamShare { id: 5 }
      │     └─StreamProject { exprs: [sum0(count)] }
      │       └─StreamSimpleAgg { aggs: [sum0(count), count] }
      │         └─StreamExchange { dist: Single }
      │           └─StreamStatelessSimpleAgg { aggs: [count] }
      │             └─StreamTableScan { table: t, columns: [t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
      └─StreamExchange { dist: HashShard(1:Int32) }
        └─StreamProject { exprs: [sum0(count), 1:Int32] }
          └─StreamShare { id: 5 }
            └─StreamProject { exprs: [sum0(count)] }
              └─StreamSimpleAgg { aggs: [sum0(count), count] }
                └─StreamExchange { dist: Single }
                  └─StreamStatelessSimpleAgg { aggs: [count] }
                    └─StreamTableScan { table: t, columns: [t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- sql: |
    set rw_enable_share_plan=false;
    create table t(a int, b int);
    with cte as (select count(*) from t) select * from cte union all select * from cte;
  stream_plan: |-
    StreamMaterialize { columns: [count, $src(hidden)], stream_key: [$src], pk_columns: [$src], pk_conflict: NoCheck }
    └─StreamUnion { all: true }
      ├─StreamExchange { dist: HashShard(0:Int32) }
      │ └─StreamProject { exprs: [sum0(count), 0:Int32] }
      │   └─StreamSimpleAgg { aggs: [sum0(count), count] }
      │     └─StreamExchange { dist: Single }
      │       └─StreamStatelessSimpleAgg { aggs: [count] }
      │         └─StreamTableScan { table: t, columns: [t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
      └─StreamExchange { dist: HashShard(1:Int32) }
        └─StreamProject { exprs: [sum0(count), 1:Int32] }
          └─StreamSimpleAgg { aggs: [sum0(count), count] }
            └─StreamExchange { dist: Single }
              └─StreamStatelessSimpleAgg { aggs: [count] }
                └─StreamTableScan { table: t, columns: [t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
- id: force_share_source_for_self_join
  before:
  - create_sources
  sql: |
    set rw_enable_share_plan=false;
    select count(*) cnt from auction A join auction B on A.id = B.id;
  stream_plan: |-
    StreamMaterialize { columns: [cnt], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamSimpleAgg [append_only] { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamHashJoin [append_only] { type: Inner, predicate: id = id, output: [_row_id, id, _row_id] }
              ├─StreamExchange { dist: HashShard(id) }
              │ └─StreamShare { id: 3 }
              │   └─StreamProject { exprs: [id, _row_id] }
              │     └─StreamRowIdGen { row_id_index: 10 }
              │       └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
              └─StreamExchange { dist: HashShard(id) }
                └─StreamShare { id: 3 }
                  └─StreamProject { exprs: [id, _row_id] }
                    └─StreamRowIdGen { row_id_index: 10 }
                      └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
- id: self_join_multiple_edges
  sql: |
    create table t (a int, b int);
    with cte as (select a, sum(b) sum from t group by a) select count(*) from cte c1 join cte c2 on c1.a = c2.a;
  stream_plan: |-
    StreamMaterialize { columns: [count], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    └─StreamProject { exprs: [sum0(count)] }
      └─StreamSimpleAgg { aggs: [sum0(count), count] }
        └─StreamExchange { dist: Single }
          └─StreamStatelessSimpleAgg { aggs: [count] }
            └─StreamHashJoin { type: Inner, predicate: t.a = t.a, output: all }
              ├─StreamShare { id: 4 }
              │ └─StreamProject { exprs: [t.a], noop_update_hint: true }
              │   └─StreamHashAgg { group_key: [t.a], aggs: [count] }
              │     └─StreamExchange { dist: HashShard(t.a) }
              │       └─StreamTableScan { table: t, columns: [t.a, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
              └─StreamShare { id: 4 }
                └─StreamProject { exprs: [t.a], noop_update_hint: true }
                  └─StreamHashAgg { group_key: [t.a], aggs: [count] }
                    └─StreamExchange { dist: HashShard(t.a) }
                      └─StreamTableScan { table: t, columns: [t.a, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [count], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [sum0(count)] }
        └── StreamSimpleAgg { aggs: [sum0(count), count] } { tables: [ SimpleAggState: 0 ] }
            └── StreamExchange Single from 1

    Fragment 1
    StreamStatelessSimpleAgg { aggs: [count] }
    └── StreamHashJoin { type: Inner, predicate: t.a = t.a, output: all }
        ├── tables:
        │   ┌── HashJoinLeft: 1
        │   ├── HashJoinDegreeLeft: 2
        │   ├── HashJoinRight: 3
        │   └── HashJoinDegreeRight: 4
        ├── StreamExchange NoShuffle from 2
        └── StreamExchange NoShuffle from 4

    Fragment 2
    StreamProject { exprs: [t.a], noop_update_hint: true }
    └── StreamHashAgg { group_key: [t.a], aggs: [count] } { tables: [ HashAggState: 5 ] }
        └── StreamExchange Hash([0]) from 3

    Fragment 3
    StreamTableScan { table: t, columns: [t.a, t._row_id], stream_scan_type: ArrangementBackfill, stream_key: [t._row_id], pk: [_row_id], dist: UpstreamHashShard(t._row_id) }
    ├── tables: [ StreamScan: 6 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 4
    StreamNoOp
    └── StreamExchange NoShuffle from 2

    Table 0 { columns: [ sum0(count), count ], primary key: [], value indices: [ 0, 1 ], distribution key: [], read pk prefix len hint: 0 }

    Table 1 { columns: [ t_a ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ t_a, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ t_a ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ t_a, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ t_a, count ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6
    ├── columns: [ vnode, _row_id, backfill_finished, row_count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ count ], primary key: [], value indices: [ 0 ], distribution key: [], read pk prefix len hint: 0 }

- id: self_join_with_temporal_filter_one_side
  before:
  - create_sources
  sql: |
    select A.id as a_id, B.id as b_id, A.date_time as A_ts, B.date_time as B_ts from auction A join auction B on A.id = B.id where A.initial_bid = 1 and B.initial_bid = 2 and A.date_time > now() - INTERVAL '1' SECOND;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: id = id, output: [id, id, date_time, date_time] }
      ├─BatchExchange { order: [], dist: HashShard(id) }
      │ └─BatchFilter { predicate: (initial_bid = 1:Int32) AND (AtTimeZone(date_time, 'UTC':Varchar) > '2021-03-31 23:59:59+00:00':Timestamptz) }
      │   └─BatchProject { exprs: [id, initial_bid, date_time] }
      │     └─BatchSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
      └─BatchExchange { order: [], dist: HashShard(id) }
        └─BatchFilter { predicate: (initial_bid = 2:Int32) }
          └─BatchProject { exprs: [id, initial_bid, date_time] }
            └─BatchSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
  stream_plan: |-
    StreamMaterialize { columns: [a_id, b_id, a_ts, b_ts, _row_id(hidden), _row_id#1(hidden)], stream_key: [_row_id, _row_id#1, a_id], pk_columns: [_row_id, _row_id#1, a_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(id, _row_id, _row_id) }
      └─StreamHashJoin { type: Inner, predicate: id = id, output: [id, id, date_time, date_time, _row_id, _row_id] }
        ├─StreamExchange { dist: HashShard(id) }
        │ └─StreamProject { exprs: [id, date_time, _row_id] }
        │   └─StreamDynamicFilter { predicate: ($expr1 > $expr2), output_watermarks: [$expr1], output: [id, date_time, $expr1, _row_id], cleaned_by_watermark: true }
        │     ├─StreamProject { exprs: [id, date_time, AtTimeZone(date_time, 'UTC':Varchar) as $expr1, _row_id] }
        │     │ └─StreamFilter { predicate: (initial_bid = 1:Int32) }
        │     │   └─StreamShare { id: 4 }
        │     │     └─StreamProject { exprs: [id, initial_bid, date_time, _row_id] }
        │     │       └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
        │     │         └─StreamRowIdGen { row_id_index: 10 }
        │     │           └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
        │     └─StreamExchange { dist: Broadcast }
        │       └─StreamProject { exprs: [SubtractWithTimeZone(now, '00:00:01':Interval, 'UTC':Varchar) as $expr2], output_watermarks: [$expr2] }
        │         └─StreamNow { output: [now] }
        └─StreamExchange { dist: HashShard(id) }
          └─StreamFilter { predicate: (initial_bid = 2:Int32) }
            └─StreamShare { id: 4 }
              └─StreamProject { exprs: [id, initial_bid, date_time, _row_id] }
                └─StreamFilter { predicate: ((initial_bid = 1:Int32) OR (initial_bid = 2:Int32)) }
                  └─StreamRowIdGen { row_id_index: 10 }
                    └─StreamSource { source: auction, columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, extra, _row_id] }
