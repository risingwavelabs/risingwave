# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: create_tables
  sql: |
    CREATE TABLE person (
        id BIGINT,
        name VARCHAR,
        email_address VARCHAR,
        credit_card VARCHAR,
        city VARCHAR,
        state VARCHAR,
        date_time TIMESTAMP,
        PRIMARY KEY (id)
    );

    CREATE TABLE auction (
        id BIGINT,
        "item_name" VARCHAR,
        "description" VARCHAR,
        "initial_bid" BIGINT,
        "reserve" BIGINT,
        "date_time" TIMESTAMP,
        "expires" TIMESTAMP,
        "seller" BIGINT,
        "category" BIGINT,
        PRIMARY KEY (id)
    );

    CREATE TABLE bid (
        "auction" BIGINT,
        "bidder" BIGINT,
        "price" BIGINT,
        "channel" VARCHAR,
        "url" VARCHAR,
        "date_time" TIMESTAMP,
        "extra" VARCHAR
    ) append only;
- id: nexmark_q0
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, date_time FROM bid;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time] }
      └─StreamExchange { dist: Single }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
        ├── state table: 0
        ├──  Upstream
        └──  BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction, bidder, price, date_time, bid._row_id ]
    ├── primary key: [ $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 4 ]
    └── read pk prefix len hint: 1

- id: nexmark_q1
  before:
  - create_tables
  sql: |
    SELECT
      auction,
      bidder,
      0.908 * price as price,
      date_time
    FROM bid;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, $expr1, bid.date_time] }
      └─StreamExchange { dist: Single }
        └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
        └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── state table: 0
            ├──  Upstream
            └──  BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction, bidder, price, date_time, bid._row_id ]
    ├── primary key: [ $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4 ]
    ├── distribution key: [ 4 ]
    └── read pk prefix len hint: 1

- id: nexmark_q2
  before:
  - create_tables
  sql: SELECT auction, price FROM bid WHERE auction = 1007 OR auction = 1020 OR auction = 2001 OR auction = 2019 OR auction = 2087;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: (((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR (bid.auction = 2001:Int32)) OR (bid.auction = 2019:Int32)) OR (bid.auction = 2087:Int32)) }
      └─BatchScan { table: bid, columns: [bid.auction, bid.price], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, price] }
    └─StreamProject { exprs: [bid.auction, bid.price] }
      └─StreamExchange { dist: Single }
        └─StreamFilter { predicate: (((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR (bid.auction = 2001:Int32)) OR (bid.auction = 2019:Int32)) OR (bid.auction = 2087:Int32)) }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, price, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamFilter { predicate: (((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR (bid.auction = 2001:Int32)) OR (bid.auction = 2019:Int32)) OR (bid.auction = 2087:Int32)) }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, price, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamFilter { predicate: (((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR (bid.auction = 2001:Int32)) OR (bid.auction = 2019:Int32)) OR (bid.auction = 2087:Int32)) }
        └── Chain { table: bid, columns: [bid.auction, bid.price, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 0 }
            ├──  Upstream
            └──  BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, price, bid._row_id ], primary key: [ $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 2 ], read pk prefix len hint: 1 }

- id: nexmark_q3
  before:
  - create_tables
  sql: |
    SELECT
        P.name, P.city, P.state, A.id
    FROM
        auction AS A INNER JOIN person AS P on A.seller = P.id
    WHERE
        A.category = 10 and (P.state = 'or' OR P.state = 'id' OR P.state = 'ca');
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: auction.seller = person.id AND (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)), output: [person.name, person.city, person.state, auction.id] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(auction.seller) }
        └─BatchProject { exprs: [auction.id, auction.seller] }
          └─BatchFilter { predicate: (auction.category = 10:Int32) }
            └─BatchScan { table: auction, columns: [auction.id, auction.seller, auction.category], distribution: UpstreamHashShard(auction.id) }
  stream_plan: |
    StreamMaterialize { columns: [name, city, state, id, auction.seller(hidden), person.id(hidden)], stream_key: [id, person.id, auction.seller], pk_columns: [id, person.id, auction.seller], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: Inner, predicate: auction.seller = person.id, output: [person.name, person.city, person.state, auction.id, auction.seller, person.id] }
      ├─StreamExchange { dist: HashShard(auction.seller) }
      | └─StreamProject { exprs: [auction.id, auction.seller] }
      |   └─StreamFilter { predicate: (auction.category = 10:Int32) }
      |     └─StreamTableScan { table: auction, columns: [auction.id, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
      └─StreamExchange { dist: HashShard(person.id) }
        └─StreamFilter { predicate: (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)) }
          └─StreamTableScan { table: person, columns: [person.id, person.name, person.city, person.state], pk: [person.id], dist: UpstreamHashShard(person.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [name, city, state, id, auction.seller(hidden), person.id(hidden)], stream_key: [id, person.id, auction.seller], pk_columns: [id, person.id, auction.seller], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: Inner, predicate: auction.seller = person.id, output: [person.name, person.city, person.state, auction.id, auction.seller, person.id] }
        ├── left table: 0
        ├── right table: 2
        ├── left degree table: 1
        ├── right degree table: 3
        ├──  StreamExchange Hash([1]) from 1
        └──  StreamExchange Hash([0]) from 2

    Fragment 1
    StreamProject { exprs: [auction.id, auction.seller] }
    └── StreamFilter { predicate: (auction.category = 10:Int32) }
        └── Chain { table: auction, columns: [auction.id, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 4 }
            ├──  Upstream
            └──  BatchPlanNode

    Fragment 2
    StreamFilter { predicate: (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)) }
    └── Chain { table: person, columns: [person.id, person.name, person.city, person.state], pk: [person.id], dist: UpstreamHashShard(person.id) } { state table: 5 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0 { columns: [ auction_id, auction_seller ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_seller, auction_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ person_id, person_name, person_city, person_state ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ person_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ vnode, id, person_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ name, city, state, id, auction.seller, person.id ]
    ├── primary key: [ $3 ASC, $5 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5 ]
    ├── distribution key: [ 4 ]
    └── read pk prefix len hint: 3

- id: nexmark_q4
  before:
  - create_tables
  sql: |
    SELECT
        Q.category,
        AVG(Q.final) as avg
    FROM (
        SELECT MAX(B.price) AS final, A.category
        FROM auction A, bid B
        WHERE A.id = B.auction AND B.date_time BETWEEN A.date_time AND A.expires
        GROUP BY A.id, A.category
    ) Q
    GROUP BY Q.category;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
      └─BatchHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price))] }
        └─BatchExchange { order: [], dist: HashShard(auction.category) }
          └─BatchHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price)] }
            └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: [auction.id, auction.category, bid.price] }
              ├─BatchExchange { order: [], dist: HashShard(auction.id) }
              | └─BatchScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], distribution: UpstreamHashShard(auction.id) }
              └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [category, avg], stream_key: [category], pk_columns: [category], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
      └─StreamHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price)), count] }
        └─StreamExchange { dist: HashShard(auction.category) }
          └─StreamProject { exprs: [auction.id, auction.category, max(bid.price)] }
            └─StreamHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price), count] }
              └─StreamProject { exprs: [auction.id, auction.category, bid.price, bid._row_id] }
                └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                  └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                    ├─StreamExchange { dist: HashShard(auction.id) }
                    | └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
                    └─StreamExchange { dist: HashShard(bid.auction) }
                      └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [category, avg], stream_key: [category], pk_columns: [category], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
        └── StreamHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price)), count] }
            ├── result table: 0
            ├── state tables: []
            ├── distinct tables: []
            └──  StreamExchange Hash([1]) from 1

    Fragment 1
    StreamProject { exprs: [auction.id, auction.category, max(bid.price)] }
    └── StreamHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price), count] }
        ├── result table: 2
        ├── state tables: [ 1 ]
        ├── distinct tables: []
        └── StreamProject { exprs: [auction.id, auction.category, bid.price, bid._row_id] }
            └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                    ├── left table: 3
                    ├── right table: 5
                    ├── left degree table: 4
                    ├── right degree table: 6
                    ├──  StreamExchange Hash([0]) from 2
                    └──  StreamExchange Hash([0]) from 3

    Fragment 2
    Chain { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
    ├── state table: 7
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 3
    Chain { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── state table: 8
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_category, sum(max(bid_price)), count(max(bid_price)), count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ auction_id, auction_category, bid_price, bid__row_id ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 DESC, $3 ASC ]
    ├── value indices: [ 0, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

    Table 2
    ├── columns: [ auction_id, auction_category, max(bid_price), count ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

    Table 3
    ├── columns: [ auction_id, auction_date_time, auction_expires, auction_category ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 4 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5
    ├── columns: [ bid_auction, bid_price, bid_date_time, bid__row_id ]
    ├── primary key: [ $0 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 6
    ├── columns: [ bid_auction, bid__row_id, _degree ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 7
    ├── columns: [ vnode, id, auction_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 8
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ category, avg ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q5
  before:
  - create_tables
  sql: |
    SELECT AuctionBids.auction, AuctionBids.num FROM (
      SELECT
        bid.auction,
        count(*) AS num,
        window_start AS starttime
      FROM
        HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
      GROUP BY
        window_start,
        bid.auction
    ) AS AuctionBids
    JOIN (
      SELECT
        max(CountBids.num) AS maxn,
        CountBids.starttime_c
      FROM (
        SELECT
          count(*) AS num,
          window_start AS starttime_c
        FROM HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
        GROUP BY
          bid.auction,
          window_start
      ) AS CountBids
      GROUP BY
        CountBids.starttime_c
    ) AS MaxBids
    ON AuctionBids.starttime = MaxBids.starttime_c AND AuctionBids.num >= MaxBids.maxn;
  logical_plan: |
    LogicalProject { exprs: [bid.auction, count] }
    └─LogicalJoin { type: Inner, on: (window_start = window_start) AND (count >= max(count)), output: all }
      ├─LogicalProject { exprs: [bid.auction, count, window_start] }
      | └─LogicalAgg { group_key: [window_start, bid.auction], aggs: [count] }
      |   └─LogicalProject { exprs: [window_start, bid.auction] }
      |     └─LogicalHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: all }
      |       └─LogicalFilter { predicate: IsNotNull(bid.date_time) }
      |         └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
      └─LogicalProject { exprs: [max(count), window_start] }
        └─LogicalAgg { group_key: [window_start], aggs: [max(count)] }
          └─LogicalProject { exprs: [window_start, count] }
            └─LogicalProject { exprs: [count, window_start] }
              └─LogicalAgg { group_key: [bid.auction, window_start], aggs: [count] }
                └─LogicalProject { exprs: [bid.auction, window_start] }
                  └─LogicalHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: all }
                    └─LogicalFilter { predicate: IsNotNull(bid.date_time) }
                      └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: window_start = window_start AND (count >= max(count)), output: [bid.auction, count] }
      ├─BatchExchange { order: [], dist: HashShard(window_start) }
      | └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
      |   └─BatchHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start] }
      |     └─BatchExchange { order: [], dist: HashShard(bid.auction) }
      |       └─BatchFilter { predicate: IsNotNull(bid.date_time) }
      |         └─BatchScan { table: bid, columns: [bid.auction, bid.date_time], distribution: SomeShard }
      └─BatchHashAgg { group_key: [window_start], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(window_start) }
          └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
            └─BatchHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start] }
              └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                └─BatchFilter { predicate: IsNotNull(bid.date_time) }
                  └─BatchScan { table: bid, columns: [bid.auction, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start, window_start#1], pk_columns: [auction, window_start, window_start#1], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, count, window_start, window_start] }
      └─StreamFilter { predicate: (count >= max(count)) }
        └─StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all }
          ├─StreamExchange { dist: HashShard(window_start) }
          | └─StreamShare { id = 5 }
          |   └─StreamAppendOnlyHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
          |     └─StreamExchange { dist: HashShard(bid.auction, window_start) }
          |       └─StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
          |         └─StreamFilter { predicate: IsNotNull(bid.date_time) }
          |           └─StreamTableScan { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
          └─StreamProject { exprs: [window_start, max(count)] }
            └─StreamHashAgg { group_key: [window_start], aggs: [max(count), count] }
              └─StreamExchange { dist: HashShard(window_start) }
                └─StreamShare { id = 5 }
                  └─StreamAppendOnlyHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
                    └─StreamExchange { dist: HashShard(bid.auction, window_start) }
                      └─StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
                        └─StreamFilter { predicate: IsNotNull(bid.date_time) }
                          └─StreamTableScan { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start, window_start#1], pk_columns: [auction, window_start, window_start#1], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [bid.auction, count, window_start, window_start] }
        └── StreamFilter { predicate: (count >= max(count)) }
            └── StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all } { left table: 0, right table: 2, left degree table: 1, right degree table: 3 }
                ├──  StreamExchange Hash([1]) from 1
                └── StreamProject { exprs: [window_start, max(count)] }
                    └── StreamHashAgg { group_key: [window_start], aggs: [max(count), count] } { result table: 7, state tables: [ 6 ], distinct tables: [] }
                        └──  StreamExchange Hash([1]) from 4

    Fragment 1
    StreamNoOp
    └──  StreamExchange NoShuffle from 2

    Fragment 2
    StreamAppendOnlyHashAgg { group_key: [bid.auction, window_start], aggs: [count] } { result table: 4, state tables: [], distinct tables: [] }
    └──  StreamExchange Hash([0, 1]) from 3

    Fragment 3
    StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
    └── StreamFilter { predicate: IsNotNull(bid.date_time) }
        └── Chain { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 5 }
            ├──  Upstream
            └──  BatchPlanNode

    Fragment 4
    StreamNoOp
    └──  StreamExchange NoShuffle from 2

    Table 0 { columns: [ bid_auction, window_start, count ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ window_start, bid_auction, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ window_start, max(count) ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ window_start, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, window_start, count ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 5 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ window_start, count, bid_auction ], primary key: [ $0 ASC, $1 DESC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ window_start, max(count), count ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4294967294 { columns: [ auction, num, window_start, window_start#1 ], primary key: [ $0 ASC, $2 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 2 ], read pk prefix len hint: 3 }

- id: nexmark_q6
  before:
  - create_tables
  sql: |
    SELECT
        Q.seller,
        AVG(Q.final) OVER
            (PARTITION BY Q.seller ORDER BY Q.date_time ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)
        as avg
    FROM (
        SELECT MAX(B.price) AS final, A.seller, B.date_time
        FROM auction AS A, bid AS B
        WHERE A.id = B.auction and B.date_time between A.date_time and A.expires
        GROUP BY A.id, A.seller
    ) AS Q;
  planner_error: 'Invalid input syntax: column must appear in the GROUP BY clause or be used in an aggregate function'
- id: nexmark_q7
  before:
  - create_tables
  sql: |
    SELECT
      B.auction,
      B.price,
      B.bidder,
      B.date_time
    FROM
      bid B
    JOIN (
      SELECT
        MAX(price) AS maxprice,
        window_end as date_time
      FROM
        TUMBLE(bid, date_time, INTERVAL '10' SECOND)
      GROUP BY
        window_end
    ) B1 ON B.price = B1.maxprice
    WHERE
      B.date_time BETWEEN B1.date_time - INTERVAL '10' SECOND
      AND B1.date_time;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: bid.price = max(bid.price) AND (bid.date_time >= $expr2) AND (bid.date_time <= $expr1), output: [bid.auction, bid.price, bid.bidder, bid.date_time] }
      ├─BatchExchange { order: [], dist: HashShard(bid.price) }
      | └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(max(bid.price)) }
        └─BatchProject { exprs: [max(bid.price), $expr1, ($expr1 - '00:00:10':Interval) as $expr2] }
          └─BatchHashAgg { group_key: [$expr1], aggs: [max(bid.price)] }
            └─BatchExchange { order: [], dist: HashShard($expr1) }
              └─BatchProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price] }
                └─BatchScan { table: bid, columns: [bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, price, bidder, date_time, bid._row_id(hidden), $expr1(hidden)], stream_key: [bid._row_id, $expr1, price], pk_columns: [bid._row_id, $expr1, price], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, bid.price, bid.bidder, bid.date_time, bid._row_id, $expr1] }
      └─StreamFilter { predicate: (bid.date_time >= $expr2) AND (bid.date_time <= $expr1) }
        └─StreamHashJoin { type: Inner, predicate: bid.price = max(bid.price), output: all }
          ├─StreamExchange { dist: HashShard(bid.price) }
          | └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
          └─StreamExchange { dist: HashShard(max(bid.price)) }
            └─StreamProject { exprs: [$expr1, max(bid.price), ($expr1 - '00:00:10':Interval) as $expr2] }
              └─StreamAppendOnlyHashAgg { group_key: [$expr1], aggs: [max(bid.price), count] }
                └─StreamExchange { dist: HashShard($expr1) }
                  └─StreamProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price, bid._row_id] }
                    └─StreamTableScan { table: bid, columns: [bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, price, bidder, date_time, bid._row_id(hidden), $expr1(hidden)], stream_key: [bid._row_id, $expr1, price], pk_columns: [bid._row_id, $expr1, price], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [bid.auction, bid.price, bid.bidder, bid.date_time, bid._row_id, $expr1] }
        └── StreamFilter { predicate: (bid.date_time >= $expr2) AND (bid.date_time <= $expr1) }
            └── StreamHashJoin { type: Inner, predicate: bid.price = max(bid.price), output: all } { left table: 0, right table: 2, left degree table: 1, right degree table: 3 }
                ├──  StreamExchange Hash([2]) from 1
                └──  StreamExchange Hash([1]) from 2

    Fragment 1
    Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 4 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    StreamProject { exprs: [$expr1, max(bid.price), ($expr1 - '00:00:10':Interval) as $expr2] }
    └── StreamAppendOnlyHashAgg { group_key: [$expr1], aggs: [max(bid.price), count] } { result table: 5, state tables: [], distinct tables: [] }
        └──  StreamExchange Hash([0]) from 3

    Fragment 3
    StreamProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price, bid._row_id] }
    └── Chain { table: bid, columns: [bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 6 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0 { columns: [ bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id ], primary key: [ $2 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 2 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ bid_price, bid__row_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ $expr1, max(bid_price), $expr2 ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ max(bid_price), $expr1, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ $expr1, max(bid_price), count ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, price, bidder, date_time, bid._row_id, $expr1 ]
    ├── primary key: [ $4 ASC, $5 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5 ]
    ├── distribution key: [ 1 ]
    └── read pk prefix len hint: 3

- id: nexmark_q8
  before:
  - create_tables
  sql: |
    SELECT
      P.id,
      P.name,
      P.starttime
    FROM (
      SELECT
        id,
        name,
        window_start AS starttime,
        window_end AS endtime
      FROM
        TUMBLE(person, date_time, INTERVAL '10' SECOND)
      GROUP BY
        id,
        name,
        window_start,
        window_end
    ) P
    JOIN (
      SELECT
        seller,
        window_start AS starttime,
        window_end AS endtime
      FROM
        TUMBLE(auction, date_time, INTERVAL '10' SECOND)
      GROUP BY
        seller,
        window_start,
        window_end
    ) A ON P.id = A.seller
      AND P.starttime = A.starttime
      AND P.endtime = A.endtime;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: [person.id, person.name, $expr1] }
      ├─BatchExchange { order: [], dist: HashShard(person.id, $expr1, $expr2) }
      | └─BatchHashAgg { group_key: [person.id, person.name, $expr1, $expr2], aggs: [] }
      |   └─BatchProject { exprs: [person.id, person.name, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1, (TumbleStart(person.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr2] }
      |     └─BatchScan { table: person, columns: [person.id, person.name, person.date_time], distribution: UpstreamHashShard(person.id) }
      └─BatchHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [] }
        └─BatchExchange { order: [], dist: HashShard(auction.seller, $expr3, $expr4) }
          └─BatchProject { exprs: [auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3, (TumbleStart(auction.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr4] }
            └─BatchScan { table: auction, columns: [auction.date_time, auction.seller], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [id, name, starttime, $expr2(hidden), auction.seller(hidden), $expr3(hidden), $expr4(hidden)], stream_key: [id, name, starttime, $expr2, auction.seller, $expr3, $expr4], pk_columns: [id, name, starttime, $expr2, auction.seller, $expr3, $expr4], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: all }
      ├─StreamExchange { dist: HashShard(person.id, $expr1, $expr2) }
      | └─StreamProject { exprs: [person.id, person.name, $expr1, $expr2] }
      |   └─StreamHashAgg { group_key: [person.id, person.name, $expr1, $expr2], aggs: [count] }
      |     └─StreamProject { exprs: [person.id, person.name, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1, (TumbleStart(person.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr2] }
      |       └─StreamTableScan { table: person, columns: [person.id, person.name, person.date_time], pk: [person.id], dist: UpstreamHashShard(person.id) }
      └─StreamProject { exprs: [auction.seller, $expr3, $expr4] }
        └─StreamHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [count] }
          └─StreamExchange { dist: HashShard(auction.seller, $expr3, $expr4) }
            └─StreamProject { exprs: [auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3, (TumbleStart(auction.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr4, auction.id] }
              └─StreamTableScan { table: auction, columns: [auction.date_time, auction.seller, auction.id], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [id, name, starttime, $expr2(hidden), auction.seller(hidden), $expr3(hidden), $expr4(hidden)], stream_key: [id, name, starttime, $expr2, auction.seller, $expr3, $expr4], pk_columns: [id, name, starttime, $expr2, auction.seller, $expr3, $expr4], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: all } { left table: 0, right table: 2, left degree table: 1, right degree table: 3 }
        ├──  StreamExchange Hash([0, 2, 3]) from 1
        └── StreamProject { exprs: [auction.seller, $expr3, $expr4] }
            └── StreamHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [count] } { result table: 6, state tables: [], distinct tables: [] }
                └──  StreamExchange Hash([0, 1, 2]) from 2

    Fragment 1
    StreamProject { exprs: [person.id, person.name, $expr1, $expr2] }
    └── StreamHashAgg { group_key: [person.id, person.name, $expr1, $expr2], aggs: [count] } { result table: 4, state tables: [], distinct tables: [] }
        └── StreamProject { exprs: [person.id, person.name, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1, (TumbleStart(person.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr2] }
            └── Chain { table: person, columns: [person.id, person.name, person.date_time], pk: [person.id], dist: UpstreamHashShard(person.id) } { state table: 5 }
                ├──  Upstream
                └──  BatchPlanNode

    Fragment 2
    StreamProject { exprs: [auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3, (TumbleStart(auction.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr4, auction.id] }
    └── Chain { table: auction, columns: [auction.date_time, auction.seller, auction.id], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 7 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0 { columns: [ person_id, person_name, $expr1, $expr2 ], primary key: [ $0 ASC, $2 ASC, $3 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0, 2, 3 ], read pk prefix len hint: 3 }

    Table 1 { columns: [ person_id, $expr1, $expr2, person_name, _degree ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC ], value indices: [ 4 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 2 { columns: [ auction_seller, $expr3, $expr4 ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 3 { columns: [ auction_seller, $expr3, $expr4, _degree ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 4 { columns: [ person_id, person_name, $expr1, $expr2, count ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC ], value indices: [ 4 ], distribution key: [ 0 ], read pk prefix len hint: 4 }

    Table 5 { columns: [ vnode, id, person_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ auction_seller, $expr3, $expr4, count ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 7 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ id, name, starttime, $expr2, auction.seller, $expr3, $expr4 ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC, $4 ASC, $5 ASC, $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 0, 2, 3 ], read pk prefix len hint: 7 }

- id: nexmark_q9
  before:
  - create_tables
  sql: |
    SELECT
      id, item_name, description, initial_bid, reserve, date_time, expires, seller, category,
      auction, bidder, price, bid_date_time
    FROM (
      SELECT A.*, B.auction, B.bidder, B.price, B.date_time AS bid_date_time,
        ROW_NUMBER() OVER (PARTITION BY A.id ORDER BY B.price DESC, B.date_time ASC) AS rownum
      FROM auction A, bid B
      WHERE A.id = B.auction AND B.date_time BETWEEN A.date_time AND A.expires
    )
    WHERE rownum <= 1;
  logical_plan: |
    LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid.auction, bid.bidder, bid.price, bid.date_time] }
    └─LogicalFilter { predicate: (row_number <= 1:Int32) }
      └─LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid.auction, bid.bidder, bid.price, bid.date_time, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY auction.id ORDER BY bid.price DESC, bid.date_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
          └─LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
            └─LogicalFilter { predicate: (auction.id = bid.auction) AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
              └─LogicalJoin { type: Inner, on: true, output: all }
                ├─LogicalScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category] }
                └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
  optimized_logical_plan_for_batch: |
    LogicalTopN { order: "[bid.price DESC, bid.date_time ASC]", limit: 1, offset: 0, group_key: [0] }
    └─LogicalJoin { type: Inner, on: (auction.id = bid.auction) AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: all }
      ├─LogicalScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category] }
      └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: "[bid.price DESC, bid.date_time ASC]", limit: 1, offset: 0, group_key: [0] }
      └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: all }
        ├─BatchExchange { order: [], dist: HashShard(auction.id) }
        | └─BatchScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], distribution: UpstreamHashShard(auction.id) }
        └─BatchExchange { order: [], dist: HashShard(bid.auction) }
          └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id(hidden)], stream_key: [id], pk_columns: [id], pk_conflict: "NoCheck" }
    └─StreamGroupTopN { order: "[bid.price DESC, bid.date_time ASC]", limit: 1, offset: 0, group_key: [0] }
      └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
        └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
          ├─StreamExchange { dist: HashShard(auction.id) }
          | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
          └─StreamExchange { dist: HashShard(bid.auction) }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id(hidden)], stream_key: [id], pk_columns: [id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamGroupTopN { order: "[bid.price DESC, bid.date_time ASC]", limit: 1, offset: 0, group_key: [0] } { state table: 0 }
        └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
            └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { left table: 1, right table: 3, left degree table: 2, right degree table: 4 }
                ├──  StreamExchange Hash([0]) from 1
                └──  StreamExchange Hash([0]) from 2

    Fragment 1
    Chain { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
    ├── state table: 5
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 6 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category, bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id ]
    ├── primary key: [ $0 ASC, $11 DESC, $12 ASC, $13 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id ], primary key: [ $0 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, bid__row_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q10
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, date_time, TO_CHAR(date_time, 'YYYY-MM-DD') as date, TO_CHAR(date_time, 'HH:MI') as time FROM bid;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time, date, time] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, $expr1, $expr2] }
      └─StreamExchange { dist: Single }
        └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, date_time, date, time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, date, time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
        └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 0 }
            ├──  Upstream
            └──  BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, date_time, date, time, bid._row_id ]
    ├── primary key: [ $6 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6 ]
    ├── distribution key: [ 6 ]
    └── read pk prefix len hint: 1

- id: nexmark_q11
  before:
  - create_tables
  sql: |
    SELECT
      B.bidder,
      count(*) as bid_count,
      SESSION_START(B.date_time, INTERVAL '10' SECOND) as starttime,
      SESSION_END(B.date_time, INTERVAL '10' SECOND) as endtime
    FROM bid B
    GROUP BY B.bidder, SESSION(B.date_time, INTERVAL '10' SECOND);
  binder_error: |-
    Bind error: failed to bind expression: SESSION_START(B.date_time, INTERVAL '10' SECOND)

    Caused by:
      Feature is not yet implemented: unsupported function: "session_start"
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/112
- id: nexmark_q12
  before:
  - create_tables
  sql: |
    SELECT
        B.bidder,
        count(*) as bid_count,
        TUMBLE_START(B.p_time, INTERVAL '10' SECOND) as starttime,
        TUMBLE_END(B.p_time, INTERVAL '10' SECOND) as endtime
    FROM (SELECT *, PROCTIME() as p_time FROM bid) B
    GROUP BY B.bidder, TUMBLE(B.p_time, INTERVAL '10' SECOND);
  binder_error: |-
    Bind error: failed to bind expression: PROCTIME()

    Caused by:
      Invalid input syntax: Function `PROCTIME()` is only allowed in CREATE TABLE/SOURCE. Is `NOW()` what you want?
- id: nexmark_q13
  before:
  - create_tables
  sql: |
    /* SELECT
        B.auction,
        B.bidder,
        B.price,
        B.date_time,
        S.value
    FROM (SELECT *, PROCTIME() as p_time FROM bid) B
    JOIN side_input FOR SYSTEM_TIME AS OF B.p_time AS S
    ON mod(B.auction, 10000) = S.key; */
    select 1;
  stream_error: 'Bind error: An alias must be specified for the 1st expression (counting from 1) in result relation'
- id: nexmark_q14
  before:
  - create_tables
  sql: |
    SELECT
      auction,
      bidder,
      0.908 * price as price,
      CASE
        WHEN
          extract(hour from date_time) >= 8 AND
          extract(hour from date_time) <= 18
        THEN 'dayTime'
        WHEN
          extract(hour from date_time) <= 6 OR
          extract(hour from date_time) >= 20
        THEN 'nightTime'
        ELSE 'otherTime'
      END AS bidTimeType,
      date_time,
      extra
      -- TODO: count_char is an UDF, add it back when we support similar functionality.
      -- https://github.com/nexmark/nexmark/blob/master/nexmark-flink/src/main/java/com/github/nexmark/flink/udf/CountChar.java
      -- count_char(extra, 'c') AS c_counts
    FROM bid
    WHERE 0.908 * price > 1000000 AND 0.908 * price < 50000000;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra] }
      └─BatchFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, bidder, price, bidtimetype, date_time, extra] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, $expr1, $expr2, bid.date_time, bid.extra] }
      └─StreamExchange { dist: Single }
        └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
          └─StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, bidtimetype, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
      └─StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, bidtimetype, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
        └── StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
            └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 0 }
                ├──  Upstream
                └──  BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, bidtimetype, date_time, extra, bid._row_id ], primary key: [ $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 6 ], read pk prefix len hint: 1 }

- id: nexmark_q15
  before:
  - create_tables
  sql: |
    SELECT
        TO_CHAR(date_time, 'yyyy-MM-dd') as day,
        count(*) AS total_bids,
        count(*) filter (where price < 10000) AS rank1_bids,
        count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
        count(*) filter (where price >= 1000000) AS rank3_bids,
        count(distinct bidder) AS total_bidders,
        count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
        count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
        count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
        count(distinct auction) AS total_auctions,
        count(distinct auction) filter (where price < 10000) AS rank1_auctions,
        count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
        count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY to_char(date_time, 'yyyy-MM-dd');
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [$expr1], aggs: [sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder) filter((flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction) filter((flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─BatchExchange { order: [], dist: HashShard($expr1) }
        └─BatchHashAgg { group_key: [$expr1, bid.bidder, bid.auction, flag], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
          └─BatchExchange { order: [], dist: HashShard($expr1, bid.bidder, bid.auction, flag) }
            └─BatchExpand { column_subsets: [[$expr1], [$expr1, bid.bidder], [$expr1, bid.auction]] }
              └─BatchProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction] }
                └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: "NoCheck" }
    └─StreamAppendOnlyHashAgg { group_key: [$expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
      └─StreamExchange { dist: HashShard($expr1) }
        └─StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamAppendOnlyHashAgg { group_key: [$expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
        ├── result table: 0
        ├── state tables: []
        ├── distinct tables: [ (distinct key: bid.bidder, table id: 1), (distinct key: bid.auction, table id: 2) ]
        └──  StreamExchange Hash([0]) from 1

    Fragment 1
    StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
    └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 3 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0
    ├── columns: [ $expr1, count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), count(distinct bid_bidder), count(distinct bid_bidder) filter((bid_price < 10000:Int32)), count(distinct bid_bidder) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_bidder) filter((bid_price >= 1000000:Int32)), count(distinct bid_auction), count(distinct bid_auction) filter((bid_price < 10000:Int32)), count(distinct bid_auction) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_auction) filter((bid_price >= 1000000:Int32)) ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ $expr1, bid_bidder, count_for_agg_call_4, count_for_agg_call_5, count_for_agg_call_6, count_for_agg_call_7 ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ $expr1, bid_auction, count_for_agg_call_8, count_for_agg_call_9, count_for_agg_call_10, count_for_agg_call_11 ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 3 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q16
  before:
  - create_tables
  sql: |
    SELECT
      channel,
      to_char(date_time, 'yyyy-MM-dd') AS day,
      max(to_char(date_time, 'HH:mm')) AS minute,
      count(*) AS total_bids,
      count(*) filter (where price < 10000) AS rank1_bids,
      count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
      count(*) filter (where price >= 1000000) AS rank3_bids,
      count(distinct bidder) AS total_bidders,
      count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
      count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
      count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
      count(distinct auction) AS total_auctions,
      count(distinct auction) filter (where price < 10000) AS rank1_auctions,
      count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
      count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY channel, to_char(date_time, 'yyyy-MM-dd');
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [bid.channel, $expr1], aggs: [max(max($expr2)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder) filter((flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction) filter((flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─BatchExchange { order: [], dist: HashShard(bid.channel, $expr1) }
        └─BatchHashAgg { group_key: [bid.channel, $expr1, bid.bidder, bid.auction, flag], aggs: [max($expr2), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
          └─BatchExchange { order: [], dist: HashShard(bid.channel, $expr1, bid.bidder, bid.auction, flag) }
            └─BatchExpand { column_subsets: [[bid.channel, $expr1, $expr2], [bid.channel, $expr1, bid.bidder], [bid.channel, $expr1, bid.auction]] }
              └─BatchProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction] }
                └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: "NoCheck" }
    └─StreamAppendOnlyHashAgg { group_key: [bid.channel, $expr1], aggs: [max($expr2), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
      └─StreamExchange { dist: HashShard(bid.channel, $expr1) }
        └─StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamAppendOnlyHashAgg { group_key: [bid.channel, $expr1], aggs: [max($expr2), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
        ├── result table: 0
        ├── state tables: []
        ├── distinct tables: [ (distinct key: bid.bidder, table id: 1), (distinct key: bid.auction, table id: 2) ]
        └──  StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
    └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 3 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0
    ├── columns: [ bid_channel, $expr1, max($expr2), count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), count(distinct bid_bidder), count(distinct bid_bidder) filter((bid_price < 10000:Int32)), count(distinct bid_bidder) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_bidder) filter((bid_price >= 1000000:Int32)), count(distinct bid_auction), count(distinct bid_auction) filter((bid_price < 10000:Int32)), count(distinct bid_auction) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_auction) filter((bid_price >= 1000000:Int32)) ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ bid_channel, $expr1, bid_bidder, count_for_agg_call_5, count_for_agg_call_6, count_for_agg_call_7, count_for_agg_call_8 ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3, 4, 5, 6 ], distribution key: [ 0, 1 ], read pk prefix len hint: 3 }

    Table 2 { columns: [ bid_channel, $expr1, bid_auction, count_for_agg_call_9, count_for_agg_call_10, count_for_agg_call_11, count_for_agg_call_12 ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3, 4, 5, 6 ], distribution key: [ 0, 1 ], read pk prefix len hint: 3 }

    Table 3 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

- id: nexmark_q17
  before:
  - create_tables
  sql: |
    SELECT
        auction,
        to_char(date_time, 'YYYY-MM-DD') AS day,
        count(*) AS total_bids,
        count(*) filter (where price < 10000) AS rank1_bids,
        count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
        count(*) filter (where price >= 1000000) AS rank3_bids,
        min(price) AS min_price,
        max(price) AS max_price,
        avg(price) AS avg_price,
        sum(price) AS sum_price
    FROM bid
    GROUP BY auction, to_char(date_time, 'YYYY-MM-DD');
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
      └─BatchHashAgg { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
        └─BatchExchange { order: [], dist: HashShard(bid.auction, $expr1) }
          └─BatchProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price] }
            └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price], stream_key: [auction, day], pk_columns: [auction, day], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
      └─StreamAppendOnlyHashAgg { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
        └─StreamExchange { dist: HashShard(bid.auction, $expr1) }
          └─StreamProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price, bid._row_id] }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price], stream_key: [auction, day], pk_columns: [auction, day], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
        └── StreamAppendOnlyHashAgg { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
            ├── result table: 0
            ├── state tables: []
            ├── distinct tables: []
            └──  StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price, bid._row_id] }
    └── Chain { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 1 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, $expr1, count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), min(bid_price), max(bid_price), sum(bid_price), count(bid_price) ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3, 4, 5, 6, 7, 8, 9 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

- id: nexmark_q18
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, channel, url, date_time, extra
    FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY bidder, auction ORDER BY date_time DESC) AS rank_number
          FROM bid)
    WHERE rank_number <= 1;
  logical_plan: |
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra] }
    └─LogicalFilter { predicate: (row_number <= 1:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.bidder, bid.auction ORDER BY bid.date_time DESC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, group_key: [1, 0] }
      └─BatchExchange { order: [], dist: HashShard(bid.bidder, bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction], pk_columns: [bidder, auction], pk_conflict: "NoCheck" }
    └─StreamAppendOnlyGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, group_key: [1, 0] }
      └─StreamExchange { dist: HashShard(bid.bidder, bid.auction) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction], pk_columns: [bidder, auction], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamAppendOnlyGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, group_key: [1, 0] } { state table: 0 }
        └──  StreamExchange Hash([1, 0]) from 1

    Fragment 1
    Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── state table: 1
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid__row_id ]
    ├── primary key: [ $1 ASC, $0 ASC, $5 DESC, $7 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 1, 0 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, channel, url, date_time, extra, bid._row_id ]
    ├── primary key: [ $1 ASC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 1, 0 ]
    └── read pk prefix len hint: 2

- id: nexmark_q18_rank
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, channel, url, date_time, extra
    FROM (SELECT *, RANK() OVER (PARTITION BY bidder, auction ORDER BY date_time DESC) AS rank_number
          FROM bid)
    WHERE rank_number <= 1;
  logical_plan: |
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra] }
    └─LogicalFilter { predicate: (rank <= 1:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, rank] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY bid.bidder, bid.auction ORDER BY bid.date_time DESC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, with_ties: true, group_key: [1, 0] }
      └─BatchExchange { order: [], dist: HashShard(bid.bidder, bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamExchange { dist: HashShard(bid._row_id) }
      └─StreamAppendOnlyGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, group_key: [1, 0], with_ties: true }
        └─StreamExchange { dist: HashShard(bid.bidder, bid.auction) }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └──  StreamExchange Hash([7]) from 1

    Fragment 1
    StreamAppendOnlyGroupTopN { order: "[bid.date_time DESC]", limit: 1, offset: 0, group_key: [1, 0], with_ties: true } { state table: 0 }
    └──  StreamExchange Hash([1, 0]) from 2

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── state table: 1
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid__row_id ]
    ├── primary key: [ $1 ASC, $0 ASC, $5 DESC, $7 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 1, 0 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, channel, url, date_time, extra, bid._row_id ]
    ├── primary key: [ $7 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 7 ]
    └── read pk prefix len hint: 1

- id: nexmark_q19
  before:
  - create_tables
  sql: |
    SELECT * FROM
    (SELECT *, ROW_NUMBER() OVER (PARTITION BY auction ORDER BY price DESC) AS rank_number FROM bid)
    WHERE rank_number <= 10;
  logical_plan: |
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, row_number] }
    └─LogicalFilter { predicate: (row_number <= 10:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id] }
- id: nexmark_q20
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel, url, B.date_time as date_timeB,
        item_name, description, initial_bid, reserve, A.date_time as date_timeA, expires, seller, category
    FROM
        bid B INNER JOIN auction A on B.auction = A.id
    WHERE A.category = 10;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: bid.auction = auction.id AND (auction.category = 10:Int32), output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category] }
      └─BatchExchange { order: [], dist: UpstreamHashShard(bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id(hidden), auction.id(hidden)], stream_key: [bid._row_id, auction.id, auction], pk_columns: [bid._row_id, auction.id, auction], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: Inner, predicate: bid.auction = auction.id, output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid._row_id, auction.id] }
      ├─StreamExchange { dist: HashShard(bid.auction) }
      | └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
      └─StreamExchange { dist: HashShard(auction.id) }
        └─StreamFilter { predicate: (auction.category = 10:Int32) }
          └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id(hidden), auction.id(hidden)], stream_key: [bid._row_id, auction.id, auction], pk_columns: [bid._row_id, auction.id, auction], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: Inner, predicate: bid.auction = auction.id, output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid._row_id, auction.id] }
        ├── left table: 0
        ├── right table: 2
        ├── left degree table: 1
        ├── right degree table: 3
        ├──  StreamExchange Hash([0]) from 1
        └──  StreamExchange Hash([0]) from 2

    Fragment 1
    Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 4 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    StreamFilter { predicate: (auction.category = 10:Int32) }
    └── Chain { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 5 }
        ├──  Upstream
        └──  BatchPlanNode

    Table 0 { columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid__row_id ], primary key: [ $0 ASC, $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ bid_auction, bid__row_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id, auction.id ]
    ├── primary key: [ $14 ASC, $15 ASC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 3

- id: nexmark_q21
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel,
        CASE
            WHEN lower(channel) = 'apple' THEN '0'
            WHEN lower(channel) = 'google' THEN '1'
            WHEN lower(channel) = 'facebook' THEN '2'
            WHEN lower(channel) = 'baidu' THEN '3'
            ELSE REGEXP_EXTRACT(url, '(&|^)channel_id=([^&]*)', 2)
            END
        AS channel_id FROM bid
        where REGEXP_EXTRACT(url, '(&|^)channel_id=([^&]*)', 2) is not null or
              lower(channel) in ('apple', 'google', 'facebook', 'baidu');
  binder_error: |-
    Bind error: failed to bind expression: CASE WHEN lower(channel) = 'apple' THEN '0' WHEN lower(channel) = 'google' THEN '1' WHEN lower(channel) = 'facebook' THEN '2' WHEN lower(channel) = 'baidu' THEN '3' ELSE REGEXP_EXTRACT(url, '(&|^)channel_id=([^&]*)', 2) END

    Caused by:
      Feature is not yet implemented: unsupported function: "regexp_extract"
    Tracking issue: https://github.com/risingwavelabs/risingwave/issues/112
- id: nexmark_q22
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel,
        SPLIT_PART(url, '/', 4) as dir1,
        SPLIT_PART(url, '/', 5) as dir2,
        SPLIT_PART(url, '/', 6) as dir3 FROM bid;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url], distribution: SomeShard }
  sink_plan: |
    StreamSink { type: append-only, columns: [auction, bidder, price, channel, dir1, dir2, dir3] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, $expr1, $expr2, $expr3] }
      └─StreamExchange { dist: Single }
        └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |
    StreamMaterialize { columns: [auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: "NoCheck" } { materialized table: 4294967294 }
    └── StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
        └── Chain { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 0 }
            ├──  Upstream
            └──  BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id ], primary key: [ $7 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ], distribution key: [ 7 ], read pk prefix len hint: 1 }

- id: nexmark_q101
  before:
  - create_tables
  sql: |
    -- A self-made query that covers outer join.
    --
    -- Monitor ongoing auctions and track the current highest bid for each one in real-time. If
    -- the auction has no bids, the highest bid will be NULL.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        b.max_price AS current_highest_bid
    FROM auction a
    LEFT OUTER JOIN (
        SELECT
            b1.auction,
            MAX(b1.price) max_price
        FROM bid b1
        GROUP BY b1.auction
    ) b ON a.id = b.auction;
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price)] }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      | └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchHashAgg { group_key: [bid.auction], aggs: [max(bid.price)] }
        └─BatchExchange { order: [], dist: HashShard(bid.auction) }
          └─BatchScan { table: bid, columns: [bid.auction, bid.price], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction_id, auction_item_name, current_highest_bid, bid.auction(hidden)], stream_key: [auction_id, bid.auction], pk_columns: [auction_id, bid.auction], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price), bid.auction] }
      ├─StreamExchange { dist: HashShard(auction.id) }
      | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
      └─StreamProject { exprs: [bid.auction, max(bid.price)] }
        └─StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [max(bid.price), count] }
          └─StreamExchange { dist: HashShard(bid.auction) }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, current_highest_bid, bid.auction(hidden)], stream_key: [auction_id, bid.auction], pk_columns: [auction_id, bid.auction], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price), bid.auction] }
        ├── left table: 0
        ├── right table: 2
        ├── left degree table: 1
        ├── right degree table: 3
        ├──  StreamExchange Hash([0]) from 1
        └── StreamProject { exprs: [bid.auction, max(bid.price)] }
            └── StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [max(bid.price), count] } { result table: 5, state tables: [], distinct tables: [] }
                └──  StreamExchange Hash([0]) from 2

    Fragment 1
    Chain { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 4 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid.price, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 6 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0 { columns: [ auction_id, auction_item_name ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ bid_auction, max(bid_price) ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ bid_auction, max(bid_price), count ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name, current_highest_bid, bid.auction ]
    ├── primary key: [ $0 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

- id: nexmark_q102
  before:
  - create_tables
  sql: |
    -- A self-made query that covers dynamic filter.
    --
    -- Show the auctions whose count of bids is greater than the overall average count of bids
    -- per auction.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        COUNT(b.auction) AS bid_count
    FROM auction a
    JOIN bid b ON a.id = b.auction
    GROUP BY a.id, a.item_name
    HAVING COUNT(b.auction) >= (
        SELECT COUNT(*) / COUNT(DISTINCT auction) FROM bid
    )
  batch_plan: |
    BatchNestedLoopJoin { type: Inner, predicate: (count(bid.auction) >= $expr1), output: [auction.id, auction.item_name, count(bid.auction)] }
    ├─BatchExchange { order: [], dist: Single }
    | └─BatchHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction)] }
    |   └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
    |     ├─BatchExchange { order: [], dist: HashShard(auction.id) }
    |     | └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
    |     └─BatchExchange { order: [], dist: HashShard(bid.auction) }
    |       └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
    └─BatchProject { exprs: [(sum0(count) / count(bid.auction)) as $expr1] }
      └─BatchSimpleAgg { aggs: [sum0(count), count(bid.auction)] }
        └─BatchExchange { order: [], dist: Single }
          └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id, auction_item_name], pk_columns: [auction_id, auction_item_name], pk_conflict: "NoCheck" }
    └─StreamDynamicFilter { predicate: (count(bid.auction) >= $expr1), output: [auction.id, auction.item_name, count(bid.auction)] }
      ├─StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction)] }
      | └─StreamHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction), count] }
      |   └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
      |     ├─StreamExchange { dist: HashShard(auction.id) }
      |     | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
      |     └─StreamExchange { dist: HashShard(bid.auction) }
      |       └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
      └─StreamExchange { dist: Broadcast }
        └─StreamProject { exprs: [(sum0(count) / count(bid.auction)) as $expr1] }
          └─StreamSimpleAgg { aggs: [sum0(count), count(bid.auction), count] }
            └─StreamExchange { dist: Single }
              └─StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] }
                └─StreamExchange { dist: HashShard(bid.auction) }
                  └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id, auction_item_name], pk_columns: [auction_id, auction_item_name], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamDynamicFilter { predicate: (count(bid.auction) >= $expr1), output: [auction.id, auction.item_name, count(bid.auction)] } { left table: 0, right table: 1 }
        ├── StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction)] }
        │   └── StreamHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction), count] } { result table: 2, state tables: [], distinct tables: [] }
        │       └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { left table: 3, right table: 5, left degree table: 4, right degree table: 6 }
        │           ├──  StreamExchange Hash([0]) from 1
        │           └──  StreamExchange Hash([0]) from 2
        └──  StreamExchange Broadcast from 3

    Fragment 1
    Chain { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 7 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 8 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 3
    StreamProject { exprs: [(sum0(count) / count(bid.auction)) as $expr1] }
    └── StreamSimpleAgg { aggs: [sum0(count), count(bid.auction), count] } { result table: 9, state tables: [], distinct tables: [] }
        └──  StreamExchange Single from 4

    Fragment 4
    StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] } { result table: 10, state tables: [], distinct tables: [] }
    └──  StreamExchange Hash([0]) from 5

    Fragment 5
    Chain { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 11 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name, count(bid_auction) ]
    ├── primary key: [ $2 ASC, $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ $expr1 ], primary key: [], value indices: [ 0 ], distribution key: [], read pk prefix len hint: 0 }

    Table 2
    ├── columns: [ auction_id, auction_item_name, count(bid_auction), count ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

    Table 3 { columns: [ auction_id, auction_item_name ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ bid_auction, bid__row_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 8 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 9 { columns: [ sum0(count), count(bid_auction), count ], primary key: [], value indices: [ 0, 1, 2 ], distribution key: [], read pk prefix len hint: 0 }

    Table 10 { columns: [ bid_auction, count ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 11 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name, bid_count ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

- id: nexmark_q103
  before:
  - create_tables
  sql: |
    -- A self-made query that covers semi join.
    --
    -- Show the auctions that have at least 20 bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name
    FROM auction a
    WHERE a.id IN (
        SELECT b.auction FROM bid b
        GROUP BY b.auction
        HAVING COUNT(*) >= 20
    );
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      | └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchProject { exprs: [bid.auction] }
        └─BatchFilter { predicate: (count >= 20:Int32) }
          └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
      ├─StreamExchange { dist: HashShard(auction.id) }
      | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
      └─StreamProject { exprs: [bid.auction] }
        └─StreamFilter { predicate: (count >= 20:Int32) }
          └─StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] }
            └─StreamExchange { dist: HashShard(bid.auction) }
              └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
        ├── left table: 0
        ├── right table: 2
        ├── left degree table: 1
        ├── right degree table: 3
        ├──  StreamExchange Hash([0]) from 1
        └── StreamProject { exprs: [bid.auction] }
            └── StreamFilter { predicate: (count >= 20:Int32) }
                └── StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] }
                    ├── result table: 5
                    ├── state tables: []
                    ├── distinct tables: []
                    └──  StreamExchange Hash([0]) from 2

    Fragment 1
    Chain { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
    ├── state table: 4
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 6 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ auction_id, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2 { columns: [ bid_auction ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3
    ├── columns: [ bid_auction, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 4
    ├── columns: [ vnode, id, auction_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 5
    ├── columns: [ bid_auction, count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 6
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q104
  before:
  - create_tables
  sql: |
    -- A self-made query that covers anti join.
    --
    -- This is the same as q103, which shows the auctions that have at least 20 bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name
    FROM auction a
    WHERE a.id NOT IN (
        SELECT b.auction FROM bid b
        GROUP BY b.auction
        HAVING COUNT(*) < 20
    );
  batch_plan: |
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      | └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchProject { exprs: [bid.auction] }
        └─BatchFilter { predicate: (count < 20:Int32) }
          └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: "NoCheck" }
    └─StreamHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
      ├─StreamExchange { dist: HashShard(auction.id) }
      | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
      └─StreamProject { exprs: [bid.auction] }
        └─StreamFilter { predicate: (count < 20:Int32) }
          └─StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] }
            └─StreamExchange { dist: HashShard(bid.auction) }
              └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
        ├── left table: 0
        ├── right table: 2
        ├── left degree table: 1
        ├── right degree table: 3
        ├──  StreamExchange Hash([0]) from 1
        └── StreamProject { exprs: [bid.auction] }
            └── StreamFilter { predicate: (count < 20:Int32) }
                └── StreamAppendOnlyHashAgg { group_key: [bid.auction], aggs: [count] }
                    ├── result table: 5
                    ├── state tables: []
                    ├── distinct tables: []
                    └──  StreamExchange Hash([0]) from 2

    Fragment 1
    Chain { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
    ├── state table: 4
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 2
    Chain { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 6 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ auction_id, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2 { columns: [ bid_auction ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3
    ├── columns: [ bid_auction, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 4
    ├── columns: [ vnode, id, auction_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 5
    ├── columns: [ bid_auction, count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 6
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q105
  before:
  - create_tables
  sql: |
    -- A self-made query that covers singleton top-n (and local-phase group top-n).
    --
    -- Show the top 1000 auctions by the number of bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        COUNT(b.auction) AS bid_count
    FROM auction a
    JOIN bid b ON a.id = b.auction
    GROUP BY a.id, a.item_name
    ORDER BY bid_count DESC
    LIMIT 1000;
  batch_plan: |
    BatchTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0 }
        └─BatchHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction)] }
          └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
            ├─BatchExchange { order: [], dist: HashShard(auction.id) }
            | └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id, auction_item_name], pk_columns: [bid_count, auction_id, auction_item_name], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction)] }
      └─StreamTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0 }
        └─StreamExchange { dist: Single }
          └─StreamGroupTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0, group_key: [3] }
            └─StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction), Vnode(auction.id) as $expr1] }
              └─StreamHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction), count] }
                └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                  ├─StreamExchange { dist: HashShard(auction.id) }
                  | └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
                  └─StreamExchange { dist: HashShard(bid.auction) }
                    └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id, auction_item_name], pk_columns: [bid_count, auction_id, auction_item_name], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction)] }
        └── StreamTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0 } { state table: 0 }
            └──  StreamExchange Single from 1

    Fragment 1
    StreamGroupTopN { order: "[count(bid.auction) DESC]", limit: 1000, offset: 0, group_key: [3] } { state table: 1 }
    └── StreamProject { exprs: [auction.id, auction.item_name, count(bid.auction), Vnode(auction.id) as $expr1] }
        └── StreamHashAgg { group_key: [auction.id, auction.item_name], aggs: [count(bid.auction), count] } { result table: 2, state tables: [], distinct tables: [] }
            └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { left table: 3, right table: 5, left degree table: 4, right degree table: 6 }
                ├──  StreamExchange Hash([0]) from 2
                └──  StreamExchange Hash([0]) from 3

    Fragment 2
    Chain { table: auction, columns: [auction.id, auction.item_name], pk: [auction.id], dist: UpstreamHashShard(auction.id) } { state table: 7 }
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 3
    Chain { table: bid, columns: [bid.auction, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) } { state table: 8 }
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name, count(bid_auction), $expr1 ]
    ├── primary key: [ $2 DESC, $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

    Table 1
    ├── columns: [ auction_id, auction_item_name, count(bid_auction), $expr1 ]
    ├── primary key: [ $3 ASC, $2 DESC, $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 3

    Table 2 { columns: [ auction_id, auction_item_name, count(bid_auction), count ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 3 { columns: [ auction_id, auction_item_name ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ auction_id, _degree ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ bid_auction, bid__row_id, _degree ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ vnode, id, auction_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 8 { columns: [ vnode, _row_id, bid_backfill_finished ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction_id, auction_item_name, bid_count ], primary key: [ $2 DESC, $0 ASC, $1 ASC ], value indices: [ 0, 1, 2 ], distribution key: [], read pk prefix len hint: 2 }

- id: nexmark_q106
  before:
  - create_tables
  sql: |
    -- A self-made query that covers two-phase stateful simple aggregation.
    --
    -- Show the minimum final price of all auctions.
    SELECT
        MIN(final) AS min_final
    FROM
        (
            SELECT
                auction.id,
                MAX(price) AS final
            FROM
                auction,
                bid
            WHERE
                bid.auction = auction.id
                AND bid.date_time BETWEEN auction.date_time AND auction.expires
            GROUP BY
                auction.id
        )
  batch_plan: |
    BatchSimpleAgg { aggs: [min(min(max(bid.price)))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [min(max(bid.price))] }
        └─BatchHashAgg { group_key: [auction.id], aggs: [max(bid.price)] }
          └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: [auction.id, bid.price] }
            ├─BatchExchange { order: [], dist: HashShard(auction.id) }
            | └─BatchScan { table: auction, columns: [auction.id, auction.date_time, auction.expires], distribution: UpstreamHashShard(auction.id) }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |
    StreamMaterialize { columns: [min_final], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    └─StreamProject { exprs: [min(min(max(bid.price)))] }
      └─StreamSimpleAgg { aggs: [min(min(max(bid.price))), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr1], aggs: [min(max(bid.price)), count] }
            └─StreamProject { exprs: [auction.id, max(bid.price), Vnode(auction.id) as $expr1] }
              └─StreamHashAgg { group_key: [auction.id], aggs: [max(bid.price), count] }
                └─StreamProject { exprs: [auction.id, bid.price, bid._row_id] }
                  └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                      ├─StreamExchange { dist: HashShard(auction.id) }
                      | └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
                      └─StreamExchange { dist: HashShard(bid.auction) }
                        └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [min_final], stream_key: [], pk_columns: [], pk_conflict: "NoCheck" }
    ├── materialized table: 4294967294
    └── StreamProject { exprs: [min(min(max(bid.price)))] }
        └── StreamSimpleAgg { aggs: [min(min(max(bid.price))), count] }
            ├── result table: 1
            ├── state tables: [ 0 ]
            ├── distinct tables: []
            └──  StreamExchange Single from 1

    Fragment 1
    StreamHashAgg { group_key: [$expr1], aggs: [min(max(bid.price)), count] }
    ├── result table: 3
    ├── state tables: [ 2 ]
    ├── distinct tables: []
    └── StreamProject { exprs: [auction.id, max(bid.price), Vnode(auction.id) as $expr1] }
        └── StreamHashAgg { group_key: [auction.id], aggs: [max(bid.price), count] }
            ├── result table: 5
            ├── state tables: [ 4 ]
            ├── distinct tables: []
            └── StreamProject { exprs: [auction.id, bid.price, bid._row_id] }
                └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                        ├── left table: 6
                        ├── right table: 8
                        ├── left degree table: 7
                        ├── right degree table: 9
                        ├──  StreamExchange Hash([0]) from 2
                        └──  StreamExchange Hash([0]) from 3

    Fragment 2
    Chain { table: auction, columns: [auction.id, auction.date_time, auction.expires], pk: [auction.id], dist: UpstreamHashShard(auction.id) }
    ├── state table: 10
    ├──  Upstream
    └──  BatchPlanNode

    Fragment 3
    Chain { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], pk: [bid._row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── state table: 11
    ├──  Upstream
    └──  BatchPlanNode

    Table 0
    ├── columns: [ min(max(bid_price)), $expr1 ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 0, 1 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

    Table 1
    ├── columns: [ min(min(max(bid_price))), count ]
    ├── primary key: []
    ├── value indices: [ 0, 1 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

    Table 2
    ├── columns: [ $expr1, max(bid_price), auction_id ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: [ 2 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 3
    ├── columns: [ $expr1, min(max(bid_price)), count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4
    ├── columns: [ auction_id, bid_price, bid__row_id ]
    ├── primary key: [ $0 ASC, $1 DESC, $2 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 5
    ├── columns: [ auction_id, max(bid_price), count ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 6
    ├── columns: [ auction_id, auction_date_time, auction_expires ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 7
    ├── columns: [ auction_id, _degree ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 8
    ├── columns: [ bid_auction, bid_price, bid_date_time, bid__row_id ]
    ├── primary key: [ $0 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 9
    ├── columns: [ bid_auction, bid__row_id, _degree ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 10
    ├── columns: [ vnode, id, auction_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 11
    ├── columns: [ vnode, _row_id, bid_backfill_finished ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: []
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ min_final ], primary key: [], value indices: [ 0 ], distribution key: [], read pk prefix len hint: 0 }

