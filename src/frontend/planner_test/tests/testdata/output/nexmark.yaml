# This file is automatically generated. See `src/frontend/planner_test/README.md` for more information.
- id: create_tables
  sql: |
    CREATE TABLE person (
        id BIGINT,
        name VARCHAR,
        email_address VARCHAR,
        credit_card VARCHAR,
        city VARCHAR,
        state VARCHAR,
        date_time TIMESTAMP,
        PRIMARY KEY (id)
    );

    CREATE TABLE auction (
        id BIGINT,
        "item_name" VARCHAR,
        "description" VARCHAR,
        "initial_bid" BIGINT,
        "reserve" BIGINT,
        "date_time" TIMESTAMP,
        "expires" TIMESTAMP,
        "seller" BIGINT,
        "category" BIGINT,
        PRIMARY KEY (id)
    );

    CREATE TABLE bid (
        "auction" BIGINT,
        "bidder" BIGINT,
        "price" BIGINT,
        "channel" VARCHAR,
        "url" VARCHAR,
        "date_time" TIMESTAMP,
        "extra" VARCHAR,
        p_time TIMESTAMPTZ as proctime()
    ) append only;

    CREATE TABLE side_input(
        key BIGINT PRIMARY KEY,
        value VARCHAR
    );
- id: nexmark_q0
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, date_time FROM bid;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time, bid._row_id(hidden)] }
    └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
        ├── tables: [ StreamScan: 0 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, date_time, bid._row_id, _rw_timestamp ], primary key: [ $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 4 ], read pk prefix len hint: 1 }

- id: nexmark_q1
  before:
  - create_tables
  sql: |
    SELECT
      auction,
      bidder,
      0.908 * price as price,
      date_time
    FROM bid;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time, bid._row_id(hidden)] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, bid.date_time, bid._row_id] }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── tables: [ StreamScan: 0 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, date_time, bid._row_id, _rw_timestamp ], primary key: [ $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 4 ], read pk prefix len hint: 1 }

- id: nexmark_q2
  before:
  - create_tables
  sql: SELECT auction, price FROM bid WHERE auction = 1007 OR auction = 1020 OR auction = 2001 OR auction = 2019 OR auction = 2087;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchFilter { predicate: ((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR ((bid.auction = 2001:Int32) OR (bid.auction = 2019:Int32))) OR (bid.auction = 2087:Int32)) }
      └─BatchScan { table: bid, columns: [bid.auction, bid.price], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, price, bid._row_id(hidden)] }
    └─StreamFilter { predicate: ((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR ((bid.auction = 2001:Int32) OR (bid.auction = 2019:Int32))) OR (bid.auction = 2087:Int32)) }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, price, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamFilter { predicate: ((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR ((bid.auction = 2001:Int32) OR (bid.auction = 2019:Int32))) OR (bid.auction = 2087:Int32)) }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, price, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamFilter { predicate: ((((bid.auction = 1007:Int32) OR (bid.auction = 1020:Int32)) OR ((bid.auction = 2001:Int32) OR (bid.auction = 2019:Int32))) OR (bid.auction = 2087:Int32)) }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── tables: [ StreamScan: 0 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ auction, price, bid._row_id, _rw_timestamp ], primary key: [ $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 2 ], read pk prefix len hint: 1 }

- id: nexmark_q3
  before:
  - create_tables
  sql: |
    SELECT
        P.name, P.city, P.state, A.id
    FROM
        auction AS A INNER JOIN person AS P on A.seller = P.id
    WHERE
        A.category = 10 and (P.state = 'or' OR P.state = 'id' OR P.state = 'ca');
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: auction.seller = person.id AND (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)), output: [person.name, person.city, person.state, auction.id], lookup table: person }
      └─BatchExchange { order: [], dist: UpstreamHashShard(auction.seller) }
        └─BatchProject { exprs: [auction.id, auction.seller] }
          └─BatchFilter { predicate: (auction.category = 10:Int32) }
            └─BatchScan { table: auction, columns: [auction.id, auction.seller, auction.category], distribution: UpstreamHashShard(auction.id) }
  stream_plan: |-
    StreamMaterialize { columns: [name, city, state, id, auction.seller(hidden), person.id(hidden)], stream_key: [id, auction.seller], pk_columns: [id, auction.seller], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(auction.id, auction.seller) }
      └─StreamHashJoin { type: Inner, predicate: auction.seller = person.id, output: [person.name, person.city, person.state, auction.id, auction.seller, person.id] }
        ├─StreamExchange { dist: HashShard(auction.seller) }
        │ └─StreamProject { exprs: [auction.id, auction.seller] }
        │   └─StreamFilter { predicate: (auction.category = 10:Int32) }
        │     └─StreamTableScan { table: auction, columns: [auction.id, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
        └─StreamExchange { dist: HashShard(person.id) }
          └─StreamFilter { predicate: (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)) }
            └─StreamTableScan { table: person, columns: [person.id, person.name, person.city, person.state], stream_scan_type: ArrangementBackfill, stream_key: [person.id], pk: [id], dist: UpstreamHashShard(person.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [name, city, state, id, auction.seller(hidden), person.id(hidden)], stream_key: [id, auction.seller], pk_columns: [id, auction.seller], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([3, 4]) from 1

    Fragment 1
    StreamHashJoin { type: Inner, predicate: auction.seller = person.id, output: [person.name, person.city, person.state, auction.id, auction.seller, person.id] }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([1]) from 2
    └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamProject { exprs: [auction.id, auction.seller] }
    └── StreamFilter { predicate: (auction.category = 10:Int32) }
        └── StreamTableScan { table: auction, columns: [auction.id, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
            ├── tables: [ StreamScan: 4 ]
            ├── Upstream
            └── BatchPlanNode

    Fragment 3
    StreamFilter { predicate: (((person.state = 'or':Varchar) OR (person.state = 'id':Varchar)) OR (person.state = 'ca':Varchar)) }
    └── StreamTableScan { table: person, columns: [person.id, person.name, person.city, person.state], stream_scan_type: ArrangementBackfill, stream_key: [person.id], pk: [id], dist: UpstreamHashShard(person.id) }
        ├── tables: [ StreamScan: 5 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ auction_id, auction_seller, _rw_timestamp ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_seller, auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ person_id, person_name, person_city, person_state, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ person_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ name, city, state, id, auction.seller, person.id, _rw_timestamp ]
    ├── primary key: [ $3 ASC, $4 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5 ]
    ├── distribution key: [ 3, 4 ]
    └── read pk prefix len hint: 2

- id: nexmark_q4
  before:
  - create_tables
  sql: |
    SELECT
        Q.category,
        AVG(Q.final) as avg
    FROM (
        SELECT MAX(B.price) AS final, A.category
        FROM auction A, bid B
        WHERE A.id = B.auction AND B.date_time BETWEEN A.date_time AND A.expires
        GROUP BY A.id, A.category
    ) Q
    GROUP BY Q.category;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
      └─BatchHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price))] }
        └─BatchExchange { order: [], dist: HashShard(auction.category) }
          └─BatchHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price)] }
            └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: [auction.id, auction.category, bid.price] }
              ├─BatchExchange { order: [], dist: HashShard(auction.id) }
              │ └─BatchScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], distribution: UpstreamHashShard(auction.id) }
              └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [category, avg], stream_key: [category], pk_columns: [category], pk_conflict: NoCheck }
    └─StreamProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
      └─StreamHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price)), count] }
        └─StreamExchange { dist: HashShard(auction.category) }
          └─StreamProject { exprs: [auction.id, auction.category, max(bid.price)] }
            └─StreamHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price), count] }
              └─StreamProject { exprs: [auction.id, auction.category, bid.price, bid._row_id] }
                └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                  └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                    ├─StreamExchange { dist: HashShard(auction.id) }
                    │ └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
                    └─StreamExchange { dist: HashShard(bid.auction) }
                      └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [category, avg], stream_key: [category], pk_columns: [category], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [auction.category, (sum(max(bid.price)) / count(max(bid.price))::Decimal) as $expr1] }
        └── StreamHashAgg { group_key: [auction.category], aggs: [sum(max(bid.price)), count(max(bid.price)), count] }
            ├── tables: [ HashAggState: 0 ]
            └── StreamExchange Hash([1]) from 1

    Fragment 1
    StreamProject { exprs: [auction.id, auction.category, max(bid.price)] }
    └── StreamHashAgg { group_key: [auction.id, auction.category], aggs: [max(bid.price), count] }
        ├── tables: [ HashAggState: 2, HashAggCall0: 1 ]
        └── StreamProject { exprs: [auction.id, auction.category, bid.price, bid._row_id] }
            └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                    ├── tables: [ HashJoinLeft: 3, HashJoinDegreeLeft: 4, HashJoinRight: 5, HashJoinDegreeRight: 6 ]
                    ├── StreamExchange Hash([0]) from 2
                    └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 7 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 8 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_category, sum(max(bid_price)), count(max(bid_price)), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, auction_category, bid_price, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 DESC, $3 ASC ], value indices: [ 0, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ auction_id, auction_category, max(bid_price), count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 3 { columns: [ auction_id, auction_date_time, auction_expires, auction_category, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 8 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ category, avg, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q5
  before:
  - create_tables
  sql: |
    SELECT AuctionBids.auction, AuctionBids.num FROM (
      SELECT
        bid.auction,
        count(*) AS num,
        window_start AS starttime
      FROM
        HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
      GROUP BY
        window_start,
        bid.auction
    ) AS AuctionBids
    JOIN (
      SELECT
        max(CountBids.num) AS maxn,
        CountBids.starttime_c
      FROM (
        SELECT
          count(*) AS num,
          window_start AS starttime_c
        FROM HOP(bid, date_time, INTERVAL '2' SECOND, INTERVAL '10' SECOND)
        GROUP BY
          bid.auction,
          window_start
      ) AS CountBids
      GROUP BY
        CountBids.starttime_c
    ) AS MaxBids
    ON AuctionBids.starttime = MaxBids.starttime_c AND AuctionBids.num >= MaxBids.maxn;
  logical_plan: |-
    LogicalProject { exprs: [bid.auction, count] }
    └─LogicalJoin { type: Inner, on: (window_start = window_start) AND (count >= max(count)), output: all }
      ├─LogicalProject { exprs: [bid.auction, count, window_start] }
      │ └─LogicalAgg { group_key: [window_start, bid.auction], aggs: [count] }
      │   └─LogicalProject { exprs: [window_start, bid.auction] }
      │     └─LogicalHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: all }
      │       └─LogicalFilter { predicate: IsNotNull(bid.date_time) }
      │         └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
      └─LogicalProject { exprs: [max(count), window_start] }
        └─LogicalAgg { group_key: [window_start], aggs: [max(count)] }
          └─LogicalProject { exprs: [window_start, count] }
            └─LogicalProject { exprs: [count, window_start] }
              └─LogicalAgg { group_key: [bid.auction, window_start], aggs: [count] }
                └─LogicalProject { exprs: [bid.auction, window_start] }
                  └─LogicalHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: all }
                    └─LogicalFilter { predicate: IsNotNull(bid.date_time) }
                      └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: window_start = window_start AND (count >= max(count)), output: [bid.auction, count] }
      ├─BatchExchange { order: [], dist: HashShard(window_start) }
      │ └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
      │   └─BatchHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start] }
      │     └─BatchExchange { order: [], dist: HashShard(bid.auction) }
      │       └─BatchFilter { predicate: IsNotNull(bid.date_time) }
      │         └─BatchScan { table: bid, columns: [bid.auction, bid.date_time], distribution: SomeShard }
      └─BatchHashAgg { group_key: [window_start], aggs: [max(count)] }
        └─BatchExchange { order: [], dist: HashShard(window_start) }
          └─BatchHashAgg { group_key: [bid.auction, window_start], aggs: [count] }
            └─BatchHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start] }
              └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                └─BatchFilter { predicate: IsNotNull(bid.date_time) }
                  └─BatchScan { table: bid, columns: [bid.auction, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start], pk_columns: [auction, window_start], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, count, window_start, window_start] }
      └─StreamFilter { predicate: (count >= max(count)) }
        └─StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all }
          ├─StreamExchange { dist: HashShard(window_start) }
          │ └─StreamShare { id: 5 }
          │   └─StreamHashAgg [append_only] { group_key: [bid.auction, window_start], aggs: [count] }
          │     └─StreamExchange { dist: HashShard(bid.auction, window_start) }
          │       └─StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
          │         └─StreamFilter { predicate: IsNotNull(bid.date_time) }
          │           └─StreamTableScan { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
          └─StreamProject { exprs: [window_start, max(count)] }
            └─StreamHashAgg { group_key: [window_start], aggs: [max(count), count] }
              └─StreamExchange { dist: HashShard(window_start) }
                └─StreamShare { id: 5 }
                  └─StreamHashAgg [append_only] { group_key: [bid.auction, window_start], aggs: [count] }
                    └─StreamExchange { dist: HashShard(bid.auction, window_start) }
                      └─StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
                        └─StreamFilter { predicate: IsNotNull(bid.date_time) }
                          └─StreamTableScan { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, num, window_start(hidden), window_start#1(hidden)], stream_key: [auction, window_start], pk_columns: [auction, window_start], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [bid.auction, count, window_start, window_start] }
        └── StreamFilter { predicate: (count >= max(count)) }
            └── StreamHashJoin { type: Inner, predicate: window_start = window_start, output: all }
                ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
                ├── StreamExchange Hash([1]) from 1
                └── StreamProject { exprs: [window_start, max(count)] }
                    └── StreamHashAgg { group_key: [window_start], aggs: [max(count), count] } { tables: [ HashAggState: 7, HashAggCall0: 6 ] }
                        └── StreamExchange Hash([1]) from 4

    Fragment 1
    StreamNoOp
    └── StreamExchange NoShuffle from 2

    Fragment 2
    StreamHashAgg [append_only] { group_key: [bid.auction, window_start], aggs: [count] } { tables: [ HashAggState: 4 ] }
    └── StreamExchange Hash([0, 1]) from 3

    Fragment 3
    StreamHopWindow { time_col: bid.date_time, slide: 00:00:02, size: 00:00:10, output: [bid.auction, window_start, bid._row_id] }
    └── StreamFilter { predicate: IsNotNull(bid.date_time) }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── tables: [ StreamScan: 5 ]
            ├── Upstream
            └── BatchPlanNode

    Fragment 4
    StreamNoOp
    └── StreamExchange NoShuffle from 2

    Table 0 { columns: [ bid_auction, window_start, count, _rw_timestamp ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ window_start, bid_auction, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ window_start, max(count), _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ window_start, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, window_start, count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 5
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 6 { columns: [ window_start, count, bid_auction, _rw_timestamp ], primary key: [ $0 ASC, $1 DESC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ window_start, max(count), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4294967294 { columns: [ auction, num, window_start, window_start#1, _rw_timestamp ], primary key: [ $0 ASC, $2 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 2 ], read pk prefix len hint: 2 }

- id: nexmark_q6_group_top1
  before:
  - create_tables
  sql: |
    SELECT
        Q.seller,
        AVG(Q.final) OVER
            (PARTITION BY Q.seller ORDER BY Q.date_time ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)
        as avg
    FROM (
        SELECT ROW_NUMBER() OVER (PARTITION BY A.id, A.seller ORDER BY B.price) as rank, A.seller, B.price as final,  B.date_time
        FROM auction AS A, bid AS B
        WHERE A.id = B.auction and B.date_time between A.date_time and A.expires
    ) AS Q
    WHERE Q.rank <= 1;
  stream_plan: |-
    StreamMaterialize { columns: [seller, avg, auction.id(hidden)], stream_key: [auction.id, seller], pk_columns: [auction.id, seller], pk_conflict: NoCheck }
    └─StreamProject { exprs: [auction.seller, (sum / count::Decimal) as $expr1, auction.id] }
      └─StreamOverWindow { window_functions: [sum(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW), count(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(auction.seller) }
          └─StreamProject { exprs: [auction.seller, bid.price, bid.date_time, auction.id] }
            └─StreamGroupTopN { order: [bid.price ASC], limit: 1, offset: 0, group_key: [auction.id, auction.seller] }
              └─StreamExchange { dist: HashShard(auction.id, auction.seller) }
                └─StreamProject { exprs: [auction.id, auction.seller, bid.price, bid.date_time, bid._row_id] }
                  └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                      ├─StreamExchange { dist: HashShard(auction.id) }
                      │ └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.seller], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
                      └─StreamExchange { dist: HashShard(bid.auction) }
                        └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [seller, avg, auction.id(hidden)], stream_key: [auction.id, seller], pk_columns: [auction.id, seller], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [auction.seller, (sum / count::Decimal) as $expr1, auction.id] }
        └── StreamOverWindow { window_functions: [sum(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW), count(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
            ├── tables: [ OverWindow: 0 ]
            └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamProject { exprs: [auction.seller, bid.price, bid.date_time, auction.id] }
    └── StreamGroupTopN { order: [bid.price ASC], limit: 1, offset: 0, group_key: [auction.id, auction.seller] } { tables: [ GroupTopN: 1 ] }
        └── StreamExchange Hash([0, 1]) from 2

    Fragment 2
    StreamProject { exprs: [auction.id, auction.seller, bid.price, bid.date_time, bid._row_id] }
    └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
        └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { tables: [ HashJoinLeft: 2, HashJoinDegreeLeft: 3, HashJoinRight: 4, HashJoinDegreeRight: 5 ] }
            ├── StreamExchange Hash([0]) from 3
            └── StreamExchange Hash([0]) from 4

    Fragment 3
    StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.seller], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) } { tables: [ StreamScan: 6 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 4
    StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 7 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_seller, bid_price, bid_date_time, auction_id, sum, count, _rw_timestamp ], primary key: [ $0 ASC, $2 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, auction_seller, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ auction_id, auction_date_time, auction_expires, auction_seller, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 7 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ seller, avg, auction.id, _rw_timestamp ], primary key: [ $2 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

- id: nexmark_q6
  before:
  - create_tables
  sql: |
    SELECT
      Q.seller,
      AVG(Q.final) OVER
        (PARTITION BY Q.seller ORDER BY Q.date_time ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)
      as avg
    FROM (
      SELECT ROW_NUMBER() OVER (PARTITION BY A.id, A.seller ORDER BY B.price) as rank, A.seller, B.price as final,  B.date_time
      FROM auction AS A, bid AS B
      WHERE A.id = B.auction and B.date_time between A.date_time and A.expires
    ) AS Q
    WHERE Q.rank <= 1
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [auction.seller, (sum / count::Decimal) as $expr1] }
      └─BatchOverWindow { window_functions: [sum(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW), count(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
        └─BatchExchange { order: [auction.seller ASC, bid.date_time ASC], dist: HashShard(auction.seller) }
          └─BatchSort { order: [auction.seller ASC, bid.date_time ASC] }
            └─BatchProject { exprs: [auction.seller, bid.price, bid.date_time] }
              └─BatchGroupTopN { order: [bid.price ASC], limit: 1, offset: 0, group_key: [auction.id, auction.seller] }
                └─BatchExchange { order: [], dist: HashShard(auction.id, auction.seller) }
                  └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: [auction.id, auction.seller, bid.price, bid.date_time] }
                    ├─BatchExchange { order: [], dist: HashShard(auction.id) }
                    │ └─BatchScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.seller], distribution: UpstreamHashShard(auction.id) }
                    └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                      └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [seller, avg, auction.id(hidden)], stream_key: [auction.id, seller], pk_columns: [auction.id, seller], pk_conflict: NoCheck }
    └─StreamProject { exprs: [auction.seller, (sum / count::Decimal) as $expr1, auction.id] }
      └─StreamOverWindow { window_functions: [sum(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW), count(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
        └─StreamExchange { dist: HashShard(auction.seller) }
          └─StreamProject { exprs: [auction.seller, bid.price, bid.date_time, auction.id] }
            └─StreamGroupTopN { order: [bid.price ASC], limit: 1, offset: 0, group_key: [auction.id, auction.seller] }
              └─StreamExchange { dist: HashShard(auction.id, auction.seller) }
                └─StreamProject { exprs: [auction.id, auction.seller, bid.price, bid.date_time, bid._row_id] }
                  └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                      ├─StreamExchange { dist: HashShard(auction.id) }
                      │ └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.seller], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
                      └─StreamExchange { dist: HashShard(bid.auction) }
                        └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [seller, avg, auction.id(hidden)], stream_key: [auction.id, seller], pk_columns: [auction.id, seller], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [auction.seller, (sum / count::Decimal) as $expr1, auction.id] }
        └── StreamOverWindow { window_functions: [sum(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW), count(bid.price) OVER(PARTITION BY auction.seller ORDER BY bid.date_time ASC ROWS BETWEEN 10 PRECEDING AND CURRENT ROW)] }
            ├── tables: [ OverWindow: 0 ]
            └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamProject { exprs: [auction.seller, bid.price, bid.date_time, auction.id] }
    └── StreamGroupTopN { order: [bid.price ASC], limit: 1, offset: 0, group_key: [auction.id, auction.seller] } { tables: [ GroupTopN: 1 ] }
        └── StreamExchange Hash([0, 1]) from 2

    Fragment 2
    StreamProject { exprs: [auction.id, auction.seller, bid.price, bid.date_time, bid._row_id] }
    └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
        └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { tables: [ HashJoinLeft: 2, HashJoinDegreeLeft: 3, HashJoinRight: 4, HashJoinDegreeRight: 5 ] }
            ├── StreamExchange Hash([0]) from 3
            └── StreamExchange Hash([0]) from 4

    Fragment 3
    StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires, auction.seller], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) } { tables: [ StreamScan: 6 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 4
    StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 7 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_seller, bid_price, bid_date_time, auction_id, sum, count, _rw_timestamp ], primary key: [ $0 ASC, $2 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, auction_seller, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ auction_id, auction_date_time, auction_expires, auction_seller, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 7 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ seller, avg, auction.id, _rw_timestamp ], primary key: [ $2 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

- id: nexmark_q7
  before:
  - create_tables
  sql: |
    SELECT
      B.auction,
      B.price,
      B.bidder,
      B.date_time
    FROM
      bid B
    JOIN (
      SELECT
        MAX(price) AS maxprice,
        window_end as date_time
      FROM
        TUMBLE(bid, date_time, INTERVAL '10' SECOND)
      GROUP BY
        window_end
    ) B1 ON B.price = B1.maxprice
    WHERE
      B.date_time BETWEEN B1.date_time - INTERVAL '10' SECOND
      AND B1.date_time;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: bid.price = max(bid.price) AND (bid.date_time >= $expr2) AND (bid.date_time <= $expr1), output: [bid.auction, bid.price, bid.bidder, bid.date_time] }
      ├─BatchExchange { order: [], dist: HashShard(bid.price) }
      │ └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
      └─BatchExchange { order: [], dist: HashShard(max(bid.price)) }
        └─BatchProject { exprs: [max(bid.price), $expr1, ($expr1 - '00:00:10':Interval) as $expr2] }
          └─BatchHashAgg { group_key: [$expr1], aggs: [max(bid.price)] }
            └─BatchExchange { order: [], dist: HashShard($expr1) }
              └─BatchProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price] }
                └─BatchScan { table: bid, columns: [bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, price, bidder, date_time, bid._row_id(hidden), $expr1(hidden)], stream_key: [bid._row_id, $expr1, price], pk_columns: [bid._row_id, $expr1, price], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.price, bid.bidder, bid.date_time, bid._row_id, $expr1] }
      └─StreamFilter { predicate: (bid.date_time >= $expr2) AND (bid.date_time <= $expr1) }
        └─StreamHashJoin { type: Inner, predicate: bid.price = max(bid.price), output: all }
          ├─StreamExchange { dist: HashShard(bid.price) }
          │ └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
          └─StreamExchange { dist: HashShard(max(bid.price)) }
            └─StreamProject { exprs: [$expr1, max(bid.price), ($expr1 - '00:00:10':Interval) as $expr2] }
              └─StreamHashAgg [append_only] { group_key: [$expr1], aggs: [max(bid.price), count] }
                └─StreamExchange { dist: HashShard($expr1) }
                  └─StreamProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price, bid._row_id] }
                    └─StreamTableScan { table: bid, columns: [bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, price, bidder, date_time, bid._row_id(hidden), $expr1(hidden)], stream_key: [bid._row_id, $expr1, price], pk_columns: [bid._row_id, $expr1, price], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [bid.auction, bid.price, bid.bidder, bid.date_time, bid._row_id, $expr1] }
        └── StreamFilter { predicate: (bid.date_time >= $expr2) AND (bid.date_time <= $expr1) }
            └── StreamHashJoin { type: Inner, predicate: bid.price = max(bid.price), output: all } { tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ] }
                ├── StreamExchange Hash([2]) from 1
                └── StreamExchange Hash([1]) from 2

    Fragment 1
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 4 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 2
    StreamProject { exprs: [$expr1, max(bid.price), ($expr1 - '00:00:10':Interval) as $expr2] }
    └── StreamHashAgg [append_only] { group_key: [$expr1], aggs: [max(bid.price), count] } { tables: [ HashAggState: 5 ] }
        └── StreamExchange Hash([0]) from 3

    Fragment 3
    StreamProject { exprs: [(TumbleStart(bid.date_time, '00:00:10':Interval) + '00:00:10':Interval) as $expr1, bid.price, bid._row_id] }
    └── StreamTableScan { table: bid, columns: [bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
        ├── tables: [ StreamScan: 6 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $2 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 2 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ bid_price, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ $expr1, max(bid_price), $expr2, _rw_timestamp ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 1 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ max(bid_price), $expr1, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ $expr1, max(bid_price), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, price, bidder, date_time, bid._row_id, $expr1, _rw_timestamp ]
    ├── primary key: [ $4 ASC, $5 ASC, $1 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5 ]
    ├── distribution key: [ 1 ]
    └── read pk prefix len hint: 3

- id: nexmark_q8
  before:
  - create_tables
  sql: |
    SELECT
      P.id,
      P.name,
      P.starttime
    FROM (
      SELECT
        id,
        name,
        window_start AS starttime,
        window_end AS endtime
      FROM
        TUMBLE(person, date_time, INTERVAL '10' SECOND)
      GROUP BY
        id,
        name,
        window_start,
        window_end
    ) P
    JOIN (
      SELECT
        seller,
        window_start AS starttime,
        window_end AS endtime
      FROM
        TUMBLE(auction, date_time, INTERVAL '10' SECOND)
      GROUP BY
        seller,
        window_start,
        window_end
    ) A ON P.id = A.seller
      AND P.starttime = A.starttime
      AND P.endtime = A.endtime;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: [person.id, internal_last_seen_value(person.name), $expr1] }
      ├─BatchExchange { order: [], dist: HashShard(person.id, $expr1, $expr2) }
      │ └─BatchHashAgg { group_key: [person.id, $expr1, $expr2], aggs: [internal_last_seen_value(person.name)] }
      │   └─BatchProject { exprs: [person.id, person.name, $expr1, ($expr1 + '00:00:10':Interval) as $expr2] }
      │     └─BatchProject { exprs: [person.id, person.name, person.date_time, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1] }
      │       └─BatchScan { table: person, columns: [person.id, person.name, person.date_time], distribution: UpstreamHashShard(person.id) }
      └─BatchHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [] }
        └─BatchExchange { order: [], dist: HashShard(auction.seller, $expr3, $expr4) }
          └─BatchProject { exprs: [auction.seller, $expr3, ($expr3 + '00:00:10':Interval) as $expr4] }
            └─BatchProject { exprs: [auction.date_time, auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3] }
              └─BatchScan { table: auction, columns: [auction.date_time, auction.seller], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, name, starttime, $expr2(hidden), auction.seller(hidden), $expr3(hidden), $expr4(hidden)], stream_key: [id, starttime, $expr2], pk_columns: [id, starttime, $expr2], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(person.id, $expr1, $expr2) }
      └─StreamHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: [person.id, internal_last_seen_value(person.name), $expr1, $expr2, auction.seller, $expr3, $expr4] }
        ├─StreamExchange { dist: HashShard(person.id, $expr1, $expr2) }
        │ └─StreamProject { exprs: [person.id, $expr1, $expr2, internal_last_seen_value(person.name)] }
        │   └─StreamHashAgg { group_key: [person.id, $expr1, $expr2], aggs: [internal_last_seen_value(person.name), count] }
        │     └─StreamProject { exprs: [person.id, person.name, $expr1, ($expr1 + '00:00:10':Interval) as $expr2] }
        │       └─StreamProject { exprs: [person.id, person.name, person.date_time, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1] }
        │         └─StreamTableScan { table: person, columns: [person.id, person.name, person.date_time], stream_scan_type: ArrangementBackfill, stream_key: [person.id], pk: [id], dist: UpstreamHashShard(person.id) }
        └─StreamProject { exprs: [auction.seller, $expr3, $expr4], noop_update_hint: true }
          └─StreamHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [count] }
            └─StreamExchange { dist: HashShard(auction.seller, $expr3, $expr4) }
              └─StreamProject { exprs: [auction.seller, $expr3, ($expr3 + '00:00:10':Interval) as $expr4, auction.id] }
                └─StreamProject { exprs: [auction.date_time, auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3, auction.id] }
                  └─StreamTableScan { table: auction, columns: [auction.date_time, auction.seller, auction.id], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [id, name, starttime, $expr2(hidden), auction.seller(hidden), $expr3(hidden), $expr4(hidden)], stream_key: [id, starttime, $expr2], pk_columns: [id, starttime, $expr2], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0, 2, 3]) from 1

    Fragment 1
    StreamHashJoin { type: Inner, predicate: person.id = auction.seller AND $expr1 = $expr3 AND $expr2 = $expr4, output: [person.id, internal_last_seen_value(person.name), $expr1, $expr2, auction.seller, $expr3, $expr4] }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([0, 1, 2]) from 2
    └── StreamProject { exprs: [auction.seller, $expr3, $expr4], noop_update_hint: true }
        └── StreamHashAgg { group_key: [auction.seller, $expr3, $expr4], aggs: [count] } { tables: [ HashAggState: 6 ] }
            └── StreamExchange Hash([0, 1, 2]) from 3

    Fragment 2
    StreamProject { exprs: [person.id, $expr1, $expr2, internal_last_seen_value(person.name)] }
    └── StreamHashAgg { group_key: [person.id, $expr1, $expr2], aggs: [internal_last_seen_value(person.name), count] } { tables: [ HashAggState: 4 ] }
        └── StreamProject { exprs: [person.id, person.name, $expr1, ($expr1 + '00:00:10':Interval) as $expr2] }
            └── StreamProject { exprs: [person.id, person.name, person.date_time, TumbleStart(person.date_time, '00:00:10':Interval) as $expr1] }
                └── StreamTableScan { table: person, columns: [person.id, person.name, person.date_time], stream_scan_type: ArrangementBackfill, stream_key: [person.id], pk: [id], dist: UpstreamHashShard(person.id) }
                    ├── tables: [ StreamScan: 5 ]
                    ├── Upstream
                    └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [auction.seller, $expr3, ($expr3 + '00:00:10':Interval) as $expr4, auction.id] }
    └── StreamProject { exprs: [auction.date_time, auction.seller, TumbleStart(auction.date_time, '00:00:10':Interval) as $expr3, auction.id] }
        └── StreamTableScan { table: auction, columns: [auction.date_time, auction.seller, auction.id], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
            ├── tables: [ StreamScan: 7 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0
    ├── columns: [ person_id, $expr1, $expr2, internal_last_seen_value(person_name), _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0, 1, 2 ]
    └── read pk prefix len hint: 3

    Table 1 { columns: [ person_id, $expr1, $expr2, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 2 { columns: [ auction_seller, $expr3, $expr4, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 3 { columns: [ auction_seller, $expr3, $expr4, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 4
    ├── columns: [ person_id, $expr1, $expr2, internal_last_seen_value(person_name), count, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 3, 4 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 3

    Table 5 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ auction_seller, $expr3, $expr4, count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 7 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ id, name, starttime, $expr2, auction.seller, $expr3, $expr4, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $2 ASC, $3 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6 ]
    ├── distribution key: [ 0, 2, 3 ]
    └── read pk prefix len hint: 3

- id: nexmark_q9
  before:
  - create_tables
  sql: |
    SELECT
      id, item_name, description, initial_bid, reserve, date_time, expires, seller, category,
      auction, bidder, price, bid_date_time
    FROM (
      SELECT A.*, B.auction, B.bidder, B.price, B.date_time AS bid_date_time,
        ROW_NUMBER() OVER (PARTITION BY A.id ORDER BY B.price DESC, B.date_time ASC) AS rownum
      FROM auction A, bid B
      WHERE A.id = B.auction AND B.date_time BETWEEN A.date_time AND A.expires
    )
    WHERE rownum <= 1;
  logical_plan: |-
    LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid.auction, bid.bidder, bid.price, bid.date_time] }
    └─LogicalFilter { predicate: (row_number <= 1:Int32) }
      └─LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid.auction, bid.bidder, bid.price, bid.date_time, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY auction.id ORDER BY bid.price DESC, bid.date_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, auction._rw_timestamp, bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
            └─LogicalFilter { predicate: (auction.id = bid.auction) AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
              └─LogicalJoin { type: Inner, on: true, output: all }
                ├─LogicalScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, auction._rw_timestamp] }
                └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  optimized_logical_plan_for_batch: |-
    LogicalTopN { order: [bid.price DESC, bid.date_time ASC], limit: 1, offset: 0, group_key: [auction.id] }
    └─LogicalJoin { type: Inner, on: (auction.id = bid.auction) AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: all }
      ├─LogicalScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category] }
      └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [bid.price DESC, bid.date_time ASC], limit: 1, offset: 0, group_key: [auction.id] }
      └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: all }
        ├─BatchExchange { order: [], dist: HashShard(auction.id) }
        │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], distribution: UpstreamHashShard(auction.id) }
        └─BatchExchange { order: [], dist: HashShard(bid.auction) }
          └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id(hidden)], stream_key: [id], pk_columns: [id], pk_conflict: NoCheck }
    └─StreamGroupTopN { order: [bid.price DESC, bid.date_time ASC], limit: 1, offset: 0, group_key: [auction.id] }
      └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
        └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
          ├─StreamExchange { dist: HashShard(auction.id) }
          │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
          └─StreamExchange { dist: HashShard(bid.auction) }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id(hidden)], stream_key: [id], pk_columns: [id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamGroupTopN { order: [bid.price DESC, bid.date_time ASC], limit: 1, offset: 0, group_key: [auction.id] } { tables: [ GroupTopN: 0 ] }
        └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
            └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all } { tables: [ HashJoinLeft: 1, HashJoinDegreeLeft: 2, HashJoinRight: 3, HashJoinDegreeRight: 4 ] }
                ├── StreamExchange Hash([0]) from 1
                └── StreamExchange Hash([0]) from 2

    Fragment 1
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 5 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 2
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 6 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category, bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $11 DESC, $12 ASC, $13 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, bid_bidder, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $4 ASC ], value indices: [ 0, 1, 2, 3, 4 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 6 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ id, item_name, description, initial_bid, reserve, date_time, expires, seller, category, auction, bidder, price, bid_date_time, bid._row_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q10
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, date_time, TO_CHAR(date_time, 'YYYY-MM-DD') as date, TO_CHAR(date_time, 'HH:MI') as time FROM bid;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time, date, time, bid._row_id(hidden)] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, date_time, date, time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, date, time, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, ToChar(bid.date_time, 'HH:MI':Varchar) as $expr2, bid._row_id] }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── tables: [ StreamScan: 0 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, date_time, date, time, bid._row_id, _rw_timestamp ], primary key: [ $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 6 ], read pk prefix len hint: 1 }

- id: nexmark_q11
  before:
  - create_tables
  sql: |
    SELECT
      B.bidder,
      count(*) as bid_count,
      SESSION_START(B.date_time, INTERVAL '10' SECOND) as starttime,
      SESSION_END(B.date_time, INTERVAL '10' SECOND) as endtime
    FROM bid B
    GROUP BY B.bidder, SESSION(B.date_time, INTERVAL '10' SECOND);
  binder_error: |
    Failed to bind expression: SESSION_START(B.date_time, INTERVAL '10' SECOND)

    Caused by:
      function session_start(timestamp without time zone, interval) does not exist
- id: nexmark_q12
  before:
  - create_tables
  sql: |
    SELECT bidder, count(*) as bid_count, window_start, window_end
    FROM TUMBLE(bid, p_time, INTERVAL '10' SECOND)
    GROUP BY bidder, window_start, window_end
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.bidder, count, $expr1, $expr2] }
      └─BatchHashAgg { group_key: [bid.bidder, $expr1, $expr2], aggs: [count] }
        └─BatchExchange { order: [], dist: HashShard(bid.bidder, $expr1, $expr2) }
          └─BatchProject { exprs: [bid.bidder, $expr1, AddWithTimeZone($expr1, '00:00:10':Interval, 'UTC':Varchar) as $expr2] }
            └─BatchProject { exprs: [bid.bidder, bid.p_time, TumbleStart(bid.p_time, '00:00:10':Interval) as $expr1] }
              └─BatchScan { table: bid, columns: [bid.bidder, bid.p_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [bidder, bid_count, window_start, window_end], stream_key: [bidder, window_start, window_end], pk_columns: [bidder, window_start, window_end], pk_conflict: NoCheck, watermark_columns: [window_start, window_end] }
    └─StreamProject { exprs: [bid.bidder, count, $expr1, $expr2], output_watermarks: [[$expr1, $expr2]] }
      └─StreamHashAgg [append_only] { group_key: [bid.bidder, $expr1, $expr2], aggs: [count], output_watermarks: [[$expr1, $expr2]] }
        └─StreamExchange { dist: HashShard(bid.bidder, $expr1, $expr2) }
          └─StreamProject { exprs: [bid.bidder, $expr1, AddWithTimeZone($expr1, '00:00:10':Interval, 'UTC':Varchar) as $expr2, bid._row_id], output_watermarks: [[$expr1, $expr2]] }
            └─StreamProject { exprs: [bid.bidder, bid.p_time, TumbleStart(bid.p_time, '00:00:10':Interval) as $expr1, bid._row_id], output_watermarks: [[bid.p_time, $expr1]] }
              └─StreamTableScan { table: bid, columns: [bid.bidder, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [bidder, bid_count, window_start, window_end], stream_key: [bidder, window_start, window_end], pk_columns: [bidder, window_start, window_end], pk_conflict: NoCheck, watermark_columns: [window_start, window_end] }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [bid.bidder, count, $expr1, $expr2], output_watermarks: [[$expr1, $expr2]] }
        └── StreamHashAgg [append_only] { group_key: [bid.bidder, $expr1, $expr2], aggs: [count], output_watermarks: [[$expr1, $expr2]] } { tables: [ HashAggState: 0 ] }
            └── StreamExchange Hash([0, 1, 2]) from 1

    Fragment 1
    StreamProject { exprs: [bid.bidder, $expr1, AddWithTimeZone($expr1, '00:00:10':Interval, 'UTC':Varchar) as $expr2, bid._row_id], output_watermarks: [[$expr1, $expr2]] }
    └── StreamProject { exprs: [bid.bidder, bid.p_time, TumbleStart(bid.p_time, '00:00:10':Interval) as $expr1, bid._row_id], output_watermarks: [[bid.p_time, $expr1]] }
        └── StreamTableScan { table: bid, columns: [bid.bidder, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 1 ] }
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ bid_bidder, $expr1, $expr2, count, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3 ], distribution key: [ 0, 1, 2 ], read pk prefix len hint: 3 }

    Table 1 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ bidder, bid_count, window_start, window_end, _rw_timestamp ], primary key: [ $0 ASC, $2 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0, 2, 3 ], read pk prefix len hint: 3 }

- id: nexmark_q13
  before:
  - create_tables
  sql: |
    SELECT
      B.auction, B.bidder, B.price, B.date_time, S.value
    FROM bid B
    JOIN side_input FOR SYSTEM_TIME AS OF PROCTIME() S
    ON mod(B.auction, 10000) = S.key
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, date_time, value, bid._row_id(hidden), $expr10018(hidden), side_input.key(hidden)] }
    └─StreamTemporalJoin { type: Inner, append_only: true, predicate: $expr1 = side_input.key, nested_loop: false, output: [bid.auction, bid.bidder, bid.price, bid.date_time, side_input.value, bid._row_id, $expr1, side_input.key] }
      ├─StreamExchange { dist: HashShard($expr1) }
      │ └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, (bid.auction % 10000:Int32) as $expr1, bid._row_id] }
      │   └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
      └─StreamExchange [no_shuffle] { dist: UpstreamHashShard(side_input.key) }
        └─StreamTableScan { table: side_input, columns: [side_input.key, side_input.value], stream_scan_type: UpstreamOnly, stream_key: [side_input.key], pk: [key], dist: UpstreamHashShard(side_input.key) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, date_time, value, bid._row_id(hidden), $expr1(hidden), side_input.key(hidden)], stream_key: [bid._row_id, $expr1], pk_columns: [bid._row_id, $expr1], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(bid._row_id, $expr1) }
      └─StreamTemporalJoin { type: Inner, append_only: true, predicate: $expr1 = side_input.key, nested_loop: false, output: [bid.auction, bid.bidder, bid.price, bid.date_time, side_input.value, bid._row_id, $expr1, side_input.key] }
        ├─StreamExchange { dist: HashShard($expr1) }
        │ └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, (bid.auction % 10000:Int32) as $expr1, bid._row_id] }
        │   └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
        └─StreamExchange [no_shuffle] { dist: UpstreamHashShard(side_input.key) }
          └─StreamTableScan { table: side_input, columns: [side_input.key, side_input.value], stream_scan_type: UpstreamOnly, stream_key: [side_input.key], pk: [key], dist: UpstreamHashShard(side_input.key) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, date_time, value, bid._row_id(hidden), $expr1(hidden), side_input.key(hidden)], stream_key: [bid._row_id, $expr1], pk_columns: [bid._row_id, $expr1], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([5, 6]) from 1

    Fragment 1
    StreamTemporalJoin { type: Inner, append_only: true, predicate: $expr1 = side_input.key, nested_loop: false, output: [bid.auction, bid.bidder, bid.price, bid.date_time, side_input.value, bid._row_id, $expr1, side_input.key] }
    ├── StreamExchange Hash([4]) from 2
    └── StreamExchange NoShuffle from 3

    Fragment 2
    StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.date_time, (bid.auction % 10000:Int32) as $expr1, bid._row_id] }
    └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
        ├── tables: [ StreamScan: 0 ]
        ├── Upstream
        └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: side_input, columns: [side_input.key, side_input.value], stream_scan_type: UpstreamOnly, stream_key: [side_input.key], pk: [key], dist: UpstreamHashShard(side_input.key) } { tables: [ StreamScan: 1 ] }
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 1 { columns: [ vnode, key, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, date_time, value, bid._row_id, $expr1, side_input.key, _rw_timestamp ]
    ├── primary key: [ $5 ASC, $6 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 5, 6 ]
    └── read pk prefix len hint: 2

- id: nexmark_q14
  before:
  - create_tables
  sql: |
    SELECT
      auction,
      bidder,
      0.908 * price as price,
      CASE
        WHEN
          extract(hour from date_time) >= 8 AND
          extract(hour from date_time) <= 18
        THEN 'dayTime'
        WHEN
          extract(hour from date_time) <= 6 OR
          extract(hour from date_time) >= 20
        THEN 'nightTime'
        ELSE 'otherTime'
      END AS bidTimeType,
      date_time,
      extra
      -- ignore UDF in planner test
      -- count_char(extra, 'c') AS c_counts
    FROM bid
    WHERE 0.908 * price > 1000000 AND 0.908 * price < 50000000;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra] }
      └─BatchFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, bidtimetype, date_time, extra, bid._row_id(hidden)] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
      └─StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, bidtimetype, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
      └─StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, bidtimetype, date_time, extra, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, bid.bidder, (0.908:Decimal * bid.price::Decimal) as $expr1, Case(((Extract('HOUR':Varchar, bid.date_time) >= 8:Decimal) AND (Extract('HOUR':Varchar, bid.date_time) <= 18:Decimal)), 'dayTime':Varchar, ((Extract('HOUR':Varchar, bid.date_time) <= 6:Decimal) OR (Extract('HOUR':Varchar, bid.date_time) >= 20:Decimal)), 'nightTime':Varchar, 'otherTime':Varchar) as $expr2, bid.date_time, bid.extra, bid._row_id] }
        └── StreamFilter { predicate: ((0.908:Decimal * bid.price::Decimal) > 1000000:Decimal) AND ((0.908:Decimal * bid.price::Decimal) < 50000000:Decimal) }
            └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 0 ] }
                ├── Upstream
                └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, bidtimetype, date_time, extra, bid._row_id, _rw_timestamp ], primary key: [ $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 6 ], read pk prefix len hint: 1 }

- id: nexmark_q15
  before:
  - create_tables
  sql: |
    SELECT
        TO_CHAR(date_time, 'yyyy-MM-dd') as day,
        count(*) AS total_bids,
        count(*) filter (where price < 10000) AS rank1_bids,
        count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
        count(*) filter (where price >= 1000000) AS rank3_bids,
        count(distinct bidder) AS total_bidders,
        count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
        count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
        count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
        count(distinct auction) AS total_auctions,
        count(distinct auction) filter (where price < 10000) AS rank1_auctions,
        count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
        count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY to_char(date_time, 'yyyy-MM-dd');
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [$expr1_expanded], aggs: [sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─BatchExchange { order: [], dist: HashShard($expr1_expanded) }
        └─BatchHashAgg { group_key: [$expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
          └─BatchExchange { order: [], dist: HashShard($expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag) }
            └─BatchExpand { column_subsets: [[$expr1], [$expr1, bid.bidder], [$expr1, bid.auction]] }
              └─BatchProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction] }
                └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: NoCheck }
    └─StreamHashAgg [append_only] { group_key: [$expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
      └─StreamExchange { dist: HashShard($expr1) }
        └─StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamHashAgg [append_only] { group_key: [$expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
        ├── tables: [ HashAggState: 0, HashAggDedupForCol2: 1, HashAggDedupForCol3: 2 ]
        └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
    └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 3 ] }
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ $expr1, count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), count(distinct bid_bidder), count(distinct bid_bidder) filter((bid_price < 10000:Int32)), count(distinct bid_bidder) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_bidder) filter((bid_price >= 1000000:Int32)), count(distinct bid_auction), count(distinct bid_auction) filter((bid_price < 10000:Int32)), count(distinct bid_auction) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_auction) filter((bid_price >= 1000000:Int32)), _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ $expr1, bid_bidder, count_for_agg_call_4, count_for_agg_call_5, count_for_agg_call_6, count_for_agg_call_7, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 2 { columns: [ $expr1, bid_auction, count_for_agg_call_8, count_for_agg_call_9, count_for_agg_call_10, count_for_agg_call_11, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2, 3, 4, 5 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

    Table 3 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q15_split_distinct_agg
  before:
  - create_tables
  sql: |
    SELECT
        TO_CHAR(date_time, 'yyyy-MM-dd') as day,
        count(*) AS total_bids,
        count(*) filter (where price < 10000) AS rank1_bids,
        count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
        count(*) filter (where price >= 1000000) AS rank3_bids,
        count(distinct bidder) AS total_bidders,
        count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
        count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
        count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
        count(distinct auction) AS total_auctions,
        count(distinct auction) filter (where price < 10000) AS rank1_auctions,
        count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
        count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY to_char(date_time, 'yyyy-MM-dd');
  stream_plan: |-
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: NoCheck }
    └─StreamProject { exprs: [$expr1_expanded, sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─StreamHashAgg { group_key: [$expr1_expanded], aggs: [sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count] }
        └─StreamExchange { dist: HashShard($expr1_expanded) }
          └─StreamHashAgg [append_only] { group_key: [$expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
            └─StreamExchange { dist: HashShard($expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag) }
              └─StreamExpand { column_subsets: [[$expr1], [$expr1, bid.bidder], [$expr1, bid.auction]] }
                └─StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
                  └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [day], pk_columns: [day], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [$expr1_expanded, sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
        └── StreamHashAgg { group_key: [$expr1_expanded], aggs: [sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count] }
            ├── tables: [ HashAggState: 0 ]
            └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamHashAgg [append_only] { group_key: [$expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] } { tables: [ HashAggState: 1 ] }
    └── StreamExchange Hash([0, 2, 3, 10]) from 2

    Fragment 2
    StreamExpand { column_subsets: [[$expr1], [$expr1, bid.bidder], [$expr1, bid.auction]] }
    └── StreamProject { exprs: [ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, bid.price, bid.bidder, bid.auction, bid._row_id] }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 2 ] }
            ├── Upstream
            └── BatchPlanNode

    Table 0
    ├── columns: [ $expr1_expanded, sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid_price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid_price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid_bidder_expanded) filter((flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_auction_expanded) filter((flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ $expr1_expanded, bid_bidder_expanded, bid_auction_expanded, flag, count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC ], value indices: [ 4, 5, 6, 7 ], distribution key: [ 0, 1, 2, 3 ], read pk prefix len hint: 4 }

    Table 2 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ day, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

  with_config_map:
    RW_FORCE_SPLIT_DISTINCT_AGG: 'true'
- id: nexmark_q16
  before:
  - create_tables
  sql: |
    SELECT
      channel,
      to_char(date_time, 'yyyy-MM-dd') AS day,
      max(to_char(date_time, 'HH:mm')) AS minute,
      count(*) AS total_bids,
      count(*) filter (where price < 10000) AS rank1_bids,
      count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
      count(*) filter (where price >= 1000000) AS rank3_bids,
      count(distinct bidder) AS total_bidders,
      count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
      count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
      count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
      count(distinct auction) AS total_auctions,
      count(distinct auction) filter (where price < 10000) AS rank1_auctions,
      count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
      count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY channel, to_char(date_time, 'yyyy-MM-dd');
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashAgg { group_key: [bid.channel_expanded, $expr1_expanded], aggs: [max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─BatchExchange { order: [], dist: HashShard(bid.channel_expanded, $expr1_expanded) }
        └─BatchHashAgg { group_key: [bid.channel_expanded, $expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [max($expr2_expanded), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
          └─BatchExchange { order: [], dist: HashShard(bid.channel_expanded, $expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag) }
            └─BatchExpand { column_subsets: [[bid.channel, $expr1, $expr2], [bid.channel, $expr1, bid.bidder], [bid.channel, $expr1, bid.auction]] }
              └─BatchProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction] }
                └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: NoCheck }
    └─StreamHashAgg [append_only] { group_key: [bid.channel, $expr1], aggs: [max($expr2), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
      └─StreamExchange { dist: HashShard(bid.channel, $expr1) }
        └─StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamHashAgg [append_only] { group_key: [bid.channel, $expr1], aggs: [max($expr2), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), count(distinct bid.bidder), count(distinct bid.bidder) filter((bid.price < 10000:Int32)), count(distinct bid.bidder) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.bidder) filter((bid.price >= 1000000:Int32)), count(distinct bid.auction), count(distinct bid.auction) filter((bid.price < 10000:Int32)), count(distinct bid.auction) filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count(distinct bid.auction) filter((bid.price >= 1000000:Int32))] }
        ├── tables: [ HashAggState: 0, HashAggDedupForCol4: 1, HashAggDedupForCol5: 2 ]
        └── StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
    └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 3 ] }
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ bid_channel, $expr1, max($expr2), count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), count(distinct bid_bidder), count(distinct bid_bidder) filter((bid_price < 10000:Int32)), count(distinct bid_bidder) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_bidder) filter((bid_price >= 1000000:Int32)), count(distinct bid_auction), count(distinct bid_auction) filter((bid_price < 10000:Int32)), count(distinct bid_auction) filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count(distinct bid_auction) filter((bid_price >= 1000000:Int32)), _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ bid_channel, $expr1, bid_bidder, count_for_agg_call_5, count_for_agg_call_6, count_for_agg_call_7, count_for_agg_call_8, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3, 4, 5, 6 ], distribution key: [ 0, 1 ], read pk prefix len hint: 3 }

    Table 2 { columns: [ bid_channel, $expr1, bid_auction, count_for_agg_call_9, count_for_agg_call_10, count_for_agg_call_11, count_for_agg_call_12, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC ], value indices: [ 3, 4, 5, 6 ], distribution key: [ 0, 1 ], read pk prefix len hint: 3 }

    Table 3 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

- id: nexmark_q16_split_distinct_agg
  before:
  - create_tables
  sql: |
    SELECT
      channel,
      to_char(date_time, 'yyyy-MM-dd') AS day,
      max(to_char(date_time, 'HH:mm')) AS minute,
      count(*) AS total_bids,
      count(*) filter (where price < 10000) AS rank1_bids,
      count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
      count(*) filter (where price >= 1000000) AS rank3_bids,
      count(distinct bidder) AS total_bidders,
      count(distinct bidder) filter (where price < 10000) AS rank1_bidders,
      count(distinct bidder) filter (where price >= 10000 and price < 1000000) AS rank2_bidders,
      count(distinct bidder) filter (where price >= 1000000) AS rank3_bidders,
      count(distinct auction) AS total_auctions,
      count(distinct auction) filter (where price < 10000) AS rank1_auctions,
      count(distinct auction) filter (where price >= 10000 and price < 1000000) AS rank2_auctions,
      count(distinct auction) filter (where price >= 1000000) AS rank3_auctions
    FROM bid
    GROUP BY channel, to_char(date_time, 'yyyy-MM-dd');
  stream_plan: |-
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.channel_expanded, $expr1_expanded, max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
      └─StreamHashAgg { group_key: [bid.channel_expanded, $expr1_expanded], aggs: [max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count] }
        └─StreamExchange { dist: HashShard(bid.channel_expanded, $expr1_expanded) }
          └─StreamHashAgg [append_only] { group_key: [bid.channel_expanded, $expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [max($expr2_expanded), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] }
            └─StreamExchange { dist: HashShard(bid.channel_expanded, $expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag) }
              └─StreamExpand { column_subsets: [[bid.channel, $expr1, $expr2], [bid.channel, $expr1, bid.bidder], [bid.channel, $expr1, bid.auction]] }
                └─StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
                  └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions], stream_key: [channel, day], pk_columns: [channel, day], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.channel_expanded, $expr1_expanded, max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64))] }
        └── StreamHashAgg { group_key: [bid.channel_expanded, $expr1_expanded], aggs: [max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid.price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid.price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid.bidder_expanded) filter((flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.bidder_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid.auction_expanded) filter((flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid.auction_expanded) filter((count filter((bid.price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count] }
            ├── tables: [ HashAggState: 1, HashAggCall0: 0 ]
            └── StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamHashAgg [append_only] { group_key: [bid.channel_expanded, $expr1_expanded, bid.bidder_expanded, bid.auction_expanded, flag], aggs: [max($expr2_expanded), count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32))] } { tables: [ HashAggState: 2 ] }
    └── StreamExchange Hash([0, 1, 4, 5, 14]) from 2

    Fragment 2
    StreamExpand { column_subsets: [[bid.channel, $expr1, $expr2], [bid.channel, $expr1, bid.bidder], [bid.channel, $expr1, bid.auction]] }
    └── StreamProject { exprs: [bid.channel, ToChar(bid.date_time, 'yyyy-MM-dd':Varchar) as $expr1, ToChar(bid.date_time, 'HH:mm':Varchar) as $expr2, bid.price, bid.bidder, bid.auction, bid._row_id] }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 3 ] }
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ bid_channel_expanded, $expr1_expanded, max($expr2_expanded), bid_bidder_expanded, bid_auction_expanded, flag, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 DESC, $3 ASC, $4 ASC, $5 ASC ], value indices: [ 0, 1, 2, 3, 4, 5 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

    Table 1
    ├── columns: [ bid_channel_expanded, $expr1_expanded, max(max($expr2_expanded)) filter((flag = 0:Int64)), sum0(count) filter((flag = 0:Int64)), sum0(count filter((bid_price < 10000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32))) filter((flag = 0:Int64)), sum0(count filter((bid_price >= 1000000:Int32))) filter((flag = 0:Int64)), count(bid_bidder_expanded) filter((flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price < 10000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_bidder_expanded) filter((count filter((bid_price >= 1000000:Int32)) > 0:Int64) AND (flag = 1:Int64)), count(bid_auction_expanded) filter((flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price < 10000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count(bid_auction_expanded) filter((count filter((bid_price >= 1000000:Int32)) > 0:Int64) AND (flag = 2:Int64)), count, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 2 { columns: [ bid_channel_expanded, $expr1_expanded, bid_bidder_expanded, bid_auction_expanded, flag, max($expr2_expanded), count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), _rw_timestamp ], primary key: [ $0 ASC, $1 ASC, $2 ASC, $3 ASC, $4 ASC ], value indices: [ 5, 6, 7, 8, 9 ], distribution key: [ 0, 1, 2, 3, 4 ], read pk prefix len hint: 5 }

    Table 3 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ channel, day, minute, total_bids, rank1_bids, rank2_bids, rank3_bids, total_bidders, rank1_bidders, rank2_bidders, rank3_bidders, total_auctions, rank1_auctions, rank2_auctions, rank3_auctions, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

  with_config_map:
    RW_FORCE_SPLIT_DISTINCT_AGG: 'true'
- id: nexmark_q17
  before:
  - create_tables
  sql: |
    SELECT
        auction,
        to_char(date_time, 'YYYY-MM-DD') AS day,
        count(*) AS total_bids,
        count(*) filter (where price < 10000) AS rank1_bids,
        count(*) filter (where price >= 10000 and price < 1000000) AS rank2_bids,
        count(*) filter (where price >= 1000000) AS rank3_bids,
        min(price) AS min_price,
        max(price) AS max_price,
        avg(price) AS avg_price,
        sum(price) AS sum_price
    FROM bid
    GROUP BY auction, to_char(date_time, 'YYYY-MM-DD');
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
      └─BatchHashAgg { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
        └─BatchExchange { order: [], dist: HashShard(bid.auction, $expr1) }
          └─BatchProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price] }
            └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price], stream_key: [auction, day], pk_columns: [auction, day], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
      └─StreamHashAgg [append_only] { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
        └─StreamExchange { dist: HashShard(bid.auction, $expr1) }
          └─StreamProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price, bid._row_id] }
            └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price], stream_key: [auction, day], pk_columns: [auction, day], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, $expr1, count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), (sum(bid.price) / count(bid.price)::Decimal) as $expr2, sum(bid.price)] }
        └── StreamHashAgg [append_only] { group_key: [bid.auction, $expr1], aggs: [count, count filter((bid.price < 10000:Int32)), count filter((bid.price >= 10000:Int32) AND (bid.price < 1000000:Int32)), count filter((bid.price >= 1000000:Int32)), min(bid.price), max(bid.price), sum(bid.price), count(bid.price)] }
            ├── tables: [ HashAggState: 0 ]
            └── StreamExchange Hash([0, 1]) from 1

    Fragment 1
    StreamProject { exprs: [bid.auction, ToChar(bid.date_time, 'YYYY-MM-DD':Varchar) as $expr1, bid.price, bid._row_id] }
    └── StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 1 ] }
        ├── Upstream
        └── BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, $expr1, count, count filter((bid_price < 10000:Int32)), count filter((bid_price >= 10000:Int32) AND (bid_price < 1000000:Int32)), count filter((bid_price >= 1000000:Int32)), min(bid_price), max(bid_price), sum(bid_price), count(bid_price), _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC ]
    ├── value indices: [ 2, 3, 4, 5, 6, 7, 8, 9 ]
    ├── distribution key: [ 0, 1 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, day, total_bids, rank1_bids, rank2_bids, rank3_bids, min_price, max_price, avg_price, sum_price, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ], distribution key: [ 0, 1 ], read pk prefix len hint: 2 }

- id: nexmark_q18
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, channel, url, date_time, extra
    FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY bidder, auction ORDER BY date_time DESC) AS rank_number
          FROM bid)
    WHERE rank_number <= 1;
  logical_plan: |-
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra] }
    └─LogicalFilter { predicate: (row_number <= 1:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.bidder, bid.auction ORDER BY bid.date_time DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [bid.date_time DESC], limit: 1, offset: 0, group_key: [bid.bidder, bid.auction] }
      └─BatchExchange { order: [], dist: HashShard(bid.bidder, bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction], pk_columns: [bidder, auction], pk_conflict: NoCheck }
    └─StreamGroupTopN [append_only] { order: [bid.date_time DESC], limit: 1, offset: 0, group_key: [bid.bidder, bid.auction] }
      └─StreamExchange { dist: HashShard(bid.bidder, bid.auction) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction], pk_columns: [bidder, auction], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamGroupTopN [append_only] { order: [bid.date_time DESC], limit: 1, offset: 0, group_key: [bid.bidder, bid.auction] } { tables: [ AppendOnlyGroupTopN: 0 ] }
        └── StreamExchange Hash([1, 0]) from 1

    Fragment 1
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 1 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid__row_id, _rw_timestamp ]
    ├── primary key: [ $1 ASC, $0 ASC, $5 DESC, $7 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 1, 0 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, url, date_time, extra, bid._row_id, _rw_timestamp ], primary key: [ $1 ASC, $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ], distribution key: [ 1, 0 ], read pk prefix len hint: 2 }

- id: nexmark_q18_rank
  before:
  - create_tables
  sql: |
    SELECT auction, bidder, price, channel, url, date_time, extra
    FROM (SELECT *, RANK() OVER (PARTITION BY bidder, auction ORDER BY date_time DESC) AS rank_number
          FROM bid)
    WHERE rank_number <= 1;
  logical_plan: |-
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra] }
    └─LogicalFilter { predicate: (rank <= 1:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, rank] }
        └─LogicalOverWindow { window_functions: [rank() OVER(PARTITION BY bid.bidder, bid.auction ORDER BY bid.date_time DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [bid.date_time DESC], limit: 1, offset: 0, with_ties: true, group_key: [bid.bidder, bid.auction] }
      └─BatchExchange { order: [], dist: HashShard(bid.bidder, bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction, bid._row_id], pk_columns: [bidder, auction, bid._row_id], pk_conflict: NoCheck }
    └─StreamGroupTopN [append_only] { order: [bid.date_time DESC], limit: 1, offset: 0, with_ties: true, group_key: [bid.bidder, bid.auction] }
      └─StreamExchange { dist: HashShard(bid.bidder, bid.auction) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, bid._row_id(hidden)], stream_key: [bidder, auction, bid._row_id], pk_columns: [bidder, auction, bid._row_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamGroupTopN [append_only] { order: [bid.date_time DESC], limit: 1, offset: 0, with_ties: true, group_key: [bid.bidder, bid.auction] } { tables: [ AppendOnlyGroupTopN: 0 ] }
        └── StreamExchange Hash([1, 0]) from 1

    Fragment 1
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 1 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid__row_id, _rw_timestamp ]
    ├── primary key: [ $1 ASC, $0 ASC, $5 DESC, $7 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ]
    ├── distribution key: [ 1, 0 ]
    └── read pk prefix len hint: 2

    Table 1 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, url, date_time, extra, bid._row_id, _rw_timestamp ], primary key: [ $1 ASC, $0 ASC, $7 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ], distribution key: [ 1, 0 ], read pk prefix len hint: 3 }

- id: nexmark_q19_no_rank
  before:
  - create_tables
  sql: |
    SELECT * EXCEPT (rank_number) FROM
    (SELECT *, ROW_NUMBER() OVER (PARTITION BY auction ORDER BY price DESC) AS rank_number FROM bid)
    WHERE rank_number <= 10;
  logical_plan: |-
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time] }
    └─LogicalFilter { predicate: (row_number <= 10:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchGroupTopN { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction] }
      └─BatchExchange { order: [], dist: HashShard(bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id(hidden)], stream_key: [auction, bid._row_id], pk_columns: [auction, bid._row_id], pk_conflict: NoCheck, watermark_columns: [p_time] }
    └─StreamGroupTopN [append_only] { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction], output_watermarks: [[bid.p_time]] }
      └─StreamExchange { dist: HashShard(bid.auction) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id(hidden)], stream_key: [auction, bid._row_id], pk_columns: [auction, bid._row_id], pk_conflict: NoCheck, watermark_columns: [p_time] }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamGroupTopN [append_only] { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction], output_watermarks: [[bid.p_time]] } { tables: [ AppendOnlyGroupTopN: 0 ] }
        └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 1 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid_p_time, bid__row_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $2 DESC, $8 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id, _rw_timestamp ], primary key: [ $0 ASC, $8 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], distribution key: [ 0 ], read pk prefix len hint: 2 }

- id: nexmark_q19
  before:
  - create_tables
  sql: |
    SELECT * FROM
    (SELECT *, ROW_NUMBER() OVER (PARTITION BY auction ORDER BY price DESC) AS rank_number FROM bid)
    WHERE rank_number <= 10;
  logical_plan: |-
    LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, row_number] }
    └─LogicalFilter { predicate: (row_number <= 10:Int32) }
      └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, row_number] }
        └─LogicalOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
          └─LogicalProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
            └─LogicalScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id, bid._rw_timestamp] }
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─BatchSort { order: [bid.auction ASC, bid.price DESC] }
        └─BatchGroupTopN { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction] }
          └─BatchExchange { order: [], dist: HashShard(bid.auction) }
            └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id(hidden), rank_number], stream_key: [auction, bid._row_id], pk_columns: [auction, bid._row_id], pk_conflict: NoCheck }
    └─StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] }
      └─StreamGroupTopN [append_only] { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction], output_watermarks: [[bid.p_time]] }
        └─StreamExchange { dist: HashShard(bid.auction) }
          └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id(hidden), rank_number], stream_key: [auction, bid._row_id], pk_columns: [auction, bid._row_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamOverWindow { window_functions: [row_number() OVER(PARTITION BY bid.auction ORDER BY bid.price DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)] } { tables: [ OverWindow: 0 ] }
        └── StreamGroupTopN [append_only] { order: [bid.price DESC], limit: 10, offset: 0, group_key: [bid.auction], output_watermarks: [[bid.p_time]] } { tables: [ AppendOnlyGroupTopN: 1 ] }
            └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid.extra, bid.p_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 2 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid_p_time, bid__row_id, row_number, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $2 DESC, $8 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1
    ├── columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid_extra, bid_p_time, bid__row_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $2 DESC, $8 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 2 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, channel, url, date_time, extra, p_time, bid._row_id, rank_number, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $8 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 2

- id: nexmark_q20
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel, url, B.date_time as date_timeB,
        item_name, description, initial_bid, reserve, A.date_time as date_timeA, expires, seller, category
    FROM
        bid B INNER JOIN auction A on B.auction = A.id
    WHERE A.category = 10;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchLookupJoin { type: Inner, predicate: bid.auction = auction.id AND (auction.category = 10:Int32), output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], lookup table: auction }
      └─BatchExchange { order: [], dist: UpstreamHashShard(bid.auction) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id(hidden), auction.id(hidden)], stream_key: [bid._row_id, auction], pk_columns: [bid._row_id, auction], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(bid.auction, bid._row_id) }
      └─StreamHashJoin { type: Inner, predicate: bid.auction = auction.id, output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid._row_id, auction.id] }
        ├─StreamExchange { dist: HashShard(bid.auction) }
        │ └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
        └─StreamExchange { dist: HashShard(auction.id) }
          └─StreamFilter { predicate: (auction.category = 10:Int32) }
            └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id(hidden), auction.id(hidden)], stream_key: [bid._row_id, auction], pk_columns: [bid._row_id, auction], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0, 14]) from 1

    Fragment 1
    StreamHashJoin { type: Inner, predicate: bid.auction = auction.id, output: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category, bid._row_id, auction.id] }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([0]) from 2
    └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 4 ] }
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamFilter { predicate: (auction.category = 10:Int32) }
    └── StreamTableScan { table: auction, columns: [auction.id, auction.item_name, auction.description, auction.initial_bid, auction.reserve, auction.date_time, auction.expires, auction.seller, auction.category], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
        ├── tables: [ StreamScan: 5 ]
        ├── Upstream
        └── BatchPlanNode

    Table 0 { columns: [ bid_auction, bid_bidder, bid_price, bid_channel, bid_url, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $6 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ auction_id, auction_item_name, auction_description, auction_initial_bid, auction_reserve, auction_date_time, auction_expires, auction_seller, auction_category, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 5 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294
    ├── columns: [ auction, bidder, price, channel, url, date_timeb, item_name, description, initial_bid, reserve, date_timea, expires, seller, category, bid._row_id, auction.id, _rw_timestamp ]
    ├── primary key: [ $14 ASC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ]
    ├── distribution key: [ 0, 14 ]
    └── read pk prefix len hint: 2

- id: nexmark_q21
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel,
        CASE
            WHEN lower(channel) = 'apple' THEN '0'
            WHEN lower(channel) = 'google' THEN '1'
            WHEN lower(channel) = 'facebook' THEN '2'
            WHEN lower(channel) = 'baidu' THEN '3'
            ELSE REGEXP_MATCH(url, '(&|^)channel_id=([^&]*)')[2]
            END
        AS channel_id FROM bid
        where REGEXP_MATCH(url, '(&|^)channel_id=([^&]*)')[2] is not null or
              lower(channel) in ('apple', 'google', 'facebook', 'baidu');
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, Case((Lower(bid.channel) = 'apple':Varchar), '0':Varchar, (Lower(bid.channel) = 'google':Varchar), '1':Varchar, (Lower(bid.channel) = 'facebook':Varchar), '2':Varchar, (Lower(bid.channel) = 'baidu':Varchar), '3':Varchar, ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) as $expr1] }
      └─BatchFilter { predicate: (IsNotNull(ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) OR In(Lower(bid.channel), 'apple':Varchar, 'google':Varchar, 'facebook':Varchar, 'baidu':Varchar)) }
        └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, channel_id, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, Case((Lower(bid.channel) = 'apple':Varchar), '0':Varchar, (Lower(bid.channel) = 'google':Varchar), '1':Varchar, (Lower(bid.channel) = 'facebook':Varchar), '2':Varchar, (Lower(bid.channel) = 'baidu':Varchar), '3':Varchar, ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) as $expr1, bid._row_id] }
      └─StreamFilter { predicate: (IsNotNull(ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) OR In(Lower(bid.channel), 'apple':Varchar, 'google':Varchar, 'facebook':Varchar, 'baidu':Varchar)) }
        └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, channel_id, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, Case((Lower(bid.channel) = 'apple':Varchar), '0':Varchar, (Lower(bid.channel) = 'google':Varchar), '1':Varchar, (Lower(bid.channel) = 'facebook':Varchar), '2':Varchar, (Lower(bid.channel) = 'baidu':Varchar), '3':Varchar, ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) as $expr1, bid._row_id] }
        └── StreamFilter { predicate: (IsNotNull(ArrayAccess(RegexpMatch(bid.url, '(&|^)channel_id=([^&]*)':Varchar), 2:Int32)) OR In(Lower(bid.channel), 'apple':Varchar, 'google':Varchar, 'facebook':Varchar, 'baidu':Varchar)) }
            └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) } { tables: [ StreamScan: 0 ] }
                ├── Upstream
                └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, channel_id, bid._row_id, _rw_timestamp ], primary key: [ $5 ASC ], value indices: [ 0, 1, 2, 3, 4, 5 ], distribution key: [ 5 ], read pk prefix len hint: 1 }

- id: nexmark_q22
  before:
  - create_tables
  sql: |
    SELECT
        auction, bidder, price, channel,
        SPLIT_PART(url, '/', 4) as dir1,
        SPLIT_PART(url, '/', 5) as dir2,
        SPLIT_PART(url, '/', 6) as dir3 FROM bid;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3] }
      └─BatchScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url], distribution: SomeShard }
  sink_plan: |-
    StreamSink { type: append-only, columns: [auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id(hidden)] }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_plan: |-
    StreamMaterialize { columns: [auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck }
    └─StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
      └─StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id(hidden)], stream_key: [bid._row_id], pk_columns: [bid._row_id], pk_conflict: NoCheck } { tables: [ Materialize: 4294967294 ] }
    └── StreamProject { exprs: [bid.auction, bid.bidder, bid.price, bid.channel, SplitPart(bid.url, '/':Varchar, 4:Int32) as $expr1, SplitPart(bid.url, '/':Varchar, 5:Int32) as $expr2, SplitPart(bid.url, '/':Varchar, 6:Int32) as $expr3, bid._row_id] }
        └── StreamTableScan { table: bid, columns: [bid.auction, bid.bidder, bid.price, bid.channel, bid.url, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
            ├── tables: [ StreamScan: 0 ]
            ├── Upstream
            └── BatchPlanNode

    Table 0 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ auction, bidder, price, channel, dir1, dir2, dir3, bid._row_id, _rw_timestamp ], primary key: [ $7 ASC ], value indices: [ 0, 1, 2, 3, 4, 5, 6, 7 ], distribution key: [ 7 ], read pk prefix len hint: 1 }

- id: nexmark_q101
  before:
  - create_tables
  sql: |
    -- A self-made query that covers outer join.
    --
    -- Monitor ongoing auctions and track the current highest bid for each one in real-time. If
    -- the auction has no bids, the highest bid will be NULL.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        b.max_price AS current_highest_bid
    FROM auction a
    LEFT OUTER JOIN (
        SELECT
            b1.auction,
            MAX(b1.price) max_price
        FROM bid b1
        GROUP BY b1.auction
    ) b ON a.id = b.auction;
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price)] }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchHashAgg { group_key: [bid.auction], aggs: [max(bid.price)] }
        └─BatchExchange { order: [], dist: HashShard(bid.auction) }
          └─BatchScan { table: bid, columns: [bid.auction, bid.price], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction_id, auction_item_name, current_highest_bid, bid.auction(hidden)], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(auction.id) }
      └─StreamHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price), bid.auction] }
        ├─StreamExchange { dist: HashShard(auction.id) }
        │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
        └─StreamProject { exprs: [bid.auction, max(bid.price)] }
          └─StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [max(bid.price), count] }
            └─StreamExchange { dist: HashShard(bid.auction) }
              └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, current_highest_bid, bid.auction(hidden)], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamHashJoin { type: LeftOuter, predicate: auction.id = bid.auction, output: [auction.id, auction.item_name, max(bid.price), bid.auction] }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([0]) from 2
    └── StreamProject { exprs: [bid.auction, max(bid.price)] }
        └── StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [max(bid.price), count] } { tables: [ HashAggState: 5 ] }
            └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 4 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 6 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ bid_auction, max(bid_price), _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4
    ├── columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 5 { columns: [ bid_auction, max(bid_price), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name, current_highest_bid, bid.auction, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q102
  before:
  - create_tables
  sql: |
    -- A self-made query that covers dynamic filter.
    --
    -- Show the auctions whose count of bids is greater than the overall average count of bids
    -- per auction.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        COUNT(b.auction) AS bid_count
    FROM auction a
    JOIN bid b ON a.id = b.auction
    GROUP BY a.id, a.item_name
    HAVING COUNT(b.auction) >= (
        SELECT COUNT(*) / COUNT(DISTINCT auction) FROM bid
    )
  batch_plan: |-
    BatchNestedLoopJoin { type: Inner, predicate: (count(bid.auction) >= $expr1), output: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
    ├─BatchExchange { order: [], dist: Single }
    │ └─BatchHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction)] }
    │   └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
    │     ├─BatchExchange { order: [], dist: HashShard(auction.id) }
    │     │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
    │     └─BatchExchange { order: [], dist: HashShard(bid.auction) }
    │       └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
    └─BatchProject { exprs: [(sum0(sum0(count)) / sum0(count(bid.auction))) as $expr1] }
      └─BatchSimpleAgg { aggs: [sum0(sum0(count)), sum0(count(bid.auction))] }
        └─BatchExchange { order: [], dist: Single }
          └─BatchSimpleAgg { aggs: [sum0(count), count(bid.auction)] }
            └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
              └─BatchExchange { order: [], dist: HashShard(bid.auction) }
                └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    └─StreamDynamicFilter { predicate: (count(bid.auction) >= $expr1), output: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
      ├─StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
      │ └─StreamHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction), count] }
      │   └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
      │     ├─StreamExchange { dist: HashShard(auction.id) }
      │     │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
      │     └─StreamExchange { dist: HashShard(bid.auction) }
      │       └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
      └─StreamExchange { dist: Broadcast }
        └─StreamProject { exprs: [(sum0(sum0(count)) / sum0(count(bid.auction))) as $expr1] }
          └─StreamSimpleAgg { aggs: [sum0(sum0(count)), sum0(count(bid.auction)), count] }
            └─StreamExchange { dist: Single }
              └─StreamStatelessSimpleAgg { aggs: [sum0(count), count(bid.auction)] }
                └─StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] }
                  └─StreamExchange { dist: HashShard(bid.auction) }
                    └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamDynamicFilter { predicate: (count(bid.auction) >= $expr1), output: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
        ├── tables: [ DynamicFilterLeft: 0, DynamicFilterRight: 1 ]
        ├── StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
        │   └── StreamHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction), count] }
        │       ├── tables: [ HashAggState: 2 ]
        │       └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
        │           ├── tables: [ HashJoinLeft: 3, HashJoinDegreeLeft: 4, HashJoinRight: 5, HashJoinDegreeRight: 6 ]
        │           ├── StreamExchange Hash([0]) from 1
        │           └── StreamExchange Hash([0]) from 2
        └── StreamExchange Broadcast from 3

    Fragment 1
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 7 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 2
    StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 8 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamProject { exprs: [(sum0(sum0(count)) / sum0(count(bid.auction))) as $expr1] }
    └── StreamSimpleAgg { aggs: [sum0(sum0(count)), sum0(count(bid.auction)), count] } { tables: [ SimpleAggState: 9 ] }
        └── StreamExchange Single from 4

    Fragment 4
    StreamStatelessSimpleAgg { aggs: [sum0(count), count(bid.auction)] }
    └── StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] } { tables: [ HashAggState: 10 ] }
        └── StreamExchange Hash([0]) from 5

    Fragment 5
    StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 11 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ auction_id, internal_last_seen_value(auction_item_name), count(bid_auction), _rw_timestamp ]
    ├── primary key: [ $2 ASC, $0 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 1 { columns: [ $expr1, _rw_timestamp ], primary key: [], value indices: [ 0 ], distribution key: [], read pk prefix len hint: 0 }

    Table 2
    ├── columns: [ auction_id, internal_last_seen_value(auction_item_name), count(bid_auction), count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 3 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7
    ├── columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 8
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 9 { columns: [ sum0(sum0(count)), sum0(count(bid_auction)), count, _rw_timestamp ], primary key: [], value indices: [ 0, 1, 2 ], distribution key: [], read pk prefix len hint: 0 }

    Table 10 { columns: [ bid_auction, count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 11
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name, bid_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

- id: nexmark_q103
  before:
  - create_tables
  sql: |
    -- A self-made query that covers semi join.
    --
    -- Show the auctions that have at least 20 bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name
    FROM auction a
    WHERE a.id IN (
        SELECT b.auction FROM bid b
        GROUP BY b.auction
        HAVING COUNT(*) >= 20
    );
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchProject { exprs: [bid.auction] }
        └─BatchFilter { predicate: (count >= 20:Int32) }
          └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(auction.id) }
      └─StreamHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
        ├─StreamExchange { dist: HashShard(auction.id) }
        │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
        └─StreamProject { exprs: [bid.auction] }
          └─StreamFilter { predicate: (count >= 20:Int32) }
            └─StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] }
              └─StreamExchange { dist: HashShard(bid.auction) }
                └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamHashJoin { type: LeftSemi, predicate: auction.id = bid.auction, output: all }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([0]) from 2
    └── StreamProject { exprs: [bid.auction] }
        └── StreamFilter { predicate: (count >= 20:Int32) }
            └── StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] } { tables: [ HashAggState: 5 ] }
                └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 4 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 6 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ bid_auction, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4
    ├── columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 5 { columns: [ bid_auction, count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q104
  before:
  - create_tables
  sql: |
    -- A self-made query that covers anti join.
    --
    -- This is the same as q103, which shows the auctions that have at least 20 bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name
    FROM auction a
    WHERE a.id NOT IN (
        SELECT b.auction FROM bid b
        GROUP BY b.auction
        HAVING COUNT(*) < 20
    );
  batch_plan: |-
    BatchExchange { order: [], dist: Single }
    └─BatchHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
      ├─BatchExchange { order: [], dist: HashShard(auction.id) }
      │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
      └─BatchProject { exprs: [bid.auction] }
        └─BatchFilter { predicate: (count < 20:Int32) }
          └─BatchHashAgg { group_key: [bid.auction], aggs: [count] }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(auction.id) }
      └─StreamHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
        ├─StreamExchange { dist: HashShard(auction.id) }
        │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
        └─StreamProject { exprs: [bid.auction] }
          └─StreamFilter { predicate: (count < 20:Int32) }
            └─StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] }
              └─StreamExchange { dist: HashShard(bid.auction) }
                └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name], stream_key: [auction_id], pk_columns: [auction_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([0]) from 1

    Fragment 1
    StreamHashJoin { type: LeftAnti, predicate: auction.id = bid.auction, output: all }
    ├── tables: [ HashJoinLeft: 0, HashJoinDegreeLeft: 1, HashJoinRight: 2, HashJoinDegreeRight: 3 ]
    ├── StreamExchange Hash([0]) from 2
    └── StreamProject { exprs: [bid.auction] }
        └── StreamFilter { predicate: (count < 20:Int32) }
            └── StreamHashAgg [append_only] { group_key: [bid.auction], aggs: [count] } { tables: [ HashAggState: 5 ] }
                └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 4 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 6 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 1 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 2 { columns: [ bid_auction, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 3 { columns: [ bid_auction, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4
    ├── columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 5 { columns: [ bid_auction, count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

- id: nexmark_q105
  before:
  - create_tables
  sql: |
    -- A self-made query that covers singleton top-n (and local-phase group top-n).
    --
    -- Show the top 1000 auctions by the number of bids.
    SELECT
        a.id AS auction_id,
        a.item_name AS auction_item_name,
        COUNT(b.auction) AS bid_count
    FROM auction a
    JOIN bid b ON a.id = b.auction
    GROUP BY a.id, a.item_name
    ORDER BY bid_count DESC
    LIMIT 1000;
  batch_plan: |-
    BatchTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0 }
    └─BatchExchange { order: [], dist: Single }
      └─BatchTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0 }
        └─BatchHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction)] }
          └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
            ├─BatchExchange { order: [], dist: HashShard(auction.id) }
            │ └─BatchScan { table: auction, columns: [auction.id, auction.item_name], distribution: UpstreamHashShard(auction.id) }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id], pk_columns: [bid_count, auction_id], pk_conflict: NoCheck }
    └─StreamExchange { dist: HashShard(count(bid.auction)) }
      └─StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
        └─StreamTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0 }
          └─StreamExchange { dist: Single }
            └─StreamGroupTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0, group_key: [$expr1] }
              └─StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction), Vnode(auction.id) as $expr1] }
                └─StreamHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction), count] }
                  └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                    ├─StreamExchange { dist: HashShard(auction.id) }
                    │ └─StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
                    └─StreamExchange { dist: HashShard(bid.auction) }
                      └─StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [auction_id, auction_item_name, bid_count], stream_key: [auction_id], pk_columns: [bid_count, auction_id], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamExchange Hash([2]) from 1

    Fragment 1
    StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction)] }
    └── StreamTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0 } { tables: [ TopN: 0 ] }
        └── StreamExchange Single from 2

    Fragment 2
    StreamGroupTopN { order: [count(bid.auction) DESC], limit: 1000, offset: 0, group_key: [$expr1] } { tables: [ GroupTopN: 1 ] }
    └── StreamProject { exprs: [auction.id, internal_last_seen_value(auction.item_name), count(bid.auction), Vnode(auction.id) as $expr1] }
        └── StreamHashAgg { group_key: [auction.id], aggs: [internal_last_seen_value(auction.item_name), count(bid.auction), count] }
            ├── tables: [ HashAggState: 2 ]
            └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                ├── tables: [ HashJoinLeft: 3, HashJoinDegreeLeft: 4, HashJoinRight: 5, HashJoinDegreeRight: 6 ]
                ├── StreamExchange Hash([0]) from 3
                └── StreamExchange Hash([0]) from 4

    Fragment 3
    StreamTableScan { table: auction, columns: [auction.id, auction.item_name], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 7 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 4
    StreamTableScan { table: bid, columns: [bid.auction, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 8 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0
    ├── columns: [ auction_id, internal_last_seen_value(auction_item_name), count(bid_auction), $expr1, _rw_timestamp ]
    ├── primary key: [ $2 DESC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: []
    └── read pk prefix len hint: 0

    Table 1
    ├── columns: [ auction_id, internal_last_seen_value(auction_item_name), count(bid_auction), $expr1, _rw_timestamp ]
    ├── primary key: [ $3 ASC, $2 DESC, $0 ASC ]
    ├── value indices: [ 0, 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 3

    Table 2
    ├── columns: [ auction_id, internal_last_seen_value(auction_item_name), count(bid_auction), count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    └── read pk prefix len hint: 1

    Table 3 { columns: [ auction_id, auction_item_name, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 4 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ bid_auction, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7
    ├── columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 8
    ├── columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ]
    ├── primary key: [ $0 ASC ]
    ├── value indices: [ 1, 2, 3 ]
    ├── distribution key: [ 0 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 4294967294
    ├── columns: [ auction_id, auction_item_name, bid_count, _rw_timestamp ]
    ├── primary key: [ $2 DESC, $0 ASC ]
    ├── value indices: [ 0, 1, 2 ]
    ├── distribution key: [ 2 ]
    └── read pk prefix len hint: 2

- id: nexmark_q106
  before:
  - create_tables
  sql: |
    -- A self-made query that covers two-phase stateful simple aggregation.
    --
    -- Show the minimum final price of all auctions.
    SELECT
        MIN(final) AS min_final
    FROM
        (
            SELECT
                auction.id,
                MAX(price) AS final
            FROM
                auction,
                bid
            WHERE
                bid.auction = auction.id
                AND bid.date_time BETWEEN auction.date_time AND auction.expires
            GROUP BY
                auction.id
        )
  batch_plan: |-
    BatchSimpleAgg { aggs: [min(min(max(bid.price)))] }
    └─BatchExchange { order: [], dist: Single }
      └─BatchSimpleAgg { aggs: [min(max(bid.price))] }
        └─BatchHashAgg { group_key: [auction.id], aggs: [max(bid.price)] }
          └─BatchHashJoin { type: Inner, predicate: auction.id = bid.auction AND (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires), output: [auction.id, bid.price] }
            ├─BatchExchange { order: [], dist: HashShard(auction.id) }
            │ └─BatchScan { table: auction, columns: [auction.id, auction.date_time, auction.expires], distribution: UpstreamHashShard(auction.id) }
            └─BatchExchange { order: [], dist: HashShard(bid.auction) }
              └─BatchScan { table: bid, columns: [bid.auction, bid.price, bid.date_time], distribution: SomeShard }
  stream_plan: |-
    StreamMaterialize { columns: [min_final], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    └─StreamProject { exprs: [min(min(max(bid.price)))] }
      └─StreamSimpleAgg { aggs: [min(min(max(bid.price))), count] }
        └─StreamExchange { dist: Single }
          └─StreamHashAgg { group_key: [$expr1], aggs: [min(max(bid.price)), count] }
            └─StreamProject { exprs: [auction.id, max(bid.price), Vnode(auction.id) as $expr1] }
              └─StreamHashAgg { group_key: [auction.id], aggs: [max(bid.price), count] }
                └─StreamProject { exprs: [auction.id, bid.price, bid._row_id] }
                  └─StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └─StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                      ├─StreamExchange { dist: HashShard(auction.id) }
                      │ └─StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
                      └─StreamExchange { dist: HashShard(bid.auction) }
                        └─StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
  stream_dist_plan: |+
    Fragment 0
    StreamMaterialize { columns: [min_final], stream_key: [], pk_columns: [], pk_conflict: NoCheck }
    ├── tables: [ Materialize: 4294967294 ]
    └── StreamProject { exprs: [min(min(max(bid.price)))] }
        └── StreamSimpleAgg { aggs: [min(min(max(bid.price))), count] }
            ├── tables: [ SimpleAggState: 1, SimpleAggCall0: 0 ]
            └── StreamExchange Single from 1

    Fragment 1
    StreamHashAgg { group_key: [$expr1], aggs: [min(max(bid.price)), count] }
    ├── tables: [ HashAggState: 3, HashAggCall0: 2 ]
    └── StreamProject { exprs: [auction.id, max(bid.price), Vnode(auction.id) as $expr1] }
        └── StreamHashAgg { group_key: [auction.id], aggs: [max(bid.price), count] }
            ├── tables: [ HashAggState: 5, HashAggCall0: 4 ]
            └── StreamProject { exprs: [auction.id, bid.price, bid._row_id] }
                └── StreamFilter { predicate: (bid.date_time >= auction.date_time) AND (bid.date_time <= auction.expires) }
                    └── StreamHashJoin { type: Inner, predicate: auction.id = bid.auction, output: all }
                        ├── tables: [ HashJoinLeft: 6, HashJoinDegreeLeft: 7, HashJoinRight: 8, HashJoinDegreeRight: 9 ]
                        ├── StreamExchange Hash([0]) from 2
                        └── StreamExchange Hash([0]) from 3

    Fragment 2
    StreamTableScan { table: auction, columns: [auction.id, auction.date_time, auction.expires], stream_scan_type: ArrangementBackfill, stream_key: [auction.id], pk: [id], dist: UpstreamHashShard(auction.id) }
    ├── tables: [ StreamScan: 10 ]
    ├── Upstream
    └── BatchPlanNode

    Fragment 3
    StreamTableScan { table: bid, columns: [bid.auction, bid.price, bid.date_time, bid._row_id], stream_scan_type: ArrangementBackfill, stream_key: [bid._row_id], pk: [_row_id], dist: UpstreamHashShard(bid._row_id) }
    ├── tables: [ StreamScan: 11 ]
    ├── Upstream
    └── BatchPlanNode

    Table 0 { columns: [ min(max(bid_price)), $expr1, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 0, 1 ], distribution key: [], read pk prefix len hint: 0 }

    Table 1 { columns: [ min(min(max(bid_price))), count, _rw_timestamp ], primary key: [], value indices: [ 0, 1 ], distribution key: [], read pk prefix len hint: 0 }

    Table 2
    ├── columns: [ $expr1, max(bid_price), auction_id, _rw_timestamp ]
    ├── primary key: [ $0 ASC, $1 ASC, $2 ASC ]
    ├── value indices: [ 1, 2 ]
    ├── distribution key: [ 2 ]
    ├── read pk prefix len hint: 1
    └── vnode column idx: 0

    Table 3 { columns: [ $expr1, min(max(bid_price)), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4 { columns: [ auction_id, bid_price, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $1 DESC, $2 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 5 { columns: [ auction_id, max(bid_price), count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 6 { columns: [ auction_id, auction_date_time, auction_expires, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 0, 1, 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 7 { columns: [ auction_id, _degree, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 8 { columns: [ bid_auction, bid_price, bid_date_time, bid__row_id, _rw_timestamp ], primary key: [ $0 ASC, $3 ASC ], value indices: [ 0, 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 9 { columns: [ bid_auction, bid__row_id, _degree, _rw_timestamp ], primary key: [ $0 ASC, $1 ASC ], value indices: [ 2 ], distribution key: [ 0 ], read pk prefix len hint: 1 }

    Table 10 { columns: [ vnode, id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 11 { columns: [ vnode, _row_id, backfill_finished, row_count, _rw_timestamp ], primary key: [ $0 ASC ], value indices: [ 1, 2, 3 ], distribution key: [ 0 ], read pk prefix len hint: 1, vnode column idx: 0 }

    Table 4294967294 { columns: [ min_final, _rw_timestamp ], primary key: [], value indices: [ 0 ], distribution key: [], read pk prefix len hint: 0 }

