- sql: |
    create table t (v1 int, v2 int, v3 int);
    select v1, min(v2), count(distinct v3) as agg from t group by v1;
  expected_outputs:
    - stream_plan
    - eowc_stream_error
- sql: |
    create source t (v1 int, v2 int, v3 int, watermark for v1 as v1 - 10) with (connector = 'kinesis') ROW FORMAT JSON;
    select v1, min(v2), count(distinct v3) as agg from t group by v1;
  expected_outputs:
    - stream_plan
    - eowc_stream_dist_plan
    - eowc_stream_plan
- sql: |
    CREATE TABLE t (a TIMESTAMP, b INT, WATERMARK FOR a AS a - INTERVAL '5 minutes') APPEND ONLY;
    SELECT
        window_start, max(b)
    FROM tumble(t, a, INTERVAL '1 hour')
    GROUP BY window_start;
  expected_outputs:
    - eowc_stream_dist_plan
    - eowc_stream_plan
    - stream_plan
- sql: |
    create source t (a int, b int, tm timestamp, watermark for tm as tm - interval '5 minutes') with (connector = 'kinesis') ROW FORMAT JSON;
    select lag(a, 2) over (partition by b order by tm) from t;
  expected_outputs:
    - eowc_stream_dist_plan
    - eowc_stream_plan
- sql: |
    create table t (tm timestamp, foo int, bar int, watermark for tm as tm - interval '5 minutes') append only;
    explain create sink s1 emit on window close as select
      tm, foo, bar,
      lag(foo, 2) over (partition by bar order by tm),
      max(foo) over (partition by bar order by tm rows between 1 preceding and 1 following),
      sum(foo) over (partition by bar order by tm rows 2 preceding exclude current row)
      from t WITH (connector = 'blackhole');
  expected_outputs:
    - explain_output
  