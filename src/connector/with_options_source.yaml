# THIS FILE IS AUTO_GENERATED. DO NOT EDIT
# UPDATE WITH: ./risedev generate-with-options

AzblobProperties:
  fields:
  - name: azblob.container_name
    field_type: String
    required: true
  - name: azblob.credentials.account_name
    field_type: String
    required: false
    default: Default::default
  - name: azblob.credentials.account_key
    field_type: String
    required: false
    default: Default::default
  - name: azblob.endpoint_url
    field_type: String
    required: true
  - name: match_pattern
    field_type: String
    required: false
    default: Default::default
  - name: refresh.interval.sec
    field_type: u64
    required: false
  - name: compression_format
    field_type: CompressionFormat
    required: false
    default: Default::default
DatagenProperties:
  fields:
  - name: datagen.split.num
    field_type: String
    comments: split_num means data source partition
    required: false
  - name: datagen.rows.per.second
    field_type: u64
    comments: |-
      default_rows_per_second =10
      when the split_num = 3 and default_rows_per_second =10
      there will be three readers that generate respectively 4,3,3 message per second
    required: false
    default: '10'
  - name: fields
    field_type: HashMap<String,String>
    comments: |-
      Some connector options of the datagen source's fields
      for example: create datagen source with column v1 int, v2 float
      'fields.v1.kind'='sequence',
      'fields.v1.start'='1',
      'fields.v1.end'='1000',
      'fields.v2.kind'='random',
      datagen will create v1 by self-incrementing from 1 to 1000
      datagen will create v2 by randomly generating from default_min to default_max
    required: false
GcsProperties:
  fields:
  - name: gcs.bucket_name
    field_type: String
    required: true
  - name: gcs.credential
    field_type: String
    comments: The base64 encoded credential key. If not set, ADC will be used.
    required: false
  - name: gcs.service_account
    field_type: String
    comments: If credential/ADC is not set. The service account can be used to provide the credential info.
    required: false
    default: Default::default
  - name: match_pattern
    field_type: String
    required: false
    default: Default::default
  - name: refresh.interval.sec
    field_type: u64
    required: false
  - name: compression_format
    field_type: CompressionFormat
    required: false
    default: Default::default
IcebergProperties:
  fields:
  - name: catalog.type
    field_type: String
    required: false
  - name: s3.region
    field_type: String
    required: false
  - name: s3.endpoint
    field_type: String
    required: false
  - name: s3.access.key
    field_type: String
    required: false
  - name: s3.secret.key
    field_type: String
    required: false
  - name: gcs.credential
    field_type: String
    required: false
  - name: warehouse.path
    field_type: String
    comments: Path of iceberg warehouse, only applicable in storage catalog.
    required: false
  - name: glue.id
    field_type: String
    comments: |-
      AWS Client id, can be omitted for storage catalog or when
      caller's AWS account ID matches glue id
    required: false
  - name: catalog.name
    field_type: String
    comments: |-
      Catalog name, can be omitted for storage catalog, but
      must be set for other catalogs.
    required: false
  - name: catalog.uri
    field_type: String
    comments: URI of iceberg catalog, only applicable in rest catalog.
    required: false
  - name: database.name
    field_type: String
    required: false
  - name: table.name
    field_type: String
    comments: Full name of table, must include schema name.
    required: true
  - name: catalog.credential
    field_type: String
    comments: |-
      Credential for accessing iceberg catalog, only applicable in rest catalog.
      A credential to exchange for a token in the OAuth2 client credentials flow.
    required: false
  - name: catalog.token
    field_type: String
    comments: |-
      token for accessing iceberg catalog, only applicable in rest catalog.
      A Bearer token which will be used for interaction with the server.
    required: false
  - name: catalog.oauth2-server-uri
    field_type: String
    comments: |-
      `oauth2-server-uri` for accessing iceberg catalog, only applicable in rest catalog.
      Token endpoint URI to fetch token from if the Rest Catalog is not the authorization server.
    required: false
  - name: catalog.scope
    field_type: String
    comments: |-
      scope for accessing iceberg catalog, only applicable in rest catalog.
      Additional scope for OAuth2.
    required: false
  - name: s3.path.style.access
    field_type: bool
    required: false
    default: Default::default
  - name: enable_config_load
    field_type: bool
    comments: enable config load currently is used by iceberg engine.
    required: false
    default: Default::default
  - name: catalog.jdbc.user
    field_type: String
    required: false
  - name: catalog.jdbc.password
    field_type: String
    required: false
KafkaProperties:
  fields:
  - name: bytes.per.second
    field_type: String
    comments: |-
      This parameter is not intended to be exposed to users.
      This parameter specifies only for one parallelism. The parallelism of kafka source
      is equal to the parallelism passed into compute nodes. So users need to calculate
      how many bytes will be consumed in total across all the parallelism by themselves.
    required: false
    alias:
    - kafka.bytes.per.second
  - name: max.num.messages
    field_type: String
    comments: |-
      This parameter is not intended to be exposed to users.
      This parameter specifies only for one parallelism. The parallelism of kafka source
      is equal to the parallelism passed into compute nodes. So users need to calculate
      how many messages will be consumed in total across all the parallelism by themselves.
    required: false
    alias:
    - kafka.max.num.messages
  - name: scan.startup.mode
    field_type: String
    required: false
    alias:
    - kafka.scan.startup.mode
  - name: scan.startup.timestamp.millis
    field_type: String
    required: false
    alias:
    - kafka.time.offset
    - scan.startup.timestamp_millis
  - name: group.id.prefix
    field_type: String
    comments: |-
      Specify a custom consumer group id prefix for the source.
      Defaults to `rw-consumer`.

      Notes:
      - Each job (materialized view) will have a separated consumer group and
      contains a generated suffix in the group id.
      The consumer group will be `{group_id_prefix}-{fragment_id}`.
      - The consumer group is solely for monintoring progress in some external
      Kafka tools, and for authorization. RisingWave does not rely on committed
      offsets, and does not join the consumer group. It just reports offsets
      to the group.
    required: false
  - name: upsert
    field_type: String
    comments: |-
      This parameter is used to tell `KafkaSplitReader` to produce `UpsertMessage`s, which
      combine both key and value fields of the Kafka message.
      TODO: Currently, `Option<bool>` can not be parsed here.
    required: false
  - name: topic
    field_type: String
    required: true
    alias:
    - kafka.topic
  - name: properties.sync.call.timeout
    field_type: Duration
    required: false
    default: 'Duration :: from_secs (5)'
  - name: properties.bootstrap.server
    field_type: String
    required: true
    alias:
    - kafka.brokers
  - name: properties.security.protocol
    field_type: String
    comments: |-
      Security protocol used for RisingWave to communicate with Kafka brokers. Could be
      PLAINTEXT, SSL, SASL_PLAINTEXT or SASL_SSL.
    required: false
  - name: properties.ssl.endpoint.identification.algorithm
    field_type: String
    required: false
  - name: properties.ssl.ca.location
    field_type: String
    comments: Path to CA certificate file for verifying the broker's key.
    required: false
  - name: properties.ssl.ca.pem
    field_type: String
    comments: CA certificate string (PEM format) for verifying the broker's key.
    required: false
  - name: properties.ssl.certificate.location
    field_type: String
    comments: Path to client's certificate file (PEM).
    required: false
  - name: properties.ssl.certificate.pem
    field_type: String
    comments: Client's public key string (PEM format) used for authentication.
    required: false
  - name: properties.ssl.key.location
    field_type: String
    comments: Path to client's private key file (PEM).
    required: false
  - name: properties.ssl.key.pem
    field_type: String
    comments: Client's private key string (PEM format) used for authentication.
    required: false
  - name: properties.ssl.key.password
    field_type: String
    comments: Passphrase of client's private key.
    required: false
  - name: properties.sasl.mechanism
    field_type: String
    comments: SASL mechanism if SASL is enabled. Currently support PLAIN, SCRAM, GSSAPI, and AWS_MSK_IAM.
    required: false
  - name: properties.sasl.username
    field_type: String
    comments: SASL username for SASL/PLAIN and SASL/SCRAM.
    required: false
  - name: properties.sasl.password
    field_type: String
    comments: SASL password for SASL/PLAIN and SASL/SCRAM.
    required: false
  - name: properties.sasl.kerberos.service.name
    field_type: String
    comments: Kafka server's Kerberos principal name under SASL/GSSAPI, not including /hostname@REALM.
    required: false
  - name: properties.sasl.kerberos.keytab
    field_type: String
    comments: Path to client's Kerberos keytab file under SASL/GSSAPI.
    required: false
  - name: properties.sasl.kerberos.principal
    field_type: String
    comments: Client's Kerberos principal name under SASL/GSSAPI.
    required: false
  - name: properties.sasl.kerberos.kinit.cmd
    field_type: String
    comments: Shell command to refresh or acquire the client's Kerberos ticket under SASL/GSSAPI.
    required: false
  - name: properties.sasl.kerberos.min.time.before.relogin
    field_type: String
    comments: Minimum time in milliseconds between key refresh attempts under SASL/GSSAPI.
    required: false
  - name: properties.sasl.oauthbearer.config
    field_type: String
    comments: Configurations for SASL/OAUTHBEARER.
    required: false
  - name: properties.message.max.bytes
    field_type: usize
    comments: |-
      Maximum Kafka protocol request message size. Due to differing framing overhead between
      protocol versions the producer is unable to reliably enforce a strict max message limit at
      produce time and may exceed the maximum size by one message in protocol ProduceRequests,
      the broker will enforce the topic's max.message.bytes limit
    required: false
  - name: properties.receive.message.max.bytes
    field_type: usize
    comments: |-
      Maximum Kafka protocol response message size. This serves as a safety precaution to avoid
      memory exhaustion in case of protocol hickups. This value must be at least fetch.max.bytes
      + 512 to allow for protocol overhead; the value is adjusted automatically unless the
      configuration property is explicitly set.
    required: false
  - name: properties.statistics.interval.ms
    field_type: usize
    required: false
  - name: properties.client.id
    field_type: String
    comments: Client identifier
    required: false
  - name: properties.enable.ssl.certificate.verification
    field_type: bool
    required: false
  - name: properties.queued.min.messages
    field_type: usize
    comments: |-
      Minimum number of messages per topic+partition librdkafka tries to maintain in the local
      consumer queue.
    required: false
  - name: properties.queued.max.messages.kbytes
    field_type: usize
    required: false
  - name: properties.fetch.wait.max.ms
    field_type: usize
    comments: |-
      Maximum time the broker may wait to fill the Fetch response with `fetch.min.`bytes of
      messages.
    required: false
  - name: properties.fetch.queue.backoff.ms
    field_type: usize
    comments: |-
      How long to postpone the next fetch request for a topic+partition in case the current fetch
      queue thresholds (`queued.min.messages` or `queued.max.messages.kbytes`) have been
      exceeded. This property may need to be decreased if the queue thresholds are set low
      and the application is experiencing long (~1s) delays between messages. Low values may
      increase CPU utilization.
    required: false
  - name: properties.fetch.max.bytes
    field_type: usize
    comments: |-
      Maximum amount of data the broker shall return for a Fetch request. Messages are fetched in
      batches by the consumer and if the first message batch in the first non-empty partition of
      the Fetch request is larger than this value, then the message batch will still be returned
      to ensure the consumer can make progress. The maximum message batch size accepted by the
      broker is defined via `message.max.bytes` (broker config) or `max.message.bytes` (broker
      topic config). `fetch.max.bytes` is automatically adjusted upwards to be at least
      `message.max.bytes` (consumer config).
    required: false
  - name: properties.enable.auto.commit
    field_type: bool
    comments: |-
      Whether to automatically and periodically commit offsets in the background.

      Note that RisingWave does NOT rely on committed offsets. Committing offset is only for exposing the
      progress for monitoring. Setting this to false can avoid creating consumer groups.

      default: true
    required: false
  - name: broker.rewrite.endpoints
    field_type: BTreeMap<String,String>
    comments: This is generated from `private_link_targets` and `private_link_endpoint` in frontend, instead of given by users.
    required: false
  - name: aws.region
    field_type: String
    required: false
    alias:
    - region
    - s3.region
  - name: aws.endpoint_url
    field_type: String
    required: false
    alias:
    - endpoint_url
    - endpoint
    - s3.endpoint
  - name: aws.credentials.access_key_id
    field_type: String
    required: false
    alias:
    - access_key
    - s3.access.key
  - name: aws.credentials.secret_access_key
    field_type: String
    required: false
    alias:
    - secret_key
    - s3.secret.key
  - name: aws.credentials.session_token
    field_type: String
    required: false
    alias:
    - session_token
  - name: aws.credentials.role.arn
    field_type: String
    comments: IAM role
    required: false
    alias:
    - arn
  - name: aws.credentials.role.external_id
    field_type: String
    comments: external ID in IAM role trust policy
    required: false
    alias:
    - external_id
  - name: aws.profile
    field_type: String
    required: false
    alias:
    - profile
KinesisProperties:
  fields:
  - name: scan.startup.mode
    field_type: String
    required: false
    alias:
    - kinesis.scan.startup.mode
  - name: scan.startup.timestamp.millis
    field_type: i64
    required: false
  - name: stream
    field_type: String
    required: true
    alias:
    - kinesis.stream.name
  - name: aws.region
    field_type: String
    required: true
    alias:
    - kinesis.stream.region
  - name: endpoint
    field_type: String
    required: false
    alias:
    - kinesis.endpoint
  - name: aws.credentials.access_key_id
    field_type: String
    required: false
    alias:
    - kinesis.credentials.access
  - name: aws.credentials.secret_access_key
    field_type: String
    required: false
    alias:
    - kinesis.credentials.secret
  - name: aws.credentials.session_token
    field_type: String
    required: false
    alias:
    - kinesis.credentials.session_token
  - name: aws.credentials.role.arn
    field_type: String
    required: false
    alias:
    - kinesis.assumerole.arn
  - name: aws.credentials.role.external_id
    field_type: String
    required: false
    alias:
    - kinesis.assumerole.external_id
LegacyS3Properties:
  fields:
  - name: s3.region_name
    field_type: String
    required: true
  - name: s3.bucket_name
    field_type: String
    required: true
  - name: match_pattern
    field_type: String
    required: false
    default: Default::default
  - name: s3.credentials.access
    field_type: String
    required: false
    default: Default::default
  - name: s3.credentials.secret
    field_type: String
    required: false
    default: Default::default
  - name: s3.endpoint_url
    field_type: String
    required: false
  - name: compression_format
    field_type: CompressionFormat
    required: false
    default: Default::default
MongodbCommon:
  fields:
  - name: mongodb.url
    field_type: String
    comments: The URL of MongoDB
    required: true
  - name: collection.name
    field_type: String
    comments: |-
      The collection name where data should be written to or read from. For sinks, the format is
      `db_name.collection_name`. Data can also be written to dynamic collections, see `collection.name.field`
      for more information.
    required: true
MqttProperties:
  fields:
  - name: url
    field_type: String
    comments: |-
      The url of the broker to connect to. e.g. tcp://localhost.
      Must be prefixed with one of either `tcp://`, `mqtt://`, `ssl://`,`mqtts://`,
      to denote the protocol for establishing a connection with the broker.
      `mqtts://`, `ssl://` will use the native certificates if no ca is specified
    required: true
  - name: qos
    field_type: QualityOfService
    comments: |-
      The quality of service to use when publishing messages. Defaults to at_most_once.
      Could be at_most_once, at_least_once or exactly_once
    required: false
  - name: username
    field_type: String
    comments: Username for the mqtt broker
    required: false
  - name: password
    field_type: String
    comments: Password for the mqtt broker
    required: false
  - name: client_prefix
    field_type: String
    comments: |-
      Prefix for the mqtt client id.
      The client id will be generated as `client_prefix`_`actor_id`_`(executor_id|source_id)`. Defaults to risingwave
    required: false
  - name: clean_start
    field_type: bool
    comments: |-
      `clean_start = true` removes all the state from queues & instructs the broker
      to clean all the client state when client disconnects.

      When set `false`, broker will hold the client state and performs pending
      operations on the client when reconnection with same `client_id`
      happens. Local queue state is also held to retransmit packets after reconnection.
    required: false
    default: Default::default
  - name: inflight_messages
    field_type: usize
    comments: The maximum number of inflight messages. Defaults to 100
    required: false
  - name: max_packet_size
    field_type: u32
    comments: The max size of messages received by the MQTT client
    required: false
  - name: tls.client_key
    field_type: String
    comments: Path to CA certificate file for verifying the broker's key.
    required: false
  - name: tls.client_cert
    field_type: String
    comments: |-
      Path to client's certificate file (PEM). Required for client authentication.
      Can be a file path under fs:// or a string with the certificate content.
    required: false
  - name: tls.client_key
    field_type: String
    comments: |-
      Path to client's private key file (PEM). Required for client authentication.
      Can be a file path under fs:// or a string with the private key content.
    required: false
  - name: topic
    field_type: String
    comments: The topic name to subscribe or publish to. When subscribing, it can be a wildcard topic. e.g /topic/#
    required: true
  - name: qos
    field_type: MqttQualityOfService
    comments: |-
      The quality of service to use when publishing messages. Defaults to at_most_once.
      Could be at_most_once, at_least_once or exactly_once
    required: false
NatsProperties:
  fields:
  - name: server_url
    field_type: String
    required: true
  - name: subject
    field_type: String
    required: true
  - name: connect_mode
    field_type: String
    required: true
  - name: username
    field_type: String
    required: false
  - name: password
    field_type: String
    required: false
  - name: jwt
    field_type: String
    required: false
  - name: nkey
    field_type: String
    required: false
  - name: max_bytes
    field_type: i64
    required: false
  - name: max_messages
    field_type: i64
    required: false
  - name: max_messages_per_subject
    field_type: i64
    required: false
  - name: max_consumers
    field_type: i32
    required: false
  - name: max_message_size
    field_type: i32
    required: false
  - name: consumer.deliver_subject
    field_type: String
    required: false
  - name: consumer.name
    field_type: String
    required: false
  - name: consumer.description
    field_type: String
    required: false
  - name: consumer.deliver_policy
    field_type: String
    required: false
  - name: consumer.ack_policy
    field_type: String
    required: false
  - name: consumer.ack_wait.sec
    field_type: u64
    required: false
  - name: consumer.max_deliver
    field_type: i64
    required: false
  - name: consumer.filter_subject
    field_type: String
    required: false
  - name: consumer.filter_subjects
    field_type: Vec<String>
    required: false
    default: Default::default
  - name: consumer.replay_policy
    field_type: String
    required: false
  - name: consumer.rate_limit
    field_type: u64
    required: false
  - name: consumer.sample_frequency
    field_type: u8
    required: false
  - name: consumer.max_waiting
    field_type: i64
    required: false
  - name: consumer.max_ack_pending
    field_type: i64
    required: false
  - name: consumer.headers_only
    field_type: bool
    required: false
  - name: consumer.max_batch
    field_type: i64
    required: false
  - name: consumer.max_bytes
    field_type: i64
    required: false
  - name: consumer.max_expires.sec
    field_type: u64
    required: false
  - name: consumer.inactive_threshold.sec
    field_type: u64
    required: false
  - name: consumer.num.replicas
    field_type: usize
    required: false
    alias:
    - consumer.num_replicas
  - name: consumer.memory_storage
    field_type: bool
    required: false
  - name: consumer.backoff.sec
    field_type: Vec<u64>
    required: false
    default: Default::default
  - name: scan.startup.mode
    field_type: String
    required: false
  - name: scan.startup.timestamp.millis
    field_type: i64
    required: false
    alias:
    - scan.startup.timestamp_millis
  - name: stream
    field_type: String
    required: true
  - name: consumer.durable_name
    field_type: String
    required: true
NexmarkProperties:
  fields:
  - name: nexmark.split.num
    field_type: i32
    required: false
    default: identity_i32::<1>
  - name: nexmark.event.num
    field_type: u64
    comments: The total event count of Bid + Auction + Person
    required: false
    default: 'u64 :: MAX'
  - name: nexmark.table.type
    field_type: EventType
    required: false
    default: None
  - name: nexmark.max.chunk.size
    field_type: u64
    required: false
    default: identity_u64::<1024>
  - name: nexmark.use.real.time
    field_type: bool
    comments: The event time gap will be like the time gap in the generated data, default false
    required: false
    default: Default::default
  - name: nexmark.min.event.gap.in.ns
    field_type: u64
    comments: Minimal gap between two events, default 100000, so that the default max throughput is 10000
    required: false
    default: identity_u64::<100_000>
  - name: nexmark.active.people
    field_type: usize
    required: false
    default: None
  - name: nexmark.in.flight.auctions
    field_type: usize
    required: false
    default: None
  - name: nexmark.out.of.order.group.size
    field_type: usize
    required: false
    default: None
  - name: nexmark.avg.person.byte.size
    field_type: usize
    required: false
    default: None
  - name: nexmark.avg.auction.byte.size
    field_type: usize
    required: false
    default: None
  - name: nexmark.avg.bid.byte.size
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.seller.ratio
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.auction.ratio
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.bidder.ratio
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.channel.ratio
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.event.id
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.event.number
    field_type: usize
    required: false
    default: None
  - name: nexmark.num.categories
    field_type: usize
    required: false
    default: None
  - name: nexmark.auction.id.lead
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.seller.ratio.2
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.auction.ratio.2
    field_type: usize
    required: false
    default: None
  - name: nexmark.hot.bidder.ratio.2
    field_type: usize
    required: false
    default: None
  - name: nexmark.person.proportion
    field_type: usize
    required: false
    default: None
  - name: nexmark.auction.proportion
    field_type: usize
    required: false
    default: None
  - name: nexmark.bid.proportion
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.auction.id
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.person.id
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.category.id
    field_type: usize
    required: false
    default: None
  - name: nexmark.person.id.lead
    field_type: usize
    required: false
    default: None
  - name: nexmark.sine.approx.steps
    field_type: usize
    required: false
    default: None
  - name: nexmark.base.time
    field_type: u64
    required: false
    default: None
  - name: nexmark.us.states
    field_type: String
    required: false
  - name: nexmark.us.cities
    field_type: String
    required: false
  - name: nexmark.first.names
    field_type: String
    required: false
  - name: nexmark.last.names
    field_type: String
    required: false
  - name: nexmark.rate.shape
    field_type: RateShape
    required: false
  - name: nexmark.rate.period
    field_type: usize
    required: false
    default: None
  - name: nexmark.first.event.rate
    field_type: usize
    required: false
    default: None
  - name: nexmark.events.per.sec
    field_type: usize
    required: false
    default: None
  - name: nexmark.next.event.rate
    field_type: usize
    required: false
    default: None
  - name: nexmark.us.per.unit
    field_type: usize
    required: false
    default: None
  - name: nexmark.threads
    field_type: usize
    required: false
    default: None
OpendalS3Properties:
  fields:
  - name: s3.region_name
    field_type: String
    required: true
  - name: s3.bucket_name
    field_type: String
    required: true
  - name: match_pattern
    field_type: String
    required: false
    default: Default::default
  - name: s3.credentials.access
    field_type: String
    required: false
    default: Default::default
  - name: s3.credentials.secret
    field_type: String
    required: false
    default: Default::default
  - name: s3.endpoint_url
    field_type: String
    required: false
  - name: compression_format
    field_type: CompressionFormat
    required: false
    default: Default::default
  - name: s3.assume_role
    field_type: String
    comments: The following are only supported by `s3_v2` (opendal) source.
    required: false
    default: Default::default
  - name: refresh.interval.sec
    field_type: u64
    required: false
PosixFsProperties:
  fields:
  - name: posix_fs.root
    field_type: String
    comments: The root directly of the files to search. The files will be searched recursively.
    required: true
  - name: match_pattern
    field_type: String
    comments: The regex pattern to match files under root directory.
    required: false
    default: Default::default
  - name: refresh.interval.sec
    field_type: u64
    required: false
  - name: compression_format
    field_type: CompressionFormat
    required: false
    default: Default::default
PubsubProperties:
  fields:
  - name: pubsub.subscription
    field_type: String
    comments: |-
      Pub/Sub subscription to consume messages from.

      Note that we rely on Pub/Sub to load-balance messages between all Readers pulling from
      the same subscription. So one `subscription` (i.e., one `Source`) can only used for one MV
      (shared between the actors of its fragment).
      Otherwise, different MVs on the same Source will both receive part of the messages.
      TODO: check and enforce this on Meta.
    required: true
  - name: pubsub.emulator_host
    field_type: String
    comments: |-
      use the connector with a pubsub emulator
      <https://cloud.google.com/pubsub/docs/emulator>
    required: false
  - name: pubsub.credentials
    field_type: String
    comments: |-
      `credentials` is a JSON string containing the service account credentials.
      See the [service-account credentials guide](https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account).
      The service account must have the `pubsub.subscriber` [role](https://cloud.google.com/pubsub/docs/access-control#roles).
    required: false
  - name: pubsub.start_offset.nanos
    field_type: String
    comments: |-
      `start_offset` is a numeric timestamp, ideally the publish timestamp of a message
      in the subscription. If present, the connector will attempt to seek the subscription
      to the timestamp and start consuming from there. Note that the seek operation is
      subject to limitations around the message retention policy of the subscription. See
      [Seeking to a timestamp](https://cloud.google.com/pubsub/docs/replay-overview#seeking_to_a_timestamp) for
      more details.
    required: false
  - name: pubsub.start_snapshot
    field_type: String
    comments: |-
      `start_snapshot` is a named pub/sub snapshot. If present, the connector will first seek
      to the snapshot before starting consumption. Snapshots are the preferred seeking mechanism
      in pub/sub because they guarantee retention of:
      - All unacknowledged messages at the time of their creation.
      - All messages created after their creation.
      Besides retention guarantees, snapshots are also more precise than timestamp-based seeks.
      See [Seeking to a snapshot](https://cloud.google.com/pubsub/docs/replay-overview#seeking_to_a_timestamp) for
      more details.
    required: false
  - name: pubsub.parallelism
    field_type: u32
    comments: |-
      `parallelism` is the number of parallel consumers to run for the subscription.
      TODO: use system parallelism if not set
    required: false
PulsarProperties:
  fields:
  - name: scan.startup.mode
    field_type: String
    required: false
    alias:
    - pulsar.scan.startup.mode
  - name: scan.startup.timestamp.millis
    field_type: String
    required: false
    alias:
    - pulsar.time.offset
    - scan.startup.timestamp_millis
  - name: topic
    field_type: String
    required: true
    alias:
    - pulsar.topic
  - name: service.url
    field_type: String
    required: true
    alias:
    - pulsar.service.url
  - name: auth.token
    field_type: String
    required: false
  - name: oauth.issuer.url
    field_type: String
    required: true
  - name: oauth.credentials.url
    field_type: String
    required: true
  - name: oauth.audience
    field_type: String
    required: true
  - name: oauth.scope
    field_type: String
    required: false
  - name: aws.region
    field_type: String
    required: false
    alias:
    - region
    - s3.region
  - name: aws.endpoint_url
    field_type: String
    required: false
    alias:
    - endpoint_url
    - endpoint
    - s3.endpoint
  - name: aws.credentials.access_key_id
    field_type: String
    required: false
    alias:
    - access_key
    - s3.access.key
  - name: aws.credentials.secret_access_key
    field_type: String
    required: false
    alias:
    - secret_key
    - s3.secret.key
  - name: aws.credentials.session_token
    field_type: String
    required: false
    alias:
    - session_token
  - name: aws.credentials.role.arn
    field_type: String
    comments: IAM role
    required: false
    alias:
    - arn
  - name: aws.credentials.role.external_id
    field_type: String
    comments: external ID in IAM role trust policy
    required: false
    alias:
    - external_id
  - name: aws.profile
    field_type: String
    required: false
    alias:
    - profile
  - name: iceberg.enabled
    field_type: bool
    required: false
  - name: iceberg.bucket
    field_type: String
    required: false
    default: Default::default
  - name: subscription.name.prefix
    field_type: String
    comments: |-
      Specify a custom consumer group id prefix for the source.
      Defaults to `rw-consumer`.

      Notes:
      - Each job (materialized view) will have multiple subscriptions and
      contains a generated suffix in the subscription name.
      The subscription name will be `{subscription_name_prefix}-{fragment_id}-{actor_id}`.
    required: false
TestSourceProperties:
  fields:
  - name: properties
    field_type: BTreeMap<String,String>
    required: true
