# Test dynamic source property updates via risectl
# This test covers:
# 1. Update broker address - most critical ops scenario (broker migration)
# 2. Split reset (reset-source-splits) - force split re-discovery
# 3. Offset injection (inject-source-offsets) - UNSAFE offset manipulation

control substitution on

# Setup: Create topic and produce initial data
system ok
rpk topic create test_safe_update

system ok
cat <<EOF | rpk topic produce 'test_safe_update' -f "%v\n"
{"id": 1, "data": "initial"}
{"id": 2, "data": "initial"}
{"id": 3, "data": "initial"}
EOF

# Create source
statement ok
CREATE SOURCE kafka_test_source (id INT, data VARCHAR)
WITH (
    ${RISEDEV_KAFKA_WITH_OPTIONS_COMMON},
    topic = 'test_safe_update',
    scan.startup.mode = 'earliest'
) FORMAT PLAIN ENCODE JSON;

statement ok
CREATE MATERIALIZED VIEW mv_test AS SELECT * FROM kafka_test_source;

# Verify initial consumption
sleep 2s

query I
SELECT COUNT(*) FROM mv_test;
----
3

# Test 1: Update broker address (most critical ops scenario)
# This simulates migrating to a different Kafka cluster
system ok
SOURCE_ID=$(psql -h ${RISEDEV_RW_FRONTEND_LISTEN_ADDRESS} \
    -p ${RISEDEV_RW_FRONTEND_PORT} \
    -d $__DATABASE__ \
    -U root \
    -t -A \
    -c "SELECT id FROM rw_sources WHERE name = 'kafka_test_source'") && \
echo "Updating broker address for Source ID: $SOURCE_ID" && \
./risedev ctl meta alter-source-properties-safe \
    --source-id $SOURCE_ID \
    --props "{\"properties.bootstrap.server\": \"${RISEDEV_KAFKA_BOOTSTRAP_SERVERS}\"}" \
    --reset-splits

# Produce more data after broker update
system ok
cat <<EOF | rpk topic produce 'test_safe_update' -f "%v\n"
{"id": 4, "data": "after_broker_update"}
{"id": 5, "data": "after_broker_update"}
{"id": 6, "data": "after_broker_update"}
EOF

sleep 2s

# Verify consumption continues after broker update
query I retry 5 backoff 1s
SELECT COUNT(*) FROM mv_test;
----
6

# Verify broker was updated in catalog
query I
SELECT COUNT(*) FROM rw_sources
WHERE name = 'kafka_test_source'
  AND definition LIKE '%${RISEDEV_KAFKA_BOOTSTRAP_SERVERS}%';
----
1

# Test 2: Reset splits (without property update)
system ok
SOURCE_ID=$(psql -h ${RISEDEV_RW_FRONTEND_LISTEN_ADDRESS} \
    -p ${RISEDEV_RW_FRONTEND_PORT} \
    -d $__DATABASE__ \
    -U root \
    -t -A \
    -c "SELECT id FROM rw_sources WHERE name = 'kafka_test_source'") && \
echo "Resetting splits for Source ID: $SOURCE_ID" && \
./risedev ctl meta reset-source-splits --source-id $SOURCE_ID

# Produce more data after reset
system ok
cat <<EOF | rpk topic produce 'test_safe_update' -f "%v\n"
{"id": 7, "data": "after_reset"}
{"id": 8, "data": "after_reset"}
{"id": 9, "data": "after_reset"}
EOF

# Verify consumption after split reset
query I retry 5 backoff 1s
SELECT COUNT(*) FROM mv_test;
----
9

# Test 3: Inject offsets (UNSAFE)
# This test verifies offset injection by injecting a backward offset,
# which should cause duplicate message consumption.

# Record current count before injection
query I
SELECT COUNT(*) FROM mv_test;
----
9

# Get Kafka offsets with skip_last=4 to go back 4 messages
# This will inject offset = high_watermark - 4, causing re-consumption of last 4 messages
system ok
python3 e2e_test/source_inline/kafka/alter/get_kafka_offsets.py \
    --topic test_safe_update \
    --skip-last 4 \
    --output /tmp/offsets.json

# Call risectl to inject offsets
system ok
SOURCE_ID=$(psql -h ${RISEDEV_RW_FRONTEND_LISTEN_ADDRESS} \
    -p ${RISEDEV_RW_FRONTEND_PORT} \
    -d $__DATABASE__ \
    -U root \
    -t -A \
    -c "SELECT id FROM rw_sources WHERE name = 'kafka_test_source'") && \
OFFSETS=$(cat /tmp/offsets.json) && \
echo "Injecting offsets for Source ID: $SOURCE_ID" && \
echo "Offsets: $OFFSETS" && \
./risedev ctl meta inject-source-offsets \
    --source-id $SOURCE_ID \
    --offsets "$OFFSETS"

# After offset injection with backward offset, the source should re-read 4 messages
# This will result in duplicates, so count should increase by 4
# Wait for the re-consumption to happen
sleep 3s

# Verify count increased due to duplicate consumption from backward offset injection
# Original: 9, re-read 4 messages = 13
query I retry 5 backoff 1s
SELECT COUNT(*) FROM mv_test;
----
13

# Produce new data - should be consumed normally
system ok
cat <<EOF | rpk topic produce 'test_safe_update' -f "%v\n"
{"id": 10, "data": "after_inject"}
{"id": 11, "data": "after_inject"}
EOF

# Verify new messages are consumed (total should be 13 + 2 = 15)
query I retry 5 backoff 1s
SELECT COUNT(*) FROM mv_test;
----
15

# Verify the "after_inject" messages were consumed
query I
SELECT COUNT(*) FROM mv_test WHERE data = 'after_inject';
----
2

# Cleanup
statement ok
DROP MATERIALIZED VIEW mv_test;

statement ok
DROP SOURCE kafka_test_source;

system ok
rpk topic delete test_safe_update
