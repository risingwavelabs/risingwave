syntax = "proto3";

package batch_plan;

import "catalog.proto";
import "common.proto";
import "data.proto";
import "order.proto";
import "expr.proto";
import "plan_common.proto";

option java_package = "com.risingwave.proto";
option optimize_for = SPEED;

message RowSeqScanNode {
  plan_common.StorageTableDesc table_desc = 1;
  repeated int32 column_ids = 2;
  // All the ranges need to be read. i.e., they are OR'ed.
  //
  // Empty `scan_ranges` means full table scan.
  repeated ScanRange scan_ranges = 3;
  // The partition to read for scan tasks.
  //
  // Will be filled by the scheduler.
  common.Buffer vnode_bitmap = 4;
  // Whether the order on output columns should be preserved.
  bool ordered = 5;

  message ChunkSize {
    uint32 chunk_size = 1;
  }
  // If along with `batch_limit`, `chunk_size` will be set.
  ChunkSize chunk_size = 6;
}

message SysRowSeqScanNode {
  uint32 table_id = 1;
  repeated plan_common.ColumnDesc column_descs = 2;
}

// The range to scan, which specifies a consecutive range of the PK
// and can represent: (Suppose there are N columns in the PK)
// - full table scan: Should not occur. Use an empty `Vec<ScanRange>` instead.
// - index range scan: `eq_conds` includes i (between 0 and N-1, inclusive) values,
//     and `lower_bound` & `upper_bound` is the range for the (i+1)th column
// - index point get: `eq_conds` includes N values, and `lower_bound` & `upper_bound` are `None`
message ScanRange {
  // The i-th element represents the value of the i-th PK column.
  repeated bytes eq_conds = 1;

  // `None` represent unbounded.
  message Bound {
    bytes value = 1;
    bool inclusive = 2;
  }
  //  The lower bound of the next PK column subsequent to those in `eq_conds`.
  Bound lower_bound = 2;
  //  The upper bound of the next PK column subsequent to those in `eq_conds`.
  Bound upper_bound = 3;
}

message SourceNode {
  uint32 source_id = 1;
  repeated plan_common.ColumnCatalog columns = 2;
  map<string, string> properties = 3;
  bytes split = 4;
  catalog.StreamSourceInfo info = 5;
}

message ProjectNode {
  repeated expr.ExprNode select_list = 1;
}

message FilterNode {
  expr.ExprNode search_condition = 1;
}

message InsertNode {
  // Id of the table to perform inserting.
  uint32 table_id = 1;
  // Version of the table.
  uint64 table_version_id = 5;
  repeated uint32 column_indices = 2;
  // An optional field and will be `None` for tables without user-defined pk.
  // The `BatchInsertExecutor` should add a column with NULL value which will
  // be filled in streaming.
  optional uint32 row_id_index = 3;
  bool returning = 4;
}

message DeleteNode {
  // Id of the table to perform deleting.
  uint32 table_id = 1;
  // Version of the table.
  uint64 table_version_id = 3;
  bool returning = 2;
}

message UpdateNode {
  // Id of the table to perform updating.
  uint32 table_id = 1;
  // Version of the table.
  uint64 table_version_id = 4;
  repeated expr.ExprNode exprs = 2;
  bool returning = 3;
}

message ValuesNode {
  message ExprTuple {
    repeated expr.ExprNode cells = 1;
  }
  repeated ExprTuple tuples = 1;
  repeated plan_common.Field fields = 2;
}

message SortNode {
  repeated order.PbColumnOrder column_orders = 1;
}

message TopNNode {
  repeated order.PbColumnOrder column_orders = 1;
  uint64 limit = 2;
  uint64 offset = 3;
  bool with_ties = 4;
}

message GroupTopNNode {
  repeated order.PbColumnOrder column_orders = 1;
  uint64 limit = 2;
  uint64 offset = 3;
  repeated uint32 group_key = 4;
  bool with_ties = 5;
}

message LimitNode {
  uint64 limit = 1;
  uint64 offset = 2;
}

message NestedLoopJoinNode {
  plan_common.JoinType join_type = 1;
  expr.ExprNode join_cond = 2;
  repeated uint32 output_indices = 3;
}

message HashAggNode {
  repeated uint32 group_key = 1;
  repeated expr.AggCall agg_calls = 2;
}

message ExpandNode {
  message Subset {
    repeated uint32 column_indices = 1;
  }
  repeated Subset column_subsets = 1;
}

message ProjectSetNode {
  repeated expr.ProjectSetSelectItem select_list = 1;
}

message SortAggNode {
  repeated expr.ExprNode group_key = 1;
  repeated expr.AggCall agg_calls = 2;
}

message HashJoinNode {
  plan_common.JoinType join_type = 1;
  repeated int32 left_key = 2;
  repeated int32 right_key = 3;
  expr.ExprNode condition = 4;
  repeated uint32 output_indices = 5;
  // Null safe means it treats `null = null` as true.
  // Each key pair can be null safe independently. (left_key, right_key, null_safe)
  repeated bool null_safe = 6;
}

message SortMergeJoinNode {
  plan_common.JoinType join_type = 1;
  repeated int32 left_key = 2;
  repeated int32 right_key = 3;
  order.PbDirection direction = 4;
  repeated uint32 output_indices = 5;
}

message HopWindowNode {
  uint32 time_col = 1;
  data.IntervalUnit window_slide = 2;
  data.IntervalUnit window_size = 3;
  repeated uint32 output_indices = 4;
}

message TableFunctionNode {
  expr.TableFunction table_function = 1;
}

// Task is a running instance of Stage.
message TaskId {
  string query_id = 1;
  uint32 stage_id = 2;
  uint32 task_id = 3;
}

// Every task will create N buffers (channels) for parent operators to fetch results from,
// where N is the parallelism of parent stage.
message TaskOutputId {
  TaskId task_id = 1;
  // The id of output channel to fetch from
  uint32 output_id = 2;
}

message LocalExecutePlan {
  batch_plan.PlanFragment plan = 1;
  common.BatchQueryEpoch epoch = 2;
}

// ExchangeSource describes where to read results from children operators
message ExchangeSource {
  TaskOutputId task_output_id = 1;
  common.HostAddress host = 2;
  oneof local_execute_plan {
    LocalExecutePlan plan = 3;
  }
}

message ExchangeNode {
  repeated ExchangeSource sources = 1;
  repeated plan_common.Field input_schema = 3;
}

message MergeSortExchangeNode {
  ExchangeNode exchange = 1;
  repeated order.PbColumnOrder column_orders = 2;
}

message LocalLookupJoinNode {
  plan_common.JoinType join_type = 1;
  expr.ExprNode condition = 2;
  repeated uint32 outer_side_key = 3;
  repeated uint32 inner_side_key = 4;
  uint32 lookup_prefix_len = 5;
  plan_common.StorageTableDesc inner_side_table_desc = 6;
  repeated uint32 inner_side_vnode_mapping = 7;
  repeated int32 inner_side_column_ids = 8;
  repeated uint32 output_indices = 9;
  repeated common.WorkerNode worker_nodes = 10;
  // Null safe means it treats `null = null` as true.
  // Each key pair can be null safe independently. (left_key, right_key, null_safe)
  repeated bool null_safe = 11;
}

// RFC: A new schedule way for distributed lookup join
// https://github.com/risingwavelabs/rfcs/pull/6
message DistributedLookupJoinNode {
  plan_common.JoinType join_type = 1;
  expr.ExprNode condition = 2;
  repeated uint32 outer_side_key = 3;
  repeated uint32 inner_side_key = 4;
  uint32 lookup_prefix_len = 5;
  plan_common.StorageTableDesc inner_side_table_desc = 6;
  repeated int32 inner_side_column_ids = 7;
  repeated uint32 output_indices = 8;
  // Null safe means it treats `null = null` as true.
  // Each key pair can be null safe independently. (left_key, right_key, null_safe)
  repeated bool null_safe = 9;
}

message UnionNode {}

message PlanNode {
  repeated PlanNode children = 1;
  reserved 22;
  reserved "sort_merge_join";
  oneof node_body {
    InsertNode insert = 2;
    DeleteNode delete = 3;
    UpdateNode update = 4;
    ProjectNode project = 5;
    HashAggNode hash_agg = 7;
    FilterNode filter = 8;
    ExchangeNode exchange = 9;
    SortNode sort = 10;
    NestedLoopJoinNode nested_loop_join = 11;
    TopNNode top_n = 14;
    SortAggNode sort_agg = 15;
    RowSeqScanNode row_seq_scan = 16;
    LimitNode limit = 17;
    ValuesNode values = 18;
    HashJoinNode hash_join = 19;
    MergeSortExchangeNode merge_sort_exchange = 21;
    HopWindowNode hop_window = 25;
    TableFunctionNode table_function = 26;
    SysRowSeqScanNode sys_row_seq_scan = 27;
    ExpandNode expand = 28;
    LocalLookupJoinNode local_lookup_join = 29;
    ProjectSetNode project_set = 30;
    UnionNode union = 31;
    GroupTopNNode group_top_n = 32;
    DistributedLookupJoinNode distributed_lookup_join = 33;
    SourceNode source = 34;
  }
  string identity = 24;
}

// ExchangeInfo determines how to distribute results to tasks of next stage.
//
// Note that the fragment itself does not know the where are the receivers. Instead, it prepares results in
// N buffers and wait for parent operators (`Exchange` nodes) to pull data from a specified buffer
message ExchangeInfo {
  enum DistributionMode {
    // No partitioning at all, used for root segment which aggregates query results
    UNSPECIFIED = 0;
    SINGLE = 1;
    BROADCAST = 2;
    HASH = 3;
    CONSISTENT_HASH = 4;
  }
  message BroadcastInfo {
    uint32 count = 1;
  }
  message HashInfo {
    uint32 output_count = 1;
    repeated uint32 key = 3;
  }
  message ConsistentHashInfo {
    // `vmap` maps virtual node to down stream task id
    repeated uint32 vmap = 1;
    repeated uint32 key = 2;
  }
  DistributionMode mode = 1;
  oneof distribution {
    BroadcastInfo broadcast_info = 2;
    HashInfo hash_info = 3;
    ConsistentHashInfo consistent_hash_info = 4;
  }
}

message PlanFragment {
  PlanNode root = 1;
  ExchangeInfo exchange_info = 2;
}
