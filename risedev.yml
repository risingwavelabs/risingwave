# The schema for RiseDev configuration files is defined under `src/risedevtool/schemas`.
#
# You can add the following section to `.vscode/settings.json` to get hover support in VS Code:
#
# ```
#     "yaml.schemas": {
#         "src/risedevtool/schemas/risedev.json": "risedev.yml",
#         "src/risedevtool/schemas/risedev-profiles.user.json": "risedev-profiles.user.yml"
#     }
# ```

profile:
  #################################################
  ### Configuration profiles used by developers ###
  #################################################

  # The default configuration will start 1 compute node, 1 meta node and 1 frontend.
  default:
    # # Specify a configuration file to override the default settings
    # config-path: src/config/example.toml
    # # Specify custom environment variables
    # env:
    #   RUST_LOG: "info,risingwave_storage::hummock=off"
    #   ENABLE_PRETTY_LOG: "true"
    steps:
      # If you want to use the local s3 storage, enable the following line
      # - use: minio

      # If you want to use aws-s3, configure AK and SK in env var and enable the following lines:
      # - use: aws-s3
      #   bucket: test-bucket

      # By default, the meta-backend is sqlite.
      # To enable postgres backend, uncomment the following lines and set the meta-backend to postgres in 'meta-node'
      # - use: postgres
      #   port: 8432
      #   user: postgres
      #   database: metadata

      # If you want to enable metrics or tracing, uncomment the following lines.
      # - use: prometheus  # metrics
      # - use: tempo       # tracing
      # - use: grafana     # visualization

      - use: meta-node
        # meta-backend: postgres
      - use: compute-node
      - use: frontend

      # If you want to enable compactor, uncomment the following line, and enable either minio or aws-s3 as well.
      # - use: compactor

      # If you want to create source from Kafka, uncomment the following lines
      # - use: kafka
      #   persist-data: true

      # To enable Confluent schema registry, uncomment the following line
      # - use: schema-registry

  default-v6:
    steps:
      - use: meta-node
        address: "[::1]"
        listen-address: "[::]"
      - use: compute-node
        address: "[::1]"
        listen-address: "[::]"
      - use: frontend
        address: "[::1]"
        listen-address: "[::]"

  # The minimum config to use with risectl.
  for-ctl:
    steps:
      - use: minio
      - use: meta-node
      - use: compute-node
      - use: frontend
      - use: compactor

  # `dev-compute-node` have the same settings as default except the compute node will be started by user.
  dev-compute-node:
    steps:
      - use: meta-node
      - use: compute-node
        user-managed: true
      - use: frontend

  dev-frontend:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
        user-managed: true

  dev-meta:
    steps:
      - use: meta-node
        user-managed: true
      - use: compute-node
      - use: frontend

  # You can use this in combination with the virtual compactor
  # provided in https://github.com/risingwavelabs/risingwave-extensions
  dev-compactor:
    steps:
      - use: minio
      - use: meta-node
      - use: compute-node
      - use: frontend
      - use: compactor
        user-managed: true

  full:
    steps:
      - use: minio
      - use: postgres
        port: 8432
        user: postgres
        password: postgres
        database: metadata
      - use: meta-node
        meta-backend: postgres
      - use: compute-node
      - use: frontend
      - use: compactor
      - use: prometheus
      - use: grafana
      - use: kafka
        persist-data: true

  standalone-full-peripherals:
    steps:
      - use: minio
      - use: postgres
        port: 8432
        user: postgres
        database: metadata
      - use: meta-node
        user-managed: true
        meta-backend: postgres
      - use: compute-node
        user-managed: true
      - use: frontend
        user-managed: true
      - use: compactor
        user-managed: true
      - use: prometheus
      - use: grafana
      - use: kafka
        persist-data: true

  standalone-minio-sqlite:
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        user-managed: true
        meta-backend: sqlite
      - use: compute-node
        user-managed: true
      - use: frontend
        user-managed: true
      - use: compactor
        user-managed: true

  standalone-minio-sqlite-compactor:
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        user-managed: true
        meta-backend: sqlite
      - use: compute-node
        user-managed: true
      - use: frontend
        user-managed: true
      - use: compactor

  hdfs:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use hdfs as storage backend, configure hdfs namenode:
      - use: opendal
        engine: hdfs
        namenode: "127.0.0.1:9000"
      - use: compactor
      # - use: prometheus
      # - use: grafana
  fs:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      - use: opendal
        engine: fs
      - use: compactor
      # - use: prometheus
      # - use: grafana
  webhdfs:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use webhdfs as storage backend, configure hdfs namenode:
      - use: opendal
        engine: webhdfs
        namenode: "127.0.0.1:9870"
      - use: compactor
      # - use: prometheus
      # - use: grafana

  gcs:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use google cloud storage as storage backend, configure bucket name:
      - use: opendal
        engine: gcs
        bucket: bucket-name
      - use: compactor
      # - use: prometheus
      # - use: grafana
  obs:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use obs as storage backend, configure bucket name:
      - use: opendal
        engine: obs
        bucket: bucket-name
      - use: compactor
      # - use: prometheus
      # - use: grafana

  oss:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use oss as storage backend, configure bucket name:
      - use: opendal
        engine: oss
        bucket: bucket-name
      - use: compactor
      # - use: prometheus
      # - use: grafana

  azblob:
    steps:
      - use: meta-node
      - use: compute-node
      - use: frontend
      # If you want to use azblob as storage backend, configure bucket(container) name:
      - use: opendal
        engine: azblob
        bucket: test-bucket
      - use: compactor
      # - use: prometheus
      # - use: grafana

  full-benchmark:
    steps:
      - use: minio
      - use: postgres
      - use: meta-node
        meta-backend: postgres
      - use: compute-node
      - use: frontend
      - use: compactor
      - use: prometheus
        remote-write: true
        remote-write-region: "ap-southeast-1"
        remote-write-url: "https://aps-workspaces.ap-southeast-1.amazonaws.com/workspaces/ws-f3841dad-6a5c-420f-8f62-8f66487f512a/api/v1/remote_write"
      - use: grafana
      - use: kafka
        persist-data: true

  meta-1cn-1fe-sqlite:
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: sqlite
      - use: compactor
      - use: compute-node
      - use: frontend

  # Start 4 CNs with resource groups rg1, rg2, and default
  multiple-resource-groups:
    steps:
      - use: minio
      - use: meta-node
      - use: compactor
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
        resource-group: "rg1"
      - use: compute-node
        port: 5688
        exporter-port: 1223
        resource-group: "rg2"
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend


  ci-time-travel:
    config-path: src/config/ci-time-travel.toml
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: sqlite
      - use: compactor
      - use: compute-node
      - use: frontend

  ci-iceberg-engine:
    steps:
      - use: minio
      - use: postgres
        port: 5432
        address: db
        database: metadata
        user: postgres
        password: postgres
        user-managed: true
        application: metastore
      - use: meta-node
        meta-backend: postgres
      - use: compute-node
      - use: frontend
      - use: compactor

  meta-1cn-1fe-sqlite-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: sqlite
      - use: compactor
      - use: compute-node
      - use: frontend

  meta-1cn-1fe-pg-backend:
    steps:
      - use: minio
      - use: postgres
        port: 8432
        user: postgres
        database: metadata
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: postgres
      - use: compactor
      - use: compute-node
      - use: frontend

  meta-1cn-1fe-pg-backend-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: postgres
        port: 8432
        user: postgres
        database: metadata
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: postgres
      - use: compactor
      - use: compute-node
      - use: frontend

  meta-1cn-1fe-mysql-backend:
    steps:
      - use: minio
      - use: mysql
        port: 4306
        user: root
        database: metadata
        application: metastore
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: mysql
      - use: compactor
      - use: compute-node
      - use: frontend

  meta-1cn-1fe-mysql-backend-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: mysql
        port: 4306
        user: root
        database: metadata
        application: metastore
      - use: meta-node
        port: 5690
        dashboard-port: 5691
        exporter-port: 1250
        meta-backend: mysql
      - use: compactor
      - use: compute-node
      - use: frontend

  java-binding-demo:
    steps:
      - use: minio
        address: "127.0.0.1"
        port: 9301
        root-user: hummockadmin
        root-password: hummockadmin
        hummock-bucket: hummock001
      - use: meta-node
        address: "127.0.0.1"
        port: 5690
      - use: compute-node
      - use: frontend
      - use: compactor

  ci-gen-cpu-flamegraph:
    steps:
      # NOTE(kwannoel): We do not use aws-s3 here, to avoid
      # contention over s3 bucket when multiple benchmarks at run at once.
      - use: minio
      - use: sqlite
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
        parallelism: 8
      - use: frontend
      - use: compactor
      # - use: prometheus
      # - use: grafana
      # Do not use kafka here, we will spawn it separately,
      # so we don't have to re-generate data each time.
      # RW will still be ale to talk to it.
      # - use: kafka
      #   port: 9092
      #   persist-data: true

  ######################################
  ### Configurations used in Compose ###
  ######################################

  compose:
    steps:
      - use: minio
        id: minio-0
        address: ${id}
        listen-address: "0.0.0.0"
        console-address: "0.0.0.0"

      - use: meta-node
        # Id must starts with `meta-node`, therefore to be picked up by other
        # components.
        id: meta-node-0

        # Advertise address can be `id`, so as to use docker's DNS. If running
        # in host network mode, we should use IP directly in this field.
        address: ${id}

        listen-address: "0.0.0.0"

      - use: compute-node
        id: compute-node-0
        listen-address: "0.0.0.0"
        address: ${id}

      - use: frontend
        id: frontend-node-0
        listen-address: "0.0.0.0"
        address: ${id}

      - use: compactor
        id: compactor-0
        listen-address: "0.0.0.0"
        address: ${id}

      - use: redpanda

      - use: prometheus
        id: prometheus-0
        listen-address: "0.0.0.0"
        address: ${id}

      - use: grafana
        listen-address: "0.0.0.0"
        address: ${id}
        id: grafana-0

      - use: tempo
        listen-address: "0.0.0.0"
        address: ${id}
        id: tempo-0

  # special config for deployment, see related PR for more information
  compose-3node-deploy:
    steps:
      # - use: minio
      #   id: minio-0
      #   address: ${dns-host:rw-source-0}
      #   listen-address: "0.0.0.0"
      #   console-address: "0.0.0.0"

      - use: aws-s3
        bucket: ${terraform:s3-bucket}

      - use: meta-node
        # Id must starts with `meta-node`, therefore to be picked up by other
        # components.
        id: meta-node-0

        # Advertise address can be `id`, so as to use docker's DNS. If running
        # in host network mode, we should use IP directly in this field.
        address: ${dns-host:rw-meta-0}
        listen-address: "0.0.0.0"

      - use: compute-node
        id: compute-node-0
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-compute-0}
        async-stack-trace: verbose
        enable-tiered-cache: true

      - use: compute-node
        id: compute-node-1
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-compute-1}
        async-stack-trace: verbose
        enable-tiered-cache: true

      - use: compute-node
        id: compute-node-2
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-compute-2}
        async-stack-trace: verbose
        enable-tiered-cache: true

      - use: frontend
        id: frontend-node-0
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-meta-0}

      - use: compactor
        id: compactor-0
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-source-0}
        compaction-worker-threads-number: 15

      - use: redpanda
        address: ${dns-host:rw-source-0}

      - use: prometheus
        id: prometheus-0
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-meta-0}

      - use: grafana
        listen-address: "0.0.0.0"
        address: ${dns-host:rw-meta-0}
        id: grafana-0

  #################################
  ### Configurations used on CI ###
  #################################

  ci-1cn-1fe:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-1cn-1fe-jdbc-to-native:
    config-path: src/config/ci-jdbc-to-native.toml
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-3cn-1fe:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-backfill-3cn-1fe:
    config-path: src/config/ci-longer-streaming-upload-timeout.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-backfill-3cn-1fe-with-monitoring:
    config-path: src/config/ci-longer-streaming-upload-timeout.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: prometheus
      - use: grafana

  ci-backfill-3cn-1fe-with-minio-rate-limit:
    config-path: src/config/ci-longer-streaming-upload-timeout.toml
    steps:
      - use: minio
        api-requests-max: 30
        api-requests-deadline: 3s
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-backfill-3cn-1fe-with-monitoring-and-minio-rate-limit:
    config-path: src/config/ci-longer-streaming-upload-timeout.toml
    steps:
      - use: minio
        api-requests-max: 30
        api-requests-deadline: 2s
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: prometheus
      - use: grafana

  ci-3cn-3fe:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
        port: 4565
        exporter-port: 2222
        health-check-port: 6786
      - use: frontend
        port: 4566
        exporter-port: 2223
        health-check-port: 6787
      - use: frontend
        port: 4567
        exporter-port: 2224
        health-check-port: 6788
      - use: compactor

  ci-3cn-3fe-in-memory:
    config-path: src/config/ci-mem.toml
    steps:
      - use: meta-node
        enable-in-memory-kv-state-backend: true
      - use: compute-node
        port: 5687
        exporter-port: 1222
      - use: compute-node
        port: 5688
        exporter-port: 1223
      - use: compute-node
        port: 5689
        exporter-port: 1224
      - use: frontend
        port: 4565
        exporter-port: 2222
        health-check-port: 6786
      - use: frontend
        port: 4566
        exporter-port: 2223
        health-check-port: 6787
      - use: frontend
        port: 4567
        exporter-port: 2224
        health-check-port: 6788

  ci-3cn-3fe-opendal-fs-backend:
    config-path: src/config/ci.toml
    steps:
      - use: meta-node
        meta-backend: env
      - use: opendal
        engine: fs
        bucket: "/tmp/rw_ci"
      - use: compute-node
        port: 5687
        exporter-port: 1222
      - use: compute-node
        port: 5688
        exporter-port: 1223
      - use: compute-node
        port: 5689
        exporter-port: 1224
      - use: frontend
        port: 4565
        exporter-port: 2222
        health-check-port: 6786
      - use: frontend
        port: 4566
        exporter-port: 2223
        health-check-port: 6787
      - use: frontend
        port: 4567
        exporter-port: 2224
        health-check-port: 6788
      - use: compactor

  ci-3streaming-2serving-3fe:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
        role: streaming
        parallelism: 4
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
        role: streaming
        parallelism: 4
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
        role: streaming
        parallelism: 4
      - use: compute-node
        port: 5685
        exporter-port: 1225
        enable-tiered-cache: true
        role: serving
        parallelism: 4
      - use: compute-node
        port: 5686
        exporter-port: 1226
        enable-tiered-cache: true
        role: serving
        parallelism: 8
      - use: frontend
        port: 4565
        exporter-port: 2222
        health-check-port: 6786
      - use: frontend
        port: 4566
        exporter-port: 2223
        health-check-port: 6787
      - use: frontend
        port: 4567
        exporter-port: 2224
        health-check-port: 6788
      - use: compactor

  ci-kafka:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: kafka
        user-managed: true
        address: message_queue
        port: 29092
      - use: schema-registry
        user-managed: true
        address: schemaregistry
        port: 8082

  local-inline-source-test:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: pubsub
        persist-data: true
      - use: kafka
        persist-data: true
      - use: schema-registry
      - use: mysql
      - use: postgres

  ci-inline-source-test:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: pubsub
        persist-data: true
      - use: kafka
        user-managed: true
        address: message_queue
        port: 29092
      - use: schema-registry
        user-managed: true
        address: schemaregistry
        port: 8082
      - use: mysql
        port: 3306
        address: mysql
        user: root
        password: 123456
        user-managed: true
      - use: postgres
        port: 5432
        address: db
        user: postgres
        password: postgres
        user-managed: true

  ci-redis:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: redis

  ci-compaction-test:
    config-path: src/config/ci-compaction-test.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
        total-memory-bytes: 17179869184
      - use: frontend
      - use: compactor

  ci-1cn-1fe-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-3cn-1fe-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        port: 5687
        exporter-port: 1222
        enable-tiered-cache: true
      - use: compute-node
        port: 5688
        exporter-port: 1223
        enable-tiered-cache: true
      - use: compute-node
        port: 5689
        exporter-port: 1224
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-1cn-1fe-user-kafka-with-recovery:
    config-path: src/config/ci-recovery.toml
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor
      - use: kafka
        user-managed: true
        address: message_queue
        port: 29092

  ci-meta-backup-test-sql:
    config-path: src/config/ci-meta-backup-test.toml
    steps:
      - use: sqlite
      - use: minio
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
      - use: frontend
      - use: compactor

  ci-meta-backup-test-restore-sql:
    config-path: src/config/ci-meta-backup-test.toml
    steps:
      - use: sqlite
      - use: minio

  ci-iceberg-test:
    config-path: src/config/ci-iceberg-test.toml
    steps:
      - use: minio
      - use: meta-node
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  ci-sink-test:
    config-path: src/config/ci.toml
    steps:
      - use: minio
      - use: meta-node
      - use: compute-node
        enable-tiered-cache: true
      - use: frontend
      - use: compactor

  hummock-trace:
    config-path: src/config/hummock-trace.toml
    steps:
      - use: minio
      - use: meta-node
      - use: compute-node
      - use: frontend
      - use: compactor

  ci-backfill:
    config-path: "src/config/ci-backfill.toml"
    steps:
      - use: minio
      - use: meta-node
        meta-backend: env
      - use: compute-node
      - use: frontend
      - use: compactor

  full-iceberg-bench:
    config-path: src/config/full-iceberg-bench.toml
    steps:
      - use: aws-s3
        bucket: renjie-iceberg-bench
      - use: sqlite
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
      - use: frontend
      - use: compactor
      - use: prometheus
      - use: grafana

  full-with-batch-query-limit:
    config-path: src/config/full-with-batch-query-limit.toml
    steps:
      - use: minio
      - use: sqlite
      - use: meta-node
        meta-backend: sqlite
      - use: compute-node
      - use: frontend
      - use: compactor
      - use: prometheus
      - use: grafana

compose:
  risingwave: "ghcr.io/risingwavelabs/risingwave:latest"
  prometheus: "prom/prometheus:latest"
  minio: "quay.io/minio/minio:latest"
  redpanda: "redpandadata/redpanda:latest"
  grafana: "grafana/grafana-oss:latest"
  tempo: "grafana/tempo:latest"

# The `use` field specified in the above `risedev` section will refer to the templates below.
template:
  minio:
    # Advertise address of MinIO s3 endpoint
    address: "127.0.0.1"

    # Advertise port of MinIO s3 endpoint
    port: 9301

    # Listen address of MinIO endpoint
    listen-address: ${address}

    # Console address of MinIO s3 endpoint
    console-address: "127.0.0.1"

    # Console port of MinIO s3 endpoint
    console-port: 9400

    # Root username (can be used to login to MinIO console)
    root-user: hummockadmin

    # Root password (can be used to login to MinIO console)
    root-password: hummockadmin

    # Bucket name to store hummock information
    hummock-bucket: hummock001

    # Id of this instance
    id: minio

    # Prometheus nodes used by this MinIO
    provide-prometheus: "prometheus*"

    # Max concurrent api requests.
    # see: https://github.com/minio/minio/blob/master/docs/throttle/README.md.
    # '0' means this env var will use the default of minio.
    api-requests-max: 0

    # Deadline for api requests.
    # Empty string means this env var will use the default of minio.
    api-requests-deadline: ""

  sqlite:
    # Id of this instance
    id: sqlite

    # File name of the sqlite database
    file: metadata.db

  compute-node:
    # Compute-node advertise address
    address: "127.0.0.1"

    # Listen address
    listen-address: ${address}

    # Compute-node listen port
    port: 5688

    # Prometheus exporter listen port
    exporter-port: 1222

    # Id of this instance
    id: compute-node-${port}

    # Whether to enable async stack trace for this compute node, `off`, `on`, or `verbose`.
    # Considering the performance, `verbose` mode only effect under `release` profile with `debug_assertions` off.
    async-stack-trace: verbose

    # If `enable-tiered-cache` is true, hummock will use data directory as file cache.
    enable-tiered-cache: false

    # Minio instances used by this compute node
    provide-minio: "minio*"

    # OpenDAL storage backend used by this compute node
    provide-opendal: "opendal*"

    # AWS s3 bucket used by this compute node
    provide-aws-s3: "aws-s3*"

    # Meta-nodes used by this compute node
    provide-meta-node: "meta-node*"

    # Tempo used by this compute node
    provide-tempo: "tempo*"

    # If `user-managed` is true, this service will be started by user with the above config
    user-managed: false

    # Total available memory for the compute node in bytes
    total-memory-bytes: 8589934592

    # Parallelism of tasks per compute node
    parallelism: 4

    role: both

    # Resource group for scheduling, default value is "default"
    resource-group: "default"

  meta-node:
    # Meta-node advertise address
    address: "127.0.0.1"

    # Meta-node listen port
    port: 5690

    # Listen address
    listen-address: ${address}

    # Dashboard listen port
    dashboard-port: 5691

    # Prometheus exporter listen port
    exporter-port: 1250

    # Id of this instance
    id: meta-node-${port}

    # If `user-managed` is true, this service will be started by user with the above config
    user-managed: false

    # meta backend type, requires extra config for provided backend
    meta-backend: "memory"

    # Sqlite backend config
    provide-sqlite-backend: "sqlite*"

    # Postgres backend config
    provide-postgres-backend: "postgres*"

    # Mysql backend config
    provide-mysql-backend: "mysql*"

    # Prometheus nodes used by dashboard service
    provide-prometheus: "prometheus*"

    # Sanity check: should use shared storage if there're multiple compute nodes
    provide-compute-node: "compute-node*"

    # Sanity check: should start at lease one compactor if using shared object store
    provide-compactor: "compactor*"

    # Minio instances used by the cluster
    provide-minio: "minio*"

    # OpenDAL storage backend used by the cluster
    provide-opendal: "opendal*"

    # AWS s3 bucket used by the cluster
    provide-aws-s3: "aws-s3*"

    # Tempo used by this meta node
    provide-tempo: "tempo*"

    # Whether to enable in-memory pure KV state backend
    enable-in-memory-kv-state-backend: false

  prometheus:
    # Advertise address of Prometheus
    address: "127.0.0.1"

    # Listen port of Prometheus
    port: 9500

    # Listen address
    listen-address: ${address}

    # Id of this instance
    id: prometheus

    # If `remote_write` is true, this Prometheus instance will push metrics to remote instance
    remote-write: false

    # AWS region of remote write
    remote-write-region: ""

    # Remote write url of this instance
    remote-write-url: ""

    # Compute-nodes used by this Prometheus instance
    provide-compute-node: "compute-node*"

    # Meta-nodes used by this Prometheus instance
    provide-meta-node: "meta-node*"

    # Minio instances used by this Prometheus instance
    provide-minio: "minio*"

    # Compactors used by this Prometheus instance
    provide-compactor: "compactor*"

    # Redpanda used by this Prometheus instance
    provide-redpanda: "redpanda*"

    # Frontend used by this Prometheus instance
    provide-frontend: "frontend*"

    # How frequently Prometheus scrape targets (collect metrics)
    scrape-interval: 15s

  frontend:
    # Advertise address of frontend
    address: "127.0.0.1"

    # Listen port of frontend
    port: 4566

    # Listen address
    listen-address: ${address}

    # Prometheus exporter listen port
    exporter-port: 2222

    # Health check listen port
    health-check-port: 6786

    # Id of this instance
    id: frontend-${port}

    # Meta-nodes used by this frontend instance
    provide-meta-node: "meta-node*"

    # Tempo used by this frontend instance
    provide-tempo: "tempo*"

    # If `user-managed` is true, this service will be started by user with the above config
    user-managed: false

  compactor:
    # Compactor advertise address
    address: "127.0.0.1"

    # Compactor listen port
    port: 6660

    # Listen address
    listen-address: ${address}

    # Prometheus exporter listen port
    exporter-port: 1260

    # Id of this instance
    id: compactor-${port}

    # Minio instances used by this compactor
    provide-minio: "minio*"

    # Meta-nodes used by this compactor
    provide-meta-node: "meta-node*"

    # Tempo used by this compator
    provide-tempo: "tempo*"

    # If `user-managed` is true, this service will be started by user with the above config
    user-managed: false

  grafana:
    # Listen address of Grafana
    listen-address: ${address}

    # Advertise address of Grafana
    address: "127.0.0.1"

    # Listen port of Grafana
    port: 3001

    # Id of this instance
    id: grafana

    # Prometheus used by this Grafana instance
    provide-prometheus: "prometheus*"

    # Tempo used by this Grafana instance
    provide-tempo: "tempo*"

  tempo:
    # Id of this instance
    id: tempo

    # Listen address of HTTP server and OTLP gRPC collector
    listen-address: "127.0.0.1"

    # Advertise address of Tempo
    address: "127.0.0.1"

    # HTTP server listen port
    port: 3200

    # gRPC listen port of the OTLP collector
    otlp-port: 4317

    max-bytes-per-trace: 5000000

  opendal:
    id: opendal

    engine: hdfs

    namenode: 127.0.0.1:9000

    bucket: risingwave-test

  # aws-s3 is a placeholder service to provide configurations
  aws-s3:
    # Id to be picked-up by services
    id: aws-s3

    # The bucket to be used for AWS S3
    bucket: test-bucket

    # access key, secret key and region should be set in aws config (either by env var or .aws/config)

  # Apache Kafka service backed by docker.
  kafka:
    # Id to be picked-up by services
    id: kafka-${port}

    # Advertise address of Kafka
    address: "127.0.0.1"

    # Listen port of Kafka
    port: 29092

    # Listen port of KRaft controller
    controller-port: 29093
    # Listen port for other services in docker (schema-registry)
    docker-port: 29094

    # The docker image. Can be overridden to use a different version.
    image: "confluentinc/cp-kafka:7.6.1"

    # If set to true, data will be persisted at data/{id}.
    persist-data: true

    # Kafka node id. If there are multiple instances of Kafka, we will need to set.
    node-id: 0

    user-managed: false

  schema-registry:
    # Id to be picked-up by services
    id: schema-registry-${port}

    # Advertise address
    address: "127.0.0.1"

    # Listen port of Schema Registry
    port: 8081

    # The docker image. Can be overridden to use a different version.
    image: "confluentinc/cp-schema-registry:7.6.1"

    user-managed: false

    provide-kafka: "kafka*"

  # Google pubsub emulator service
  pubsub:
    id: pubsub-${port}

    address: "127.0.0.1"

    port: 5980

    persist-data: true

  # Only supported in RiseDev compose
  redpanda:
    # Id to be picked-up by services
    id: redpanda

    # Port used inside docker-compose cluster (e.g. create MV)
    internal-port: 29092

    # Port used on host (e.g. import data, connecting using kafkacat)
    outside-port: 9092

    # Connect address
    address: ${id}

    # Number of CPUs to use
    cpus: 8

    # Memory limit for Redpanda
    memory: 16G

  # redis service
  redis:
    # Id to be picked-up by services
    id: redis

    # listen port of redis
    port: 6379

    # address of redis
    address: "127.0.0.1"

  # MySQL service backed by docker.
  mysql:
    # Id to be picked-up by services
    id: mysql-${port}

    # address of mysql
    address: "127.0.0.1"

    # listen port of mysql
    port: 8306

    # Note:
    # - This will be used to initialize the MySQL instance.
    #   * If the user is "root", the password will be used as the root password.
    #   * Otherwise, a regular user will be created with the given password. The root password will be empty.
    #   Note that this only applies to fresh instances, i.e., the data directory is empty.
    # - These configs will be passed as-is to risedev-env default user for MySQL operations.
    # - This is not used in RISEDEV_MYSQL_WITH_OPTIONS_COMMON.
    user: root
    password: ""
    database: "risedev"

    # Which application to use. Can be overridden for metastore purpose.
    application: "connector"

    # The docker image. Can be overridden to use a different version.
    image: "mysql:8.0"

    # If set to true, data will be persisted at data/{id}.
    persist-data: true

    # If `user-managed` is true, user is responsible for starting the service
    # to serve at the above address and port in any way they see fit.
    user-managed: false

  # PostgreSQL service backed by docker.
  postgres:
    # Id to be picked-up by services
    id: postgres-${port}

    # address of pg
    address: "127.0.0.1"

    # listen port of pg
    port: 8432

    # Note:
    # - This will be used to initialize the PostgreSQL instance if it's fresh.
    # - These configs will be passed as-is to risedev-env default user for PostgreSQL operations.
    user: postgres
    password: ""
    database: "postgres"

    # Which application to use. Can be overridden for connector purpose.
    application: "metastore"

    # The docker image. Can be overridden to use a different version.
    image: "postgres:17-alpine"

    # If set to true, data will be persisted at data/{id}.
    persist-data: true

    # If `user-managed` is true, user is responsible for starting the service
    # to serve at the above address and port in any way they see fit.
    user-managed: false

  # Sql Server service backed by docker.
  sqlserver:
    # Note: Sql Server is now only for connector purpose.
    # Id to be picked-up by services
    id: sqlserver-${port}

    # address of mssql
    address: "127.0.0.1"

    # listen port of mssql
    port: 1433

    # Note:
    # - This will be used to initialize the Sql Server instance if it's fresh.
    # - In user-managed mode, these configs are not validated by risedev.
    #   They are passed as-is to risedev-env default user for Sql Server operations.
    user: SA
    password: "YourPassword123"
    database: "master"

    # The docker image. Can be overridden to use a different version.
    image: "mcr.microsoft.com/mssql/server:2022-latest"

    # If set to true, data will be persisted at data/{id}.
    persist-data: true

    # If `user-managed` is true, user is responsible for starting the service
    # to serve at the above address and port in any way they see fit.
    user-managed: false
